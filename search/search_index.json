{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Alsek \u26f0","text":""},{"location":"#overview","title":"Overview","text":"<p>Alsek is a distributed task queue library for Python. It has been built to be highly  capable while remaining very lightweight. Current functionality includes:</p> <ul> <li>Multiprocess and multi-thread task execution</li> <li>Automatic retries, with customizable backoff procedures</li> <li>Prioritization of queues and messages</li> <li>Result storage</li> <li>Status Tracking and Publishing</li> <li>Interactive Result Iteration</li> <li>Cron, date and interval task triggers (with result storage support)</li> <li>Robust task timeouts</li> <li>Revoking tasks</li> <li>Callbacks</li> <li>Dead Letter Queues (DLQs)</li> </ul>"},{"location":"#installing","title":"Installing","text":"<pre><code>pip install git+git://github.com/TariqAHassan/alsek@main\n</code></pre> <p>Note: Alsek will be added to PyPI in the near future.</p> <p>Requires Python 3.9+</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Alsek provides a framework for distributing, managing and executing tasks.  It accomplishes this using two core pieces of machinery: brokers and workers.  Brokers are responsible for the distribution and management of tasks, while  workers are  responsible for task execution. Let's work though each of these pieces in order.</p> <p>First, we'll create a <code>Broker()</code> powered by a <code>Redis</code> backend.  Let's suppose we do this in a file named <code>singletons.py</code>.</p> <pre><code>from alsek import Broker\nfrom alsek.storage.backends.redis import RedisBackend\n\nbackend = RedisBackend(\"&lt;connection_url&gt;\")\nbroker = Broker(backend)\n</code></pre> <p>Next, we can define a task to perform. Let's imagine we do this in a file named <code>my_tasks.py</code>.</p> <pre><code>from alsek import task\nfrom singletons import broker\n\n@task(broker, queue=\"math_ops\")\ndef add(a: int, b: int) -&gt; int:\n    return a + b\n</code></pre> <p>When we generate an instance of this task, as shown below, it will be persisted to the backend by the broker.</p> <pre><code>message = add.generate(args=(1, 1))\n</code></pre> <p>Task generation yields a <code>Message()</code> object, which contains detailed information about the task.  We can see this information by simply printing the message:</p> <pre><code>Message(\n    task_name='add',\n    queue='math_ops',\n    args=(1, 1),\n    kwargs={},\n    metadata=None,\n    result_ttl=None,\n    uuid='cb3b106a-2314-11f0-b7d7-4af50920870b',\n    progenitor_uuid=None,\n    retries=0,\n    timeout=3600000,\n    ...\n)\n</code></pre> <p>Here we can see the name of the original task was \"add\" and that it was enqueued on the \"math_ops\" queue.  We can also see more advanced information, such as the backoff procedure that will be used in the case of  retries as well as the mechanism that will be use to execute the task.  (In this case, the Worker Pool will execute the task in a distinct process.)</p> <p>In order for this message to be processed, we will need to start up a worker pool.  This can be accomplished using Alsek's command line interface (CLI).</p> <p>When spinning up a worker pool, we need to specify the modules where the tasks are defined.  In our case, this means passing <code>my_tasks</code>. (Note that Alsek scans this argument recursively,  allowing for task definitions to be nested deep inside directories.)</p> <pre><code>alsek thread-pool my_tasks\n</code></pre> <p>Now, detailed information about the workers will be logged to the console, which we can see below.</p> <pre><code>[2025-04-26 23:14:33.329] [MainProcess] [MainThread] [INFO] alsek.core.worker._helpers: Monitoring 1 tasks\n[2025-04-26 23:14:33.329] [MainProcess] [MainThread] [INFO] alsek.core.worker.thread: Starting thread-based worker pool with up to 88 workers (8 max threads and 11 max processes)...\n[2025-04-26 23:14:33.329] [MainProcess] [MainThread] [INFO] alsek.core.worker._base: Monitoring 1 queue(s).\n[2025-04-26 23:14:33.329] [MainProcess] [MainThread] [INFO] alsek.core.worker._base: Worker pool online.\n[2025-04-26 23:14:33.426] [Process-1] [Thread-2 (_wrapper)] [INFO] alsek.core.futures: Received Message(uuid='cb3b106a-2314-11f0-b7d7-4af50920870b', queue='math_ops', task='add')...\n[2025-04-26 23:14:33.427] [Process-1] [Thread-2 (_wrapper)] [INFO] alsek.core.futures: Successfully processed Message(uuid='cb3b106a-2314-11f0-b7d7-4af50920870b', queue='math_ops', task='add').\n[2025-04-26 23:14:33.427] [Process-1] [Thread-2 (_wrapper)] [INFO] alsek.core.broker: Removing Message(uuid='cb3b106a-2314-11f0-b7d7-4af50920870b', queue='math_ops', task='add')...\n[2025-04-26 23:14:33.428] [Process-1] [Thread-2 (_wrapper)] [INFO] alsek.core.broker: Removed Message(uuid='cb3b106a-2314-11f0-b7d7-4af50920870b', queue='math_ops', task='add').\n</code></pre> <p>Above we can see that once the worker pool booted up, a worker consumed the  message we created above and then processed it successfully.</p>"},{"location":"#alsek_1","title":"Alsek?","text":"<p>This library is named after the Tatshenshini-Alsek Park and UNESCO World Heritage Site in northern British Columbia, Canada.</p>"},{"location":"guided_tour/","title":"Guided tour","text":"<p>from alsek.storage.backends.redis import AsyncRedisBackend</p>"},{"location":"guided_tour/#guided-tour","title":"Guided Tour \ud83e\udd7e","text":"<p>This document provides a guided tour of Alsek.  Please feel free to feed the functions. \ud83d\ude42</p>"},{"location":"guided_tour/#backends","title":"Backends","text":"<p>Alsek currently provides 'out of the box' support for <code>Redis</code>.</p>"},{"location":"guided_tour/#redis","title":"Redis","text":""},{"location":"guided_tour/#synchronous","title":"Synchronous","text":"<pre><code>from alsek.storage.backends.redis import RedisBackend\n\n# Note: by default, `RedisBackend()` will attempt to \n# connect to an instance of Redis running on localhost.\nbackend = RedisBackend()\n</code></pre>"},{"location":"guided_tour/#asynchronous","title":"Asynchronous","text":"<pre><code>from alsek.storage.backends.redis import AsyncRedisBackend\n\n# Note: by default, `AsyncRedisBackend()` will attempt to \n# connect to an instance of Redis running on localhost.\nasync_backend = AsyncRedisBackend()\n</code></pre> <p>Warning</p> <p>Currently, not all parts of Avalis support asynchronous backends.</p>"},{"location":"guided_tour/#lazy-initialization","title":"Lazy Initialization","text":"<p>The <code>RedisBackend</code> supports lazy initialization. In this mode, an attempt to establish a connection with the database will be  deferred until the first time it is absolutely needed (e.g., for a <code>SET</code>, <code>GET</code>,  <code>DELETE</code>, etc.). This can be useful in applications such as REST APIs where the  backend may not be available precisely when the application boots up. A small example  of this mode is provided below.</p> <pre><code>from redis import Redis\nfrom alsek.storage.backends.lazy import LazyClient\nfrom alsek.storage.backends.redis import RedisBackend\n\n# Initialize the backend with LazyClient\nlazy_backend = RedisBackend(LazyClient(lambda: Redis()))\n\n# Run an operation. \n# This will cause LazyClient to evaluate the\n# lambda and return a usable client connection.\nlazy_backend.count(\"queues:math_ops\")\n</code></pre>"},{"location":"guided_tour/#namespaces","title":"Namespaces","text":"<p>Backends store all of their data in a predefined namespace. This is simply a prefix that will be prepended to all \"keys\" (names)  the backend writes to storage.</p>"},{"location":"guided_tour/#serializers","title":"Serializers","text":"<p>Prior to being written into the backend, Alsek requires that data is first serialized. When data is read from the backend, it is deserialized prior to use.</p> <p>By default, Alsek uses JSON serialization, as implemented in  <code>alsek.storage.serialization.JsonSerializer()</code>. However, another  approach can be used, provided it is supported by the backend. To use a different serialization procedure, one must:</p> <ul> <li> <p>create a new from serializer on top of the base <code>Serializer()</code> and </p> </li> <li> <p>pass the new serializer to the relevant backend at initialization time.</p> </li> </ul>"},{"location":"guided_tour/#messages","title":"Messages","text":"<p>Messages are the \"lingua franca\" of Alsek. This is because the data they  contain can be \"understood\" by all parts of the library from brokers and  result stores, to tasks and worker pools.</p>"},{"location":"guided_tour/#properties","title":"Properties","text":"<p>Messages have a lot of helpful functionality, the most notable of which is explored here.</p> <pre><code>from alsek import Broker, task\nfrom alsek.storage.backends.redis.standard import RedisBackend\n\nbroker = Broker(RedisBackend())\n\n@task(broker)\ndef simple_task() -&gt; int:\n    return 99\n\nmessage = simple_task.generate()\n</code></pre> <p>First, let's print the message:</p> <pre><code>from alsek import Message\n\nMessage(\n    task_name='simple_task',\n    queue='alsek_queue',\n    args=(),\n    kwargs={},\n    metadata=None,\n    exception_details=None,\n    result_ttl=None,\n    uuid='67de0e4c-9816-11eb-8cb0-acde48001122',\n    progenitor_uuid=None,\n    retries=0,\n    timeout=3600000,\n    created_at='2021-04-08 05:59:16.424000',\n    updated_at='2021-04-08 05:59:16.424000',\n    delay=0,\n    previous_result=None,\n    previous_message_uuid=None,\n    callback_message_data=None,\n    backoff_settings={'algorithm': 'ExponentialBackoff', 'parameters': {'base': 4, 'factor': 10000, 'floor': 60000, 'ceiling': 3600000, 'zero_override': True}},\n    mechanism='thread',\n)\n</code></pre> <p>Next, we can take a quick look at the key properties of the <code>message</code> object.</p> <pre><code># Dictionary containing all of the data that can be,\n# and will be, persisted to the backend by the broker.\nmessage.data\n# Output: {'task_name': 'simple_task', ...}\n\n# High-level summary of the message\nmessage.summary\n# Output: Message(uuid='67de0e4c-9816-11eb-8cb0-acde48001122', queue='alsek_queue', task='simple_task')\n\n# UTC Timestamp for when the message will next be ready for processing \nmessage.ready_at\n# Output: 1617861556424\n\n# Time until the message is ready for processing\nmessage.ttr\n# Output: 0\n\n# UUIDs which have descended or will descend from this message\nmessage.descendant_uuids\n# Output: None\n\n# Whether the message is ready for processing\nmessage.ready\n# Output: True\n</code></pre>"},{"location":"guided_tour/#brokers","title":"Brokers","text":"<p>A message broker is responsible for adding and managing tasks on the backend. In Alsek, the <code>Broker</code> class provides the following main methods:</p> <ul> <li><code>exists()</code>: whether a message exists on the backend</li> <li><code>sumbit()</code>: submit a message to a queue</li> <li><code>retry()</code>: retry a message on a queue</li> <li><code>remove()</code>: remove a message from the backend</li> <li><code>fail()</code>: remove a message, and move it to the Dead Letter Queue (DQL), if enabled</li> </ul> <p>Notably, <code>Broker</code> also exposes:</p> <ul> <li><code>ack()</code>: acknowledge the message. (This is a convenience method and is      functionally the same as <code>remove()</code>.)</li> </ul>"},{"location":"guided_tour/#tasks","title":"Tasks","text":"<p>In this section we will take a closer look at the capabilities of Alsek tasks.</p> <p>Note</p> <p>The original behaviour of a function is conserved after it has been decorated with <code>task</code>. This is illustrated in the example below.</p> <pre><code>from alsek import task\n\n@task(...)\ndef add(a: int, b: int) -&gt; int:\n    return a + b\n\nassert add(1, b=1) == 2  # True\n</code></pre>"},{"location":"guided_tour/#mechanisms","title":"Mechanisms","text":"<p>Tasks can be executed on a Worker Pool using either a <code>'thread'</code> or <code>'process'</code> mechanism. We can specify which mechanism the worker pool should use when we construct the task.</p> <pre><code>from alsek import task\n\n@task(..., mechanism=\"thread\")\ndef my_task() -&gt; int:\n    return 99\n</code></pre> <p>While the default mechanism is <code>'process'</code>, threads can be used in cases where  lower overhead is desirable, or the task in question is largely I/O bound.  </p> <p>Danger</p> <p>Many implementations of Python use a Global Interpreter Lock (GIL), including the most common one: CPython. In such implementations,  only one thread can do work at any one time within any given Python process. As a consequence, using  <code>mechanism=\"thread\"</code> carries the risk of interfering with the threads used by the Worker Pool itself (see below).  In the worst case, a task specified with <code>mechanism=\"thread\"</code> may never relinquish the GIL and, as a result, the  process in which that thread will cease to function (along with any other tasks running in threads in that process).</p> <p>While this problem is relatively uncommon in practice, it is an important risk  to keep in mind when building your application.</p>"},{"location":"guided_tour/#timeouts","title":"Timeouts","text":"<p>All Alsek tasks must include a <code>timeout</code> (in milliseconds), which is used to  safeguard against hanging tasks. The default timeout is 3,600,000 milliseconds (1 hour).</p> <p>Tasks which exceed their timeout will be shutdown by the worker pool. If a task is eligible to be retried (see below) against a <code>TimeoutError</code>, it will be. Otherwise, the corresponding message will be failed and deleted.</p> <pre><code>from alsek import task\n\n@task(..., timeout=90 * 1000)  # lower timeout to 90 seconds\ndef my_task() -&gt; int:\n    return 99\n</code></pre> <p>Warning</p> <p>Enforcement of timeouts for tasks which use <code>mechanism='thread'</code> is only available for CPython (see below).</p> <p>Warning</p> <p>Timeout enforcement for tasks which use <code>mechanism='thread'</code> is not as reliable as it is for tasks which use <code>mechanism='process'</code>. This is because Alsek effectuates timeouts in  thread tasks by asynchronously setting a <code>TimeoutError</code> inside them. In order for this error  to be raised, the thread in question must first acquire the GIL (see above). If the thread never acquires the GIL, the error will never be raised. Conversely, Alsek implements timeouts for process tasks by directly terminating them, which is generally extremely reliable. The reasons for this dichotomy are beyond Alsek's control and stem from the implementation details of CPython itself.</p> <p>As above, while this problem is relatively uncommon in practice, it is an important risk  to keep in mind when building your application.</p>"},{"location":"guided_tour/#priority","title":"Priority","text":"<p>As with timeouts, priority values can be set for each message.</p> <p>Let's take a look at an example.</p> <pre><code>from alsek import task\n\n@task(..., queue=\"my_queue\")\ndef task_a() -&gt; str:\n    return \"A!\"\n\nmessage_1 = task_a.generate(priority=1)\nmessage_2 = task_a.generate(priority=0)\n</code></pre> <p>In Alsek, <code>priority</code> is inverted. That is, lower integers correspond to higher priority. Thus, in the example above, <code>message_2</code> will take priority over <code>message_1</code>.</p> <p>Note</p> <p>Alsek implements intra-queue message priority. In other words, priority  is enforced within, but not between, queues (which themselves can be prioritized).</p>"},{"location":"guided_tour/#triggers","title":"Triggers","text":"<p>Alsek supports cron, date as well as interval triggers. Let's explore this using the example below.</p> <pre><code>from alsek import Broker, task\nfrom alsek.storage.backends.redis.standard import RedisBackend\nfrom apscheduler.triggers.interval import IntervalTrigger\n\nbroker = Broker(RedisBackend())\n\n@task(broker, trigger=IntervalTrigger(hours=1))\ndef check_system_usage() -&gt; int:\n    return 99\n</code></pre> <p>The result will be a special of a type: <code>TriggerTask</code>. Like <code>Task</code>, we can generate an instance of the task by calling <code>generate()</code>.</p> <pre><code>message = check_system_usage.generate()\n</code></pre> <p>The task will now be submitted to the broker every hour for as long  as the Python process in which it was created is alive.</p> <p>There are three main ways we can interrupt these kinds of tasks.</p> <p>First, we can pause the scheduler:</p> <pre><code>check_resource_usage.pause()\n</code></pre> <p>(Note that this can be undone by running <code>check_resource_usage.resume()</code>.)</p> <p>Second, we can clear the scheduled task:</p> <pre><code>check_resource_usage.clear()\n</code></pre> <p>Finally, we can shut down the underlying scheduler:</p> <pre><code>check_resource_usage.shutdown()\n</code></pre> <p>Warning</p> <p>Function parameters are not permitted for tasks which use a trigger.</p>"},{"location":"guided_tour/#message-passing","title":"Message Passing","text":"<p>The message itself will be passed to <code>task</code>s which include a <code>message</code> parameter. </p> <pre><code>from alsek import Broker, Message, task\nfrom alsek.storage.backends.redis.standard import RedisBackend\n\nbroker = Broker(RedisBackend())\n\n@task(broker)\ndef my_task(message: Message) -&gt; None:  # note: type hints are optional\n    print(message.uuid)\n</code></pre> <p>Warning</p> <p>The message will not be passed to the task if:</p> <ul> <li>a \"message\" key is included in <code>kwargs</code>, e.g., <code>my_task.generate(kwargs={\"message\": \"string\"})</code></li> <li>a type hint that does not resolve to <code>Message</code> is used for <code>message</code>.</li> </ul>"},{"location":"guided_tour/#callbacks","title":"Callbacks","text":"<p>When a task completes, another task can be automatically triggered through the use of a callback.</p> <p>To see this, let's contrive two simple tasks: <code>add_1()</code> and <code>print_result()</code>:</p> <pre><code>from alsek import Broker, Message, task\nfrom alsek.storage.backends.redis.standard import RedisBackend\n\nbroker = Broker(RedisBackend())\n\n@task(broker)\ndef add_1(number: int) -&gt; int:\n    return number + 1\n\n@task(broker)\ndef print_result(message: Message) -&gt; None:\n    print(message.previous_result)\n</code></pre> <p>In order to make <code>print_result()</code> execute when <code>add_1()</code> completes, we simply need to pass a generated message to <code>callback</code>. It's also advisable to set <code>submit=False</code> so that submission to the broker is  deferred until after the first message completes.</p> <pre><code>add_1.generate(\n    args=(1,),\n    callback=print_result.generate(submit=False)\n)\n</code></pre> <p>As a convenience, we can also use deferred mode, which instructs the next call of <code>generate()</code> to skip submitting the message to the broker.</p> <pre><code>add_1.generate(\n    args=(1,),\n    callback=print_result.defer().generate()\n)\n</code></pre>"},{"location":"guided_tour/#nested","title":"Nested","text":"<p>Callbacks of arbitrary depth are also supported.</p> <p>To see this, let's add another task into the mix.</p> <pre><code>@task(broker)\ndef add_1_previous(message: Message) -&gt; int:\n    return message.previous_result + 1\n</code></pre> <pre><code>add_1.generate(\n    args=(1,),\n    callback=(\n        add_1_previous.defer().generate(\n            callback=add_1_previous.defer().generate(\n                callback=add_1_previous.defer().generate(\n                    callback=print_result.defer().generate()\n                )\n            ),\n        )\n    ),\n)\n</code></pre> <p>While the code above will \"work\", it is very difficult to read.  A better solution is to use a <code>tuple</code> of messages.</p> <pre><code>add_1.generate(\n    args=(1,),\n    callback=(\n        add_1_previous.defer().generate(),\n        add_1_previous.defer().generate(),\n        add_1_previous.defer().generate(),\n        print_result.defer().generate()\n    ),\n)\n</code></pre> <p>Internally, a message nesting procedure will be run against the tuple passed to <code>callback</code>. As a result, the two different approaches to multiple callbacks shown above are functionally  identical.</p> <p>Note</p> <p>The internal process described above for nesting a flat tuple of callbacks will update the <code>callback_message_data</code>  fields in the original messages.</p> <p>Note</p> <p>Deferred mode is automatically cancelled by <code>generate()</code> prior to it returning.</p> <p>Note</p> <p>The progenitor for a callback message is considered to be the root callback.  </p> <p>Warning</p> <p>Each callback message's <code>previous_result</code> and <code>progenitor_uuid</code> fields  will be set on the worker pool after successful execution of the  previous message, and are not available prior to this.</p> <p>Danger</p> <p>While it is valid for a task with a trigger to have callbacks, callbacks should not include tasks with triggers.</p>"},{"location":"guided_tour/#control","title":"Control","text":"<p>If a callback is present for a message it will be executed by default. However, it is possible to override this behaviour by reasoning about the original message itself, the result of the task or both. </p> <pre><code>from typing import Any\n\nfrom alsek import Message\nfrom alsek.core.task import Task, task\n\nclass CustomTask1(Task):\n    def do_callback(self, message: Message, result: Any) -&gt; bool:\n        if result &gt; 1:\n            return True\n        else:\n            return False\n\n@task(..., base_task=CustomTask1)\ndef simple_task() -&gt; int:\n    return 99\n</code></pre> <p>Warning</p> <p>The <code>do_callback()</code> method is only evaluated for messages which contain a callback.</p>"},{"location":"guided_tour/#prepost-ops","title":"Pre/Post Ops","text":"<p>The <code>pre_op()</code> and <code>post_op()</code> methods of <code>Task</code> can be used to  perform operations before and/or after the <code>function</code> itself executes, respectively. To do this, a new <code>base_task</code> must be created.</p> <pre><code>from alsek import Message\nfrom alsek.core.task import Task, task\n\nclass CustomTask2(Task):\n    def pre_op(self, message: Message) -&gt; None:\n        print(f\"About to process {message.summary}!\")\n\n    def post_op(self, message: Message, result: Any) -&gt; None:\n        print(f\"Processed {message.summary} and got '{result}'!\")\n\n\n@task(..., base_task=CustomTask2)\ndef simple_task() -&gt; int:\n    return 99\n</code></pre>"},{"location":"guided_tour/#retries","title":"Retries","text":"<p>The number of times a task will be retried is determined by <code>max_retries</code> by default. In cases where this is not sufficiently  sophisticated to determine if message should be retried, the <code>do_retry()</code>  method of the <code>Task</code> class can be overridden.</p> <pre><code>from alsek import Message\nfrom alsek.core.task import Task, task\n\nclass CustomTask3(Task):\n    def do_retry(self, message: Message, exception: BaseException) -&gt; bool:\n        if isinstance(exception, ZeroDivisionError):\n            return False\n        elif self.max_retries is None:\n            return True\n        else:\n            return message.retries &lt; self.max_retries\n\n@task(..., base_task=CustomTask3)\ndef simple_task() -&gt; int:\n    return 99\n</code></pre>"},{"location":"guided_tour/#backoff","title":"Backoff","text":"<p>Rather than reprocessing a task immediately after it fails, Alsek uses a backoff procedure. By default, <code>ExponentialBackoff()</code>  is used with \"sensible\" defaults. However, the type of backoff algorithm  as well as its parameters are extremely customizable. </p> <pre><code>from alsek import task\nfrom alsek.core.backoff import (\n    ConstantBackoff, \n    ExponentialBackoff,\n    LinearBackoff, \n)\n\n@task(..., backoff=ConstantBackoff(constant=30 * 1000))\ndef task_a() -&gt; int:\n    return 99\n\n@task(..., backoff=LinearBackoff(factor=30 * 1000))\ndef task_b() -&gt; int:\n    return 99\n\n@task(..., backoff=ExponentialBackoff(ceiling=90 * 1000))\ndef task_c() -&gt; int:\n    return 99\n</code></pre> <p>Note</p> <p>Backoff duration is determined by the number of 'incidents'. Here, an incident is a failed attempt to process the message.</p> <p>Note</p> <p>Setting <code>backoff=None</code> is functionally equivalent to  <code>ConstantBackoff(constant=0, floor=0, ceiling=0, zero_override=True)</code>.</p>"},{"location":"guided_tour/#status-tracking","title":"Status Tracking","text":"<p>The status of tasks can be tracked using <code>StatusTracker()</code>.</p> <pre><code>from alsek import Broker, StatusTracker, task\nfrom alsek.storage.backends.redis import RedisBackend\n\nbackend = RedisBackend(\"&lt;connection_url&gt;\")\n\nbroker = Broker(backend)\nstatus_tracker = StatusTracker(backend)\n\n@task(broker, status_tracker=status_tracker)\ndef sum_n(n: int) -&gt; int:\n    return int(n * (n + 1) / 2)\n\nmessage = sum_n.generate(kwargs={\"n\": 100})\n</code></pre> <p>The status can be checked using <code>.get()</code>:</p> <pre><code>status_tracker.get(message)\n</code></pre> <p>and can be any one of the following:</p> <ul> <li><code>&lt;TaskStatus.UNKNOWN: 0&gt;</code></li> <li><code>&lt;TaskStatus.SUBMITTED: 1&gt;</code></li> <li><code>&lt;TaskStatus.RUNNING: 2&gt;</code></li> <li><code>&lt;TaskStatus.RETRYING: 3&gt;</code></li> <li><code>&lt;TaskStatus.FAILED: 4&gt;</code></li> <li><code>&lt;TaskStatus.SUCCEEDED: 5&gt;</code></li> </ul> <p>Note</p> <p><code>StatusTracker()</code> can be paired with <code>StatusTrackerIntegryScanner()</code>, which will periodically scan for message statuses which have become invalid. Specifically,  a scan will be performed to check for messages with statuses which are non-terminal (i.e., not  <code>TaskStatus.FAILED</code> or <code>TaskStatus.SUCCEEDED</code>) and no longer exist in the broker. Any messages meeting these criteria will have their status updated to <code>TaskStatus.UNKNOWN</code>.  Status information can become corrupt in  this way in cases where a worker pool is unable to update the message status  before exiting (i.e., in the event of an ungraceful shutdown) and the message is never subsequently retried.</p> <p>The frequency of status integrity scans can be changed by altering the <code>trigger</code> parameter of <code>StatusTrackerIntegryScanner()</code>..</p>"},{"location":"guided_tour/#asynchronous-status-tracking","title":"Asynchronous Status Tracking","text":"<p>An asynchronous status tracker is also available, <code>AsyncStatusTracker()</code>.</p> <pre><code>from alsek.storage.backends.redis.asyncio import AsyncRedisBackend\nfrom alsek.core.status.asyncio import AsyncStatusTracker\n\nbackend = AsyncRedisBackend(\"&lt;connection_url&gt;\")\nstatus_tracker = AsyncStatusTracker(backend)\n...\n</code></pre> <p>Warning</p> <p>Currently, the <code>Task()</code> class, used by the <code>task()</code> decorator by default, does not support     instances of <code>AsyncStatusTracker()</code> and will raise an error if one is provided to it.</p>"},{"location":"guided_tour/#result-storage","title":"Result Storage","text":"<p>Task results can be persisted to a <code>backend</code> using <code>ResultStore()</code>. </p> <pre><code>from typing import Dict\n\nfrom alsek import Broker, task\nfrom alsek.storage.backends.redis import RedisBackend\nfrom alsek.storage.result import ResultStore\n\nbackend = RedisBackend(\"&lt;connection_url&gt;\")\n\nbroker = Broker(backend)\nresult_store = ResultStore(backend)\n\n@task(broker, result_store=result_store)\ndef valuable_output() -&gt; Dict[str, int]:\n    return {\"a\": 1, \"b\": 2, \"c\": 3}\n</code></pre> <p>Warning</p> <p>In order for data to be persisted via <code>result_store</code>, it must be of a type supported by the <code>backend</code>'s <code>serializer</code>.</p> <p>Warning</p> <p>By default, results are automatically deleted once they are fetched.  To disable this behavior, set <code>keep=True</code> when invoking <code>get()</code>.</p>"},{"location":"guided_tour/#triggers-result-storage","title":"Triggers &amp; Result Storage","text":"<p>We can request result storage for tasks with triggers, just as we did with a standard task above.  However, fetching the results of a task requires us to know its <code>uuid</code>. While it is possible to collect this information (e.g., via <code>pre_op()</code> or <code>post_op()</code>), it is often far easier to  simply store the progenitor message or, at the least, its <code>uuid</code>. With this information,  we can obtain all descendant messages.</p> <pre><code>from random import randint\nfrom apscheduler.triggers.interval import IntervalTrigger\n\nfrom alsek import Broker, task\nfrom alsek.storage.backends.redis.standard import RedisBackend\nfrom alsek.storage.result import ResultStore\n\nbackend = RedisBackend()\nbroker = Broker(backend)\nresult_storage = ResultStore(backend)\n\n\n@task(broker, result_store=result_storage, trigger=IntervalTrigger(seconds=10))\ndef harvest_data() -&gt; int:\n    data = randint(0, 100)\n    return data\n\n# Start \nmessage = harvest_data.generate()\n\n# Get all of the results as a list. By setting `descendants=True` we\n# will also data for any descendant messages which have completed.\nresults = result_storage.get(message, timeout=30 * 1000, descendants=True)\n\nprint(results)\n# [3, 5, 88, ...]\n</code></pre> <p>Note</p> <p>Metadata for each result can be included by specifying <code>with_metadata=True</code>.</p> <p>Warning</p> <p>The order of results when <code>descendants=True</code> is determined by the  time at which the data was written to the backend, not when the corresponding task  completed. While this difference is usually very small, if this is not appropriate for your application, you must include timestamp information  in the output of the task function and re-sort the results accordingly.</p>"},{"location":"guided_tour/#result-iteration","title":"Result Iteration","text":"<p>The <code>ResultPool()</code> class provides an intuitive means of iterating over  stored results. To see how, we can define a task, just as we have done  several times before, and create an instance of the <code>ResultPool()</code> class.</p> <pre><code>from alsek import Broker, task\nfrom alsek.storage.backends.redis import RedisBackend\nfrom alsek.storage.result import ResultStore\nfrom alsek.tools import ResultPool\n\nbackend = RedisBackend(\"&lt;connection_url&gt;\")\n\nbroker = Broker(backend)\nresult_store = ResultStore(backend)\nresult_pool = ResultPool(result_store)\n\n@task(broker, result_store=result_store)\ndef sum_n(n: int) -&gt; int:\n    return int(n * (n + 1) / 2)\n</code></pre> <p>From here we can use the <code>istream()</code> method of <code>result_pool</code> to  iterate over message results as they become available.</p> <pre><code>for message, result in result_pool.istream(\n    sum_n.generate(kwargs=dict(n=10)),\n    sum_n.generate(kwargs=dict(n=100)),\n    sum_n.generate(kwargs=dict(n=1000)),\n    descendants=False,  # enable if any messages contain callbacks\n):\n    print(f\"The result of message '{message.uuid}' is {result}.\")\n</code></pre> <p>Result pools can be used in applications, or for interactive distributed computing.</p> <p>Note</p> <p>If your use case requires a guarantee that results will be yielded  in the same order in which the messages were provided, use the <code>stream()</code>  method instead.</p>"},{"location":"guided_tour/#concurrency","title":"Concurrency","text":"<p>Alsek's concurrency <code>Lock()</code> provides a straightforward way limit  simultaneity across a distributed application to a single task, as shown here:</p> <pre><code>from alsek import Lock, task\nfrom alsek.storage.backends.redis.standard import RedisBackend\n\nbackend = RedisBackend()\n\n@task(...)\ndef send_data() -&gt; None:\n    with Lock(\"send_data\", backend=backend) as lock:\n        if lock.acquire(strict=False):\n            print(\"Sending data...\")\n        else:\n            print(\"Failed to acquire lock\")\n</code></pre>"},{"location":"guided_tour/#consumers","title":"Consumers","text":"<p>As their name suggests, consumers pull messages inserted by the broker onto workers. A concurrency lock (similar to what is shown above) is used to ensure than one, and only one, consumer can hold a message at any given time.</p> <p>Standard use of Alsek does not typically entail direct interaction with consumers, as they are managed by Worker Pools (see below). However, in the interest  of completeness, an illustrative example of working with consumers is provided below.</p> <pre><code>from alsek import Broker\nfrom alsek.core.consumer import Consumer\nfrom alsek.storage.backends.redis import RedisBackend\n\nbroker = Broker(RedisBackend())\nconsumer = Consumer(broker)\n\nfor message in consumer.stream():\n    print(f\"Got {message.summary}\")\n</code></pre> <p>Note</p> <p>Consumers backoff following one or more passes over the backend that  do not yield any ready messages. By default, <code>LinearBackoff()</code> is used.</p>"},{"location":"guided_tour/#worker-pools","title":"Worker Pools","text":"<p>Alsek provides two distinct worker pool implementations for processing tasks: <code>ThreadWorkerPool</code> and <code>ProcessWorkerPool</code>. Each offers different performance characteristics and scaling capabilities.</p>"},{"location":"guided_tour/#thread-worker-pool","title":"Thread Worker Pool","text":"<p>The <code>ThreadWorkerPool</code> uses a hierarchical architecture with process groups that each manage multiple threads:</p> <pre><code>from alsek import Broker\nfrom alsek.core.worker.thread import ThreadWorkerPool\nfrom alsek.storage.backends.redis import RedisBackend\n\nbackend = RedisBackend()\nbroker = Broker(backend)\n\npool = ThreadWorkerPool(\n    tasks=[task_a, task_b],  # tasks to process\n    n_threads=8,             # threads per process group\n    n_processes=4,           # maximum number of process groups\n)\npool.run()\n</code></pre> <p>Key features of the <code>ThreadWorkerPool</code>:</p> <ul> <li>Elastic Scaling: Automatically creates new process groups as needed and prunes them when they're no longer required</li> <li>Hierarchical Design: Each process group manages its own set of threads</li> <li>Total Capacity: The maximum number of concurrent tasks is <code>n_threads \u00d7 n_processes</code></li> <li>Resource Efficiency: Ideal for I/O-bound tasks or when lower overhead is desired</li> </ul> <p>The <code>ThreadWorkerPool</code> will dynamically scale up to <code>n_processes</code> process groups, each managing up to <code>n_threads</code> threads, for a maximum capacity of <code>n_threads \u00d7 n_processes</code>. When a message needs to be processed, it is assigned to an available process group, which then executes it on one of its threads.</p>"},{"location":"guided_tour/#process-worker-pool","title":"Process Worker Pool","text":"<p>The <code>ProcessWorkerPool</code> uses a direct approach where each task runs in its own dedicated process:</p> <pre><code>from alsek import Broker\nfrom alsek.core.worker.process import ProcessWorkerPool\nfrom alsek.storage.backends.redis import RedisBackend\n\nbackend = RedisBackend()\nbroker = Broker(backend)\n\npool = ProcessWorkerPool(\n    tasks=[task_a, task_b],  # tasks to process\n    n_processes=4,           # maximum number of processes\n    prune_interval=100,      # milliseconds between prune scans\n)\npool.run()\n</code></pre> <p>Key features of the <code>ProcessWorkerPool</code>:</p> <ul> <li>Process Isolation: Each task runs in its own dedicated process</li> <li>Fixed Capacity: Limited to a maximum of <code>n_processes</code> concurrent tasks</li> <li>Background Pruning: Uses a background scheduler to periodically prune spent futures</li> <li>Resource Safety: Ideal for CPU-bound tasks or when process isolation is necessary</li> </ul> <p>The <code>ProcessWorkerPool</code> will execute each task in its own dedicated process, up to the maximum of <code>n_processes</code> concurrent processes. This offers stronger isolation between tasks but with slightly higher overhead compared to threads.</p>"},{"location":"guided_tour/#performance-considerations","title":"Performance Considerations","text":"<p>When choosing between worker pool types, consider:</p> <ol> <li> <p>I/O vs CPU Bound Tasks: For I/O-bound tasks (e.g., network requests, database operations), <code>ThreadWorkerPool</code> often offers better performance. For CPU-bound tasks, <code>ProcessWorkerPool</code> can better utilize multiple cores.</p> </li> <li> <p>Memory Usage: <code>ThreadWorkerPool</code> is typically more memory-efficient as threads share memory within their process group.</p> </li> <li> <p>Isolation Needs: If tasks need strong isolation from each other, <code>ProcessWorkerPool</code> provides better separation.</p> </li> <li> <p>Elasticity: If your workload has variable demand, <code>ThreadWorkerPool</code>'s elastic scaling may be more efficient.</p> </li> <li> <p>Shutdown Reliability: <code>ProcessWorkerPool</code> offers more robust shutdown logic since it can directly terminate processes, avoiding potential GIL-related issues where a thread might never relinquish control and prevent proper shutdown (see above).</p> </li> </ol> <p>Note</p> <p>Both worker pool types use timeouts to manage hanging tasks and provide similar retry and backoff capabilities.</p> <p>Warning</p> <p>For tasks using <code>mechanism='thread'</code>, be aware of Python's Global Interpreter Lock (GIL) which can limit true parallelism within a single process group.</p>"},{"location":"guided_tour/#cli","title":"CLI","text":"<p>Alsek's command line interface (CLI) provides an easy way to bring a pool of workers online to process tasks for which we can provide the definition. </p> <p>Alsek offers two types of worker pools:</p> <ul> <li><code>thread-pool</code>: Uses a hierarchical architecture with process groups that each manage multiple threads</li> <li><code>process-pool</code>: Uses a direct approach where each task runs in its own process</li> </ul> <p>Each worker pool relies on a <code>Consumer</code> to pull messages written to the backend by the <code>Broker</code>.  When the worker pool reaches capacity, it will pause the stream of data from the consumer.  This is done to both reduce load on the backend and to allow other worker pools (perhaps  running on different machines) to acquire messages for processing.</p>"},{"location":"guided_tour/#basics","title":"Basics","text":"<p>The CLI requires that we inform it where tasks can be found.</p> <p>To start with a simple case, let's imagine our one and only task is located in the current working directory in a file titled <code>my_task.py</code>. </p> <p>Then, starting a worker pool against this task can be accomplished by running:</p> <pre><code># For a process-based worker pool\nalsek process-pool my_tasks\n\n# For a thread-based worker pool\nalsek thread-pool my_tasks\n</code></pre>"},{"location":"guided_tour/#nested-files","title":"Nested files","text":"<p>Alternatively, we might have a file of task definitions inside a directory, like this:</p> <pre><code>my_project\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 singletons.py\n    \u2514\u2500\u2500 my_tasks.py\n</code></pre> <p>Starting a pool with this kind of structure can be accomplished by passing the dot-separated \"path\" to the file: </p> <pre><code>alsek process-pool my_project.my_tasks\n</code></pre>"},{"location":"guided_tour/#recursive","title":"Recursive","text":"<p>We can also simply specify the directory where the task definitions live,  and it will be scanned recursively in order to recover all task definitions.</p> <pre><code>alsek thread-pool my_project\n</code></pre>"},{"location":"guided_tour/#advanced-options","title":"Advanced options","text":"<p>Alsek's CLI includes several dials to achieve fine-grain control over the worker pool. We won't cover all of them here, but there are at least a few worth highlighting.</p>"},{"location":"guided_tour/#queue-selection","title":"Queue Selection","text":"<p>The <code>-qu</code>/<code>--queues</code> option allows you to limit the queues which will be consumed by the worker pool.  It can be set using a comma-separated list.</p> <pre><code>alsek process-pool my_project -qu queue_a\n</code></pre> <pre><code>alsek thread-pool my_project -qu queue_a,queue_b,queue_z\n</code></pre>"},{"location":"guided_tour/#worker-capacity","title":"Worker Capacity","text":""},{"location":"guided_tour/#thread-based-worker-pools","title":"Thread-based Worker Pools","text":"<p>For thread-based worker pools, you can control both the number of threads per process group and  the maximum number of process groups:</p> <pre><code># Configure 8 threads per process group\nalsek thread-pool my_project --n_threads 8\n\n# Configure a maximum of 4 process groups\nalsek thread-pool my_project --n_processes 4\n</code></pre> <p>The total maximum capacity of a thread-based worker pool is <code>n_threads \u00d7 n_processes</code>.</p> <p>Thread pools support elastic scaling, automatically creating new process groups up to the configured maximum as needed, and pruning them when no longer needed.</p>"},{"location":"guided_tour/#process-based-worker-pools","title":"Process-based Worker Pools","text":"<p>For process-based worker pools, you can control the maximum number of concurrent processes:</p> <pre><code># Configure a maximum of 4 processes\nalsek process-pool my_project --n_processes 4\n</code></pre>"},{"location":"guided_tour/#performance-tuning","title":"Performance Tuning","text":"<p>Both worker pool types support additional performance tuning options:</p> <pre><code># Configure slot wait interval (milliseconds to wait when pool is full)\nalsek thread-pool my_project --slot_wait_interval 50\n\n# For process-based worker pools, configure prune interval\nalsek process-pool my_project --prune_interval 100\n\n# For thread-based worker pools, wait for thread exit to mark as complete\nalsek thread-pool my_project --complete_only_on_thread_exit\n</code></pre> <p>Note</p> <p>The worker pool's <code>Consumer</code> will respect the order in which queues are listed for the <code>-qu</code>/<code>--queues</code> option. If, this option is not specified,  queues will be consumed in alphabetical order.</p> <p>Note</p> <p>Worker pools scale up and down dynamically based on load.</p> <p>Note</p> <p>The full documentation for Alsek's CLI can be obtained by running:</p> <pre><code>alsek --help\n</code></pre> <p>Warning</p> <p>If a worker pool encounters a message which refers to an unknown  task, an error will be logged and the message will be failed.</p>"},{"location":"reference/","title":"Reference \ud83d\udcda","text":""},{"location":"reference/#alsek","title":"<code>alsek</code>","text":"<p>Alsek</p>"},{"location":"reference/#alsek.cli","title":"<code>cli</code>","text":""},{"location":"reference/#alsek.cli.cli","title":"<code>cli</code>","text":"<p>Command Line Interface</p>"},{"location":"reference/#alsek.cli.cli.main","title":"<code>main()</code>","text":"<p>Alsek CLI.</p> Source code in <code>alsek/cli/cli.py</code> <pre><code>@click.group()\n@click.version_option(__version__)\ndef main() -&gt; None:\n    \"\"\"Alsek CLI.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#alsek.cli.cli.process_pool","title":"<code>process_pool(package, queues, task_specific_mode, n_processes, prune_interval, slot_wait_interval, consumer_backoff_factor, consumer_backoff_floor, consumer_backoff_ceiling, log_level)</code>","text":"<p>Start a process-based worker pool.</p> Source code in <code>alsek/cli/cli.py</code> <pre><code>@main.command()\n@click.argument(\"package\", type=str)\n@click.option(\n    \"--queues\",\n    type=str,\n    default=None,\n    help=\"Comma-separated list of queues to consume from.\",\n)\n@click.option(\n    \"--task_specific_mode\",\n    is_flag=True,\n    help=\"Monitor tasks specifically, not just queues.\",\n)\n@click.option(\n    \"--n_processes\",\n    type=int,\n    default=None,\n    help=\"Max number of processes.\",\n)\n@click.option(\n    \"--prune_interval\",\n    type=int,\n    default=100,\n    help=\"Milliseconds between prune scans.\",\n)\n@click.option(\n    \"--slot_wait_interval\",\n    type=int,\n    default=100,\n    help=\"Milliseconds to wait when full.\",\n)\n@click.option(\n    \"--consumer_backoff_factor\",\n    type=int,\n    default=1 * 1000,\n    help=\"Backoff factor in response to passes over the backend \"\n    \"which yield no messages (milliseconds)\",\n)\n@click.option(\n    \"--consumer_backoff_floor\",\n    type=int,\n    default=1_000,\n    help=\"Minimum backoff in response to a pass over the backend\"\n    \"which yields no message (milliseconds)\",\n)\n@click.option(\n    \"--consumer_backoff_ceiling\",\n    type=int,\n    default=30_000,\n    help=\"Maximum backoff in response to a pass over the backend\"\n    \"which yields no message (milliseconds)\",\n)\n@click.option(\n    \"--log-level\",\n    type=click.Choice(LOG_LEVELS, case_sensitive=False),\n    default=\"INFO\",\n    help=\"Logging level.\",\n)\ndef process_pool(\n    package: str,\n    queues: Optional[str],\n    task_specific_mode: bool,\n    n_processes: Optional[int],\n    prune_interval: int,\n    slot_wait_interval: int,\n    consumer_backoff_factor: int,\n    consumer_backoff_floor: int,\n    consumer_backoff_ceiling: int,\n    log_level: str,\n) -&gt; None:\n    \"\"\"Start a process-based worker pool.\"\"\"\n    _apply_logging_level(log_level)\n\n    pool = ProcessWorkerPool(\n        tasks=collect_tasks(package),\n        queues=[q.strip() for q in queues.split(\",\")] if queues else None,\n        task_specific_mode=task_specific_mode,\n        n_processes=n_processes,\n        prune_interval=prune_interval,\n        slot_wait_interval=slot_wait_interval,\n        backoff=LinearBackoff(\n            factor=consumer_backoff_factor,\n            floor=consumer_backoff_floor,\n            ceiling=consumer_backoff_ceiling,\n            zero_override=False,\n        ),\n    )\n    pool.run()\n</code></pre>"},{"location":"reference/#alsek.cli.cli.thread_pool","title":"<code>thread_pool(package, queues, task_specific_mode, n_threads, n_processes, n_process_floor, slot_wait_interval, complete_only_on_thread_exit, consumer_backoff_factor, consumer_backoff_floor, consumer_backoff_ceiling, log_level)</code>","text":"<p>Start a thread-based worker pool.</p> Source code in <code>alsek/cli/cli.py</code> <pre><code>@main.command()\n@click.argument(\"package\", type=str)\n@click.option(\n    \"--queues\",\n    type=str,\n    default=None,\n    help=\"Comma-separated list of queues to consume from.\",\n)\n@click.option(\n    \"--task_specific_mode\",\n    is_flag=True,\n    help=\"Monitor tasks specifically, not just queues.\",\n)\n@click.option(\n    \"--n_threads\",\n    type=int,\n    default=8,\n    help=\"Threads per group.\",\n)\n@click.option(\n    \"--n_processes\",\n    type=int,\n    default=None,\n    help=\"Max process groups.\",\n)\n@click.option(\n    \"--n_process_floor\",\n    type=int,\n    default=1,\n    help=\"Minimum number of process groups to keep alive.\",\n)\n@click.option(\n    \"--slot_wait_interval\",\n    type=int,\n    default=50,\n    help=\"Milliseconds to wait when full.\",\n)\n@click.option(\n    \"--complete_only_on_thread_exit\",\n    is_flag=True,\n    help=\"Wait for thread exit to mark as complete.\",\n)\n@click.option(\n    \"--consumer_backoff_factor\",\n    type=int,\n    default=1 * 1000,\n    help=\"Backoff factor in response to passes over the backend \"\n    \"which yield no messages (milliseconds)\",\n)\n@click.option(\n    \"--consumer_backoff_floor\",\n    type=int,\n    default=1_000,\n    help=\"Minimum backoff in response to a pass over the backend\"\n    \"which yields no message (milliseconds)\",\n)\n@click.option(\n    \"--consumer_backoff_ceiling\",\n    type=int,\n    default=30_000,\n    help=\"Maximum backoff in response to a pass over the backend\"\n    \"which yields no message (milliseconds)\",\n)\n@click.option(\n    \"--log-level\",\n    type=click.Choice(LOG_LEVELS, case_sensitive=False),\n    default=\"INFO\",\n    help=\"Logging level.\",\n)\ndef thread_pool(\n    package: str,\n    queues: Optional[str],\n    task_specific_mode: bool,\n    n_threads: int,\n    n_processes: Optional[int],\n    n_process_floor: int,\n    slot_wait_interval: int,\n    complete_only_on_thread_exit: bool,\n    consumer_backoff_factor: int,\n    consumer_backoff_floor: int,\n    consumer_backoff_ceiling: int,\n    log_level: str,\n) -&gt; None:\n    \"\"\"Start a thread-based worker pool.\"\"\"\n    _apply_logging_level(log_level)\n\n    pool = ThreadWorkerPool(\n        tasks=collect_tasks(package),\n        queues=[q.strip() for q in queues.split(\",\")] if queues else None,\n        task_specific_mode=task_specific_mode,\n        n_threads=n_threads,\n        n_processes=n_processes,\n        n_process_floor=n_process_floor,\n        slot_wait_interval=slot_wait_interval,\n        complete_only_on_thread_exit=complete_only_on_thread_exit,\n        package_name=package,\n        backoff=LinearBackoff(\n            factor=consumer_backoff_factor,\n            floor=consumer_backoff_floor,\n            ceiling=consumer_backoff_ceiling,\n            zero_override=False,\n        ),\n    )\n    pool.run()\n</code></pre>"},{"location":"reference/#alsek.cli.helpers","title":"<code>helpers</code>","text":"<p>Helpers</p>"},{"location":"reference/#alsek.cli.helpers.package2path","title":"<code>package2path(package)</code>","text":"<p>Convert a Python package name into its corresponding filesystem path.</p> Source code in <code>alsek/cli/helpers.py</code> <pre><code>def package2path(package: str) -&gt; Path:\n    \"\"\"Convert a Python package name into its corresponding filesystem path.\"\"\"\n    spec = find_spec(package)\n    if spec is None or spec.origin is None:\n        raise ModuleNotFoundError(f\"Package '{package}' not found.\")\n\n    path = Path(spec.origin)\n    return path.parent if path.name == \"__init__.py\" else path\n</code></pre>"},{"location":"reference/#alsek.core","title":"<code>core</code>","text":"<p>Core</p>"},{"location":"reference/#alsek.core.backoff","title":"<code>backoff</code>","text":"<p>Backoff Algorithms</p>"},{"location":"reference/#alsek.core.backoff.Backoff","title":"<code>Backoff</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base backoff class.</p> <p>Parameters:</p> Name Type Description Default <code>floor</code> <code>int</code> <p>minimum backoff in milliseconds</p> <code>60 * 1000</code> <code>ceiling</code> <code>int</code> <p>maximum backoff in milliseconds</p> <code>60 * 60 * 1000</code> <code>zero_override</code> <code>bool</code> <p>override backoff to zero if the number of <code>incidents</code> is zero.</p> <code>True</code> Source code in <code>alsek/core/backoff.py</code> <pre><code>class Backoff(ABC):\n    \"\"\"Base backoff class.\n\n    Args:\n        floor (int, optional): minimum backoff in milliseconds\n        ceiling (int, optional): maximum backoff in milliseconds\n        zero_override (bool): override backoff to zero if the number\n            of ``incidents`` is zero.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        floor: Optional[int] = 60 * 1000,\n        ceiling: Optional[int] = 60 * 60 * 1000,\n        zero_override: bool = True,\n    ) -&gt; None:\n        self.floor = floor\n        self.ceiling = ceiling\n        self.zero_override = zero_override\n\n        if floor is not None and ceiling is not None:\n            if floor &gt; ceiling:\n                raise ValueError(f\"floor ({floor} greater than ceiling ({ceiling})\")\n            if ceiling &lt; floor:\n                raise ValueError(f\"ceiling ({ceiling}) less than floor ({floor})\")\n\n    @property\n    @abstractmethod\n    def parameters(self) -&gt; dict[str, Optional[int]]:\n        \"\"\"Parameters of the current instance which uniquely\n        characterize it.\n\n        Returns:\n            params (dict): backoff parameters\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def __repr__(self) -&gt; str:\n        return auto_repr(self, **self.parameters)\n\n    @property\n    def settings(self) -&gt; BackoffSettingsType:\n        \"\"\"Settings the current algorithm.\n\n        Returns:\n            serialization (BackoffSettingsType): summary\n                of the current algorithm and parameters with\n                sufficient information to reconstruct it.\n\n        \"\"\"\n        return dict(algorithm=self.__class__.__name__, parameters=self.parameters)\n\n    @abstractmethod\n    def formula(self, incidents: int) -&gt; int:\n        \"\"\"Implementation of the formula for computing the backoff.\n\n        Args:\n            incidents (int): current number of incidents\n\n        Returns:\n            int\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def _clipper(self, amount: int) -&gt; int:\n        if self.floor is not None and amount &lt; self.floor:\n            return self.floor\n        elif self.ceiling is not None and amount &gt; self.ceiling:\n            return self.ceiling\n        else:\n            return amount\n\n    def get(self, incidents: int) -&gt; int:\n        \"\"\"Get the backoff.\n\n        Args:\n            incidents (int): current number of incidents\n\n        Returns:\n            backoff (int): backoff in milliseconds\n\n        \"\"\"\n        if self.zero_override and incidents == 0:\n            return 0\n        return self._clipper(self.formula(incidents))\n</code></pre>"},{"location":"reference/#alsek.core.backoff.Backoff.parameters","title":"<code>parameters</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Parameters of the current instance which uniquely characterize it.</p> <p>Returns:</p> Name Type Description <code>params</code> <code>dict</code> <p>backoff parameters</p>"},{"location":"reference/#alsek.core.backoff.Backoff.settings","title":"<code>settings</code>  <code>property</code>","text":"<p>Settings the current algorithm.</p> <p>Returns:</p> Name Type Description <code>serialization</code> <code>BackoffSettingsType</code> <p>summary of the current algorithm and parameters with sufficient information to reconstruct it.</p>"},{"location":"reference/#alsek.core.backoff.Backoff.formula","title":"<code>formula(incidents)</code>  <code>abstractmethod</code>","text":"<p>Implementation of the formula for computing the backoff.</p> <p>Parameters:</p> Name Type Description Default <code>incidents</code> <code>int</code> <p>current number of incidents</p> required <p>Returns:</p> Type Description <code>int</code> <p>int</p> Source code in <code>alsek/core/backoff.py</code> <pre><code>@abstractmethod\ndef formula(self, incidents: int) -&gt; int:\n    \"\"\"Implementation of the formula for computing the backoff.\n\n    Args:\n        incidents (int): current number of incidents\n\n    Returns:\n        int\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/#alsek.core.backoff.Backoff.get","title":"<code>get(incidents)</code>","text":"<p>Get the backoff.</p> <p>Parameters:</p> Name Type Description Default <code>incidents</code> <code>int</code> <p>current number of incidents</p> required <p>Returns:</p> Name Type Description <code>backoff</code> <code>int</code> <p>backoff in milliseconds</p> Source code in <code>alsek/core/backoff.py</code> <pre><code>def get(self, incidents: int) -&gt; int:\n    \"\"\"Get the backoff.\n\n    Args:\n        incidents (int): current number of incidents\n\n    Returns:\n        backoff (int): backoff in milliseconds\n\n    \"\"\"\n    if self.zero_override and incidents == 0:\n        return 0\n    return self._clipper(self.formula(incidents))\n</code></pre>"},{"location":"reference/#alsek.core.backoff.ConstantBackoff","title":"<code>ConstantBackoff</code>","text":"<p>               Bases: <code>Backoff</code></p> <p>Constant backoff.</p> <p>Parameters:</p> Name Type Description Default <code>constant</code> <code>int</code> <p>amount of time (in milliseconds) to backoff.</p> <code>60 * 1000</code> <code>**kwargs</code> <code>Keyword Args</code> <p>keyword arguments to pass to <code>Backoff</code></p> <code>{}</code> Source code in <code>alsek/core/backoff.py</code> <pre><code>class ConstantBackoff(Backoff):\n    \"\"\"Constant backoff.\n\n    Args:\n        constant (int): amount of time (in milliseconds) to backoff.\n        **kwargs (Keyword Args): keyword arguments to pass to\n            ``Backoff``\n\n    \"\"\"\n\n    def __init__(self, constant: int = 60 * 1000, **kwargs: Any) -&gt; None:\n        super().__init__(**kwargs)\n        self.constant = constant\n\n    @property\n    def parameters(self) -&gt; dict[str, Optional[int]]:\n        \"\"\"Parameters of the current ``ConstantBackoff``\n        instance which uniquely characterize it.\n\n        Returns:\n            params (dict): backoff parameters\n\n        \"\"\"\n        return dict(\n            constant=self.constant,\n            floor=self.floor,\n            ceiling=self.ceiling,\n            zero_override=self.zero_override,\n        )\n\n    def formula(self, incidents: int) -&gt; int:\n        \"\"\"Constant backoff formula.\n\n        Implements:\n\n        $$c$$\n\n        where $c$ is `constant`.\n\n        Args:\n            incidents (int): current number of incidents\n\n        Returns:\n            backoff (int): backoff in milliseconds\n\n        \"\"\"\n        return self.constant\n</code></pre>"},{"location":"reference/#alsek.core.backoff.ConstantBackoff.parameters","title":"<code>parameters</code>  <code>property</code>","text":"<p>Parameters of the current <code>ConstantBackoff</code> instance which uniquely characterize it.</p> <p>Returns:</p> Name Type Description <code>params</code> <code>dict</code> <p>backoff parameters</p>"},{"location":"reference/#alsek.core.backoff.ConstantBackoff.formula","title":"<code>formula(incidents)</code>","text":"<p>Constant backoff formula.</p> <p>Implements:</p> \\[c\\] <p>where \\(c\\) is <code>constant</code>.</p> <p>Parameters:</p> Name Type Description Default <code>incidents</code> <code>int</code> <p>current number of incidents</p> required <p>Returns:</p> Name Type Description <code>backoff</code> <code>int</code> <p>backoff in milliseconds</p> Source code in <code>alsek/core/backoff.py</code> <pre><code>def formula(self, incidents: int) -&gt; int:\n    \"\"\"Constant backoff formula.\n\n    Implements:\n\n    $$c$$\n\n    where $c$ is `constant`.\n\n    Args:\n        incidents (int): current number of incidents\n\n    Returns:\n        backoff (int): backoff in milliseconds\n\n    \"\"\"\n    return self.constant\n</code></pre>"},{"location":"reference/#alsek.core.backoff.ExponentialBackoff","title":"<code>ExponentialBackoff</code>","text":"<p>               Bases: <code>Backoff</code></p> <p>Exponential backoff.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>int</code> <p>the base of the exponential (milliseconds)</p> <code>4</code> <code>factor</code> <code>int</code> <p>factor to multiply the result by</p> <code>10000</code> <code>**kwargs</code> <code>Keyword Args</code> <p>keyword arguments to pass to <code>Backoff</code></p> <code>{}</code> Source code in <code>alsek/core/backoff.py</code> <pre><code>class ExponentialBackoff(Backoff):\n    \"\"\"Exponential backoff.\n\n    Args:\n        base (int): the base of the exponential (milliseconds)\n        factor (int): factor to multiply the result by\n        **kwargs (Keyword Args): keyword arguments to pass to\n            ``Backoff``\n\n    \"\"\"\n\n    def __init__(self, base: int = 4, factor: int = 10_000, **kwargs: Any) -&gt; None:\n        super().__init__(**kwargs)\n        self.base = base\n        self.factor = factor\n\n    @property\n    def parameters(self) -&gt; dict[str, Optional[int]]:\n        \"\"\"Parameters of the current ``ExponentialBackoff``\n        instance which uniquely characterize it.\n\n        Returns:\n            params (dict): backoff parameters\n\n        \"\"\"\n        return dict(\n            base=self.base,\n            factor=self.factor,\n            floor=self.floor,\n            ceiling=self.ceiling,\n            zero_override=self.zero_override,\n        )\n\n    def formula(self, incidents: int) -&gt; int:\n        \"\"\"Exponential backoff formula.\n\n        Implements:\n\n        $$f * (b^{i})$$\n\n        where $f$ is `factor`, $b$ is `base` and $i$ is the number of `incidents`.\n\n        Args:\n            incidents (int): current number of incidents\n\n        Returns:\n            backoff (int): backoff in milliseconds\n\n        \"\"\"\n        return int(self.factor * (self.base**incidents))\n</code></pre>"},{"location":"reference/#alsek.core.backoff.ExponentialBackoff.parameters","title":"<code>parameters</code>  <code>property</code>","text":"<p>Parameters of the current <code>ExponentialBackoff</code> instance which uniquely characterize it.</p> <p>Returns:</p> Name Type Description <code>params</code> <code>dict</code> <p>backoff parameters</p>"},{"location":"reference/#alsek.core.backoff.ExponentialBackoff.formula","title":"<code>formula(incidents)</code>","text":"<p>Exponential backoff formula.</p> <p>Implements:</p> \\[f * (b^{i})\\] <p>where \\(f\\) is <code>factor</code>, \\(b\\) is <code>base</code> and \\(i\\) is the number of <code>incidents</code>.</p> <p>Parameters:</p> Name Type Description Default <code>incidents</code> <code>int</code> <p>current number of incidents</p> required <p>Returns:</p> Name Type Description <code>backoff</code> <code>int</code> <p>backoff in milliseconds</p> Source code in <code>alsek/core/backoff.py</code> <pre><code>def formula(self, incidents: int) -&gt; int:\n    \"\"\"Exponential backoff formula.\n\n    Implements:\n\n    $$f * (b^{i})$$\n\n    where $f$ is `factor`, $b$ is `base` and $i$ is the number of `incidents`.\n\n    Args:\n        incidents (int): current number of incidents\n\n    Returns:\n        backoff (int): backoff in milliseconds\n\n    \"\"\"\n    return int(self.factor * (self.base**incidents))\n</code></pre>"},{"location":"reference/#alsek.core.backoff.LinearBackoff","title":"<code>LinearBackoff</code>","text":"<p>               Bases: <code>Backoff</code></p> <p>Linear backoff.</p> <p>Parameters:</p> Name Type Description Default <code>factor</code> <code>int</code> <p>amount of time (in milliseconds) to add to backoff after each retry.</p> <code>30 * 1000</code> <code>**kwargs</code> <code>Keyword Args</code> <p>keyword arguments to pass to <code>Backoff</code></p> <code>{}</code> Source code in <code>alsek/core/backoff.py</code> <pre><code>class LinearBackoff(Backoff):\n    \"\"\"Linear backoff.\n\n    Args:\n        factor (int): amount of time (in milliseconds) to add to backoff\n            after each retry.\n        **kwargs (Keyword Args): keyword arguments to pass to\n            ``Backoff``\n\n    \"\"\"\n\n    def __init__(self, factor: int = 30 * 1000, **kwargs: Any) -&gt; None:\n        super().__init__(**kwargs)\n        self.factor = factor\n\n    @property\n    def parameters(self) -&gt; dict[str, Optional[int]]:\n        \"\"\"Parameters of the current ``LinearBackoff``\n        instance which uniquely characterize it.\n\n        Returns:\n            params (dict): backoff parameters\n\n        \"\"\"\n        return dict(\n            factor=self.factor,\n            floor=self.floor,\n            ceiling=self.ceiling,\n            zero_override=self.zero_override,\n        )\n\n    def formula(self, incidents: int) -&gt; int:\n        \"\"\"Linear backoff formula.\n\n        Implements:\n\n        $$f * i$$\n\n        where $f$ is `factor` and $i$ is the number of `incidents`.\n\n        Args:\n            incidents (int): current number of incidents\n\n        Returns:\n            backoff (int): backoff in milliseconds\n\n        \"\"\"\n        return int(self.factor * incidents)\n</code></pre>"},{"location":"reference/#alsek.core.backoff.LinearBackoff.parameters","title":"<code>parameters</code>  <code>property</code>","text":"<p>Parameters of the current <code>LinearBackoff</code> instance which uniquely characterize it.</p> <p>Returns:</p> Name Type Description <code>params</code> <code>dict</code> <p>backoff parameters</p>"},{"location":"reference/#alsek.core.backoff.LinearBackoff.formula","title":"<code>formula(incidents)</code>","text":"<p>Linear backoff formula.</p> <p>Implements:</p> \\[f * i\\] <p>where \\(f\\) is <code>factor</code> and \\(i\\) is the number of <code>incidents</code>.</p> <p>Parameters:</p> Name Type Description Default <code>incidents</code> <code>int</code> <p>current number of incidents</p> required <p>Returns:</p> Name Type Description <code>backoff</code> <code>int</code> <p>backoff in milliseconds</p> Source code in <code>alsek/core/backoff.py</code> <pre><code>def formula(self, incidents: int) -&gt; int:\n    \"\"\"Linear backoff formula.\n\n    Implements:\n\n    $$f * i$$\n\n    where $f$ is `factor` and $i$ is the number of `incidents`.\n\n    Args:\n        incidents (int): current number of incidents\n\n    Returns:\n        backoff (int): backoff in milliseconds\n\n    \"\"\"\n    return int(self.factor * incidents)\n</code></pre>"},{"location":"reference/#alsek.core.backoff.settings2backoff","title":"<code>settings2backoff(settings)</code>","text":"<p>Convert backoff settings to a <code>Backoff</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>BackoffSettingsType</code> <p>backoff settings of the form <code>{\"algorithm\": str, \"parameters\": dict}</code>.</p> required <p>Returns:</p> Name Type Description <code>backoff</code> <code>Backoff</code> <p>a backoff instance</p> Source code in <code>alsek/core/backoff.py</code> <pre><code>def settings2backoff(settings: BackoffSettingsType) -&gt; Backoff:\n    \"\"\"Convert backoff settings to a ``Backoff`` instance.\n\n    Args:\n        settings (BackoffSettingsType): backoff settings of\n            the form ``{\"algorithm\": str, \"parameters\": dict}``.\n\n    Returns:\n        backoff (Backoff): a backoff instance\n\n    \"\"\"\n    algorithm = _get_algorithm(settings[\"algorithm\"])\n    return algorithm(**settings[\"parameters\"])\n</code></pre>"},{"location":"reference/#alsek.core.broker","title":"<code>broker</code>","text":"<p>Broker</p>"},{"location":"reference/#alsek.core.broker.Broker","title":"<code>Broker</code>","text":"<p>Alsek Broker.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>Backend</code> <p>backend for data storage</p> required <code>dlq_ttl</code> <code>int</code> <p>time to live (in milliseconds) for Dead Letter Queue (DLQ). If <code>None</code>, failed messages will not be moved to the DLQ.</p> <code>DEFAULT_TTL</code> Source code in <code>alsek/core/broker.py</code> <pre><code>class Broker:\n    \"\"\"Alsek Broker.\n\n    Args:\n        backend (Backend): backend for data storage\n        dlq_ttl (int, optional): time to live (in milliseconds) for\n            Dead Letter Queue (DLQ). If ``None``, failed messages\n            will not be moved to the DLQ.\n\n    \"\"\"\n\n    def __init__(self, backend: Backend, dlq_ttl: Optional[int] = DEFAULT_TTL) -&gt; None:\n        self.backend = backend\n        self.dlq_ttl = dlq_ttl\n\n        if self.backend.IS_ASYNC:\n            raise AttributeError(\"Asynchronous backends are not yet supported\")\n\n    def __repr__(self) -&gt; str:\n        return auto_repr(\n            self,\n            backend=self.backend,\n            dlq_ttl=self.dlq_ttl,\n        )\n\n    def serialize(self) -&gt; dict[str, Any]:\n        settings = gather_init_params(self, ignore=(\"backend\",))\n        settings[\"backend\"] = dict(\n            cls=self.backend.__class__,\n            encoding=self.backend.encode(),\n        )\n        return settings\n\n    @classmethod\n    def deserialize(cls, settings: dict[str, Any]) -&gt; Broker:\n        settings = settings.copy()\n        backend_data = dill.loads(settings[\"backend\"][\"encoding\"])\n        settings[\"backend\"] = settings[\"backend\"][\"cls\"].from_settings(\n            backend_data[\"settings\"]\n        )\n        return cls(**settings)\n\n    def exists(self, message: Message) -&gt; bool:\n        \"\"\"Determine if the message exists in the backend.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            exists (bool): whether the message exists.\n\n        \"\"\"\n        name = get_message_name(message)\n        return self.backend.exists(name)\n\n    @magic_logger(\n        before=lambda message: log.debug(\"Submitting %s...\", message.summary),\n        after=lambda input_: log.debug(\"Submitted %s.\", input_[\"message\"].summary),\n    )\n    def submit(self, message: Message, ttl: int = DEFAULT_TTL) -&gt; None:\n        \"\"\"Submit a message for processing.\n\n        Args:\n            message (Message): an Alsek message\n            ttl (int): time to live for the submitted message in milliseconds\n\n        Returns:\n            None\n\n        Raises:\n            MessageAlreadyExistsError: if the message already exists\n\n        \"\"\"\n        name = get_message_name(message)\n        try:\n            self.backend.set(name, value=message.data, nx=True, ttl=ttl)\n        except KeyError:\n            raise MessageAlreadyExistsError(f\"'{name}' found in backend\")\n\n        self.backend.priority_add(\n            get_priority_namespace_from_message(message),\n            unique_id=name,\n            priority=message.priority,\n        )\n\n    @magic_logger(\n        before=lambda message: log.debug(\"Retrying %s...\", message.summary),\n    )\n    def retry(self, message: Message) -&gt; None:\n        \"\"\"Retry a message.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            None\n\n        Warning:\n            * This method will mutate ``message`` by incrementing it.\n\n        \"\"\"\n        if not self.exists(message):\n            raise MessageDoesNotExistsError(\n                f\"Message '{message.uuid}' not found in backend\"\n            )\n\n        # We release the lock before setting the messate data\n        # so that the `linked_lock` field on the message ie None.\n        message.release_lock(\n            not_linked_ok=True,\n            target_backend=self.backend,\n        )\n        message.increment_retries()\n        self.backend.set(get_message_name(message), value=message.data)\n        log.info(\n            \"Retrying %s in %s ms...\",\n            message.summary,\n            format(message.get_backoff_duration(), \",\"),\n        )\n\n    @magic_logger(\n        before=lambda message: log.info(\"Removing %s...\", message.summary),\n        after=lambda input_: log.info(\"Removed %s.\", input_[\"message\"].summary),\n    )\n    def remove(self, message: Message) -&gt; None:\n        \"\"\"Remove a message from the backend.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            None\n\n        \"\"\"\n        self.backend.priority_remove(\n            key=get_priority_namespace_from_message(message),\n            unique_id=get_message_name(message),\n        )\n        self.backend.delete(get_message_name(message), missing_ok=True)\n        message.release_lock(\n            not_linked_ok=True,\n            target_backend=self.backend,\n        )\n\n    @magic_logger(\n        before=lambda message: log.debug(\"Acking %s...\", message.summary),\n        after=lambda input_: log.debug(\"Acked %s.\", input_[\"message\"].summary),\n    )\n    def ack(self, message: Message) -&gt; None:\n        \"\"\"Acknowledge a message by removing it from the data backend.\n\n        Args:\n            message (Message): a message to acknowledge\n\n        Returns:\n            None\n\n        Warning:\n            * Messages will not be redelivered once acked.\n\n        \"\"\"\n        self.remove(message)\n\n    @magic_logger(\n        before=lambda message: log.info(\"Failing %s...\", message.summary),\n        after=lambda input_: log.info(\"Failed %s.\", input_[\"message\"].summary),\n    )\n    def fail(self, message: Message) -&gt; None:\n        \"\"\"Acknowledge and fail a message by removing it from the backend.\n        If ``dlq_ttl`` is not null, the messages will be persisted to\n        the dead letter queue for the prescribed amount of time.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            None\n\n        \"\"\"\n        self.ack(message)\n        if self.dlq_ttl:\n            self.backend.set(\n                get_dlq_message_name(message),\n                value=message.data,\n                ttl=self.dlq_ttl,\n            )\n            log.debug(\"Added %s to DLQ.\", message.summary)\n\n    @magic_logger(\n        before=lambda message: log.info(\"Failing %s...\", message.summary),\n        after=lambda input_: log.info(\"Failed %s.\", input_[\"message\"].summary),\n    )\n    def in_dlq(self, message: Message) -&gt; bool:\n        \"\"\"Determine if a message is in the dead letter queue.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            bool: whether the message is in the DLQ.\n\n        \"\"\"\n        return self.backend.exists(get_dlq_message_name(message))\n\n    @magic_logger(\n        before=lambda message: log.info(\"Syncing from backend %s...\", message.summary),\n        after=lambda input_: log.info(\n            \"Synced from backend %s.\",\n            input_[\"message\"].summary,\n        ),\n    )\n    def sync_from_backend(self, message: Message) -&gt; Message:\n        \"\"\"Synchronize a message's internal data with that in the backend.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            updated_message (Message): the updated message data\n\n        \"\"\"\n        try:\n            data = self.backend.get(get_message_name(message), default=Empty)\n        except KeyError:\n            data = self.backend.get(get_dlq_message_name(message), default=Empty)\n        return Message(**data)\n\n    @magic_logger(\n        before=lambda message: log.info(\"Syncing %s to backend...\", message.summary),\n        after=lambda input_: log.info(\n            \"Synced %s to backend.\", input_[\"message\"].summary\n        ),\n    )\n    def sync_to_backend(self, message: Message) -&gt; None:\n        \"\"\"Synchronize the data persisted in the backend with the current state of\n        ``message`` held in memory.\n\n        This method is the logical inverse of ``sync_from_backend``; any changes\n        made to the ``message`` instance are written back to the backend so that\n        future reads reflect the most up-to-date information.\n\n        Args:\n            message (Message): an Alsek message whose current state should be\n                persisted.\n\n        Returns:\n            None\n\n        Warning:\n            * This method will mutate ``message`` by updating it\n              regardless of whether a lock is linked to it.\n              You are responsible for ensuring that any mutation\n              of the message's underlying data is only performed\n              by the lock owner.\n\n        \"\"\"\n        # Determine which key (regular queue or DLQ) should be updated\n        if self.exists(message):\n            key = get_message_name(message)\n        elif self.in_dlq(message):\n            key = get_dlq_message_name(message)\n        else:\n            raise MessageDoesNotExistsError(\n                f\"Message '{message.uuid}' not found in backend\"\n            )\n\n        # Persist the updated message data. We intentionally omit a TTL value\n        # to preserve the existing expiry associated with ``key`` (if any).\n        self.backend.set(key, value=message.data)\n</code></pre>"},{"location":"reference/#alsek.core.broker.Broker.ack","title":"<code>ack(message)</code>","text":"<p>Acknowledge a message by removing it from the data backend.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>a message to acknowledge</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Warning <ul> <li>Messages will not be redelivered once acked.</li> </ul> Source code in <code>alsek/core/broker.py</code> <pre><code>@magic_logger(\n    before=lambda message: log.debug(\"Acking %s...\", message.summary),\n    after=lambda input_: log.debug(\"Acked %s.\", input_[\"message\"].summary),\n)\ndef ack(self, message: Message) -&gt; None:\n    \"\"\"Acknowledge a message by removing it from the data backend.\n\n    Args:\n        message (Message): a message to acknowledge\n\n    Returns:\n        None\n\n    Warning:\n        * Messages will not be redelivered once acked.\n\n    \"\"\"\n    self.remove(message)\n</code></pre>"},{"location":"reference/#alsek.core.broker.Broker.exists","title":"<code>exists(message)</code>","text":"<p>Determine if the message exists in the backend.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>exists</code> <code>bool</code> <p>whether the message exists.</p> Source code in <code>alsek/core/broker.py</code> <pre><code>def exists(self, message: Message) -&gt; bool:\n    \"\"\"Determine if the message exists in the backend.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        exists (bool): whether the message exists.\n\n    \"\"\"\n    name = get_message_name(message)\n    return self.backend.exists(name)\n</code></pre>"},{"location":"reference/#alsek.core.broker.Broker.fail","title":"<code>fail(message)</code>","text":"<p>Acknowledge and fail a message by removing it from the backend. If <code>dlq_ttl</code> is not null, the messages will be persisted to the dead letter queue for the prescribed amount of time.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/broker.py</code> <pre><code>@magic_logger(\n    before=lambda message: log.info(\"Failing %s...\", message.summary),\n    after=lambda input_: log.info(\"Failed %s.\", input_[\"message\"].summary),\n)\ndef fail(self, message: Message) -&gt; None:\n    \"\"\"Acknowledge and fail a message by removing it from the backend.\n    If ``dlq_ttl`` is not null, the messages will be persisted to\n    the dead letter queue for the prescribed amount of time.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        None\n\n    \"\"\"\n    self.ack(message)\n    if self.dlq_ttl:\n        self.backend.set(\n            get_dlq_message_name(message),\n            value=message.data,\n            ttl=self.dlq_ttl,\n        )\n        log.debug(\"Added %s to DLQ.\", message.summary)\n</code></pre>"},{"location":"reference/#alsek.core.broker.Broker.in_dlq","title":"<code>in_dlq(message)</code>","text":"<p>Determine if a message is in the dead letter queue.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>whether the message is in the DLQ.</p> Source code in <code>alsek/core/broker.py</code> <pre><code>@magic_logger(\n    before=lambda message: log.info(\"Failing %s...\", message.summary),\n    after=lambda input_: log.info(\"Failed %s.\", input_[\"message\"].summary),\n)\ndef in_dlq(self, message: Message) -&gt; bool:\n    \"\"\"Determine if a message is in the dead letter queue.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        bool: whether the message is in the DLQ.\n\n    \"\"\"\n    return self.backend.exists(get_dlq_message_name(message))\n</code></pre>"},{"location":"reference/#alsek.core.broker.Broker.remove","title":"<code>remove(message)</code>","text":"<p>Remove a message from the backend.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/broker.py</code> <pre><code>@magic_logger(\n    before=lambda message: log.info(\"Removing %s...\", message.summary),\n    after=lambda input_: log.info(\"Removed %s.\", input_[\"message\"].summary),\n)\ndef remove(self, message: Message) -&gt; None:\n    \"\"\"Remove a message from the backend.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        None\n\n    \"\"\"\n    self.backend.priority_remove(\n        key=get_priority_namespace_from_message(message),\n        unique_id=get_message_name(message),\n    )\n    self.backend.delete(get_message_name(message), missing_ok=True)\n    message.release_lock(\n        not_linked_ok=True,\n        target_backend=self.backend,\n    )\n</code></pre>"},{"location":"reference/#alsek.core.broker.Broker.retry","title":"<code>retry(message)</code>","text":"<p>Retry a message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Warning <ul> <li>This method will mutate <code>message</code> by incrementing it.</li> </ul> Source code in <code>alsek/core/broker.py</code> <pre><code>@magic_logger(\n    before=lambda message: log.debug(\"Retrying %s...\", message.summary),\n)\ndef retry(self, message: Message) -&gt; None:\n    \"\"\"Retry a message.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        None\n\n    Warning:\n        * This method will mutate ``message`` by incrementing it.\n\n    \"\"\"\n    if not self.exists(message):\n        raise MessageDoesNotExistsError(\n            f\"Message '{message.uuid}' not found in backend\"\n        )\n\n    # We release the lock before setting the messate data\n    # so that the `linked_lock` field on the message ie None.\n    message.release_lock(\n        not_linked_ok=True,\n        target_backend=self.backend,\n    )\n    message.increment_retries()\n    self.backend.set(get_message_name(message), value=message.data)\n    log.info(\n        \"Retrying %s in %s ms...\",\n        message.summary,\n        format(message.get_backoff_duration(), \",\"),\n    )\n</code></pre>"},{"location":"reference/#alsek.core.broker.Broker.submit","title":"<code>submit(message, ttl=DEFAULT_TTL)</code>","text":"<p>Submit a message for processing.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>ttl</code> <code>int</code> <p>time to live for the submitted message in milliseconds</p> <code>DEFAULT_TTL</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>MessageAlreadyExistsError</code> <p>if the message already exists</p> Source code in <code>alsek/core/broker.py</code> <pre><code>@magic_logger(\n    before=lambda message: log.debug(\"Submitting %s...\", message.summary),\n    after=lambda input_: log.debug(\"Submitted %s.\", input_[\"message\"].summary),\n)\ndef submit(self, message: Message, ttl: int = DEFAULT_TTL) -&gt; None:\n    \"\"\"Submit a message for processing.\n\n    Args:\n        message (Message): an Alsek message\n        ttl (int): time to live for the submitted message in milliseconds\n\n    Returns:\n        None\n\n    Raises:\n        MessageAlreadyExistsError: if the message already exists\n\n    \"\"\"\n    name = get_message_name(message)\n    try:\n        self.backend.set(name, value=message.data, nx=True, ttl=ttl)\n    except KeyError:\n        raise MessageAlreadyExistsError(f\"'{name}' found in backend\")\n\n    self.backend.priority_add(\n        get_priority_namespace_from_message(message),\n        unique_id=name,\n        priority=message.priority,\n    )\n</code></pre>"},{"location":"reference/#alsek.core.broker.Broker.sync_from_backend","title":"<code>sync_from_backend(message)</code>","text":"<p>Synchronize a message's internal data with that in the backend.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>updated_message</code> <code>Message</code> <p>the updated message data</p> Source code in <code>alsek/core/broker.py</code> <pre><code>@magic_logger(\n    before=lambda message: log.info(\"Syncing from backend %s...\", message.summary),\n    after=lambda input_: log.info(\n        \"Synced from backend %s.\",\n        input_[\"message\"].summary,\n    ),\n)\ndef sync_from_backend(self, message: Message) -&gt; Message:\n    \"\"\"Synchronize a message's internal data with that in the backend.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        updated_message (Message): the updated message data\n\n    \"\"\"\n    try:\n        data = self.backend.get(get_message_name(message), default=Empty)\n    except KeyError:\n        data = self.backend.get(get_dlq_message_name(message), default=Empty)\n    return Message(**data)\n</code></pre>"},{"location":"reference/#alsek.core.broker.Broker.sync_to_backend","title":"<code>sync_to_backend(message)</code>","text":"<p>Synchronize the data persisted in the backend with the current state of <code>message</code> held in memory.</p> <p>This method is the logical inverse of <code>sync_from_backend</code>; any changes made to the <code>message</code> instance are written back to the backend so that future reads reflect the most up-to-date information.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message whose current state should be persisted.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Warning <ul> <li>This method will mutate <code>message</code> by updating it   regardless of whether a lock is linked to it.   You are responsible for ensuring that any mutation   of the message's underlying data is only performed   by the lock owner.</li> </ul> Source code in <code>alsek/core/broker.py</code> <pre><code>@magic_logger(\n    before=lambda message: log.info(\"Syncing %s to backend...\", message.summary),\n    after=lambda input_: log.info(\n        \"Synced %s to backend.\", input_[\"message\"].summary\n    ),\n)\ndef sync_to_backend(self, message: Message) -&gt; None:\n    \"\"\"Synchronize the data persisted in the backend with the current state of\n    ``message`` held in memory.\n\n    This method is the logical inverse of ``sync_from_backend``; any changes\n    made to the ``message`` instance are written back to the backend so that\n    future reads reflect the most up-to-date information.\n\n    Args:\n        message (Message): an Alsek message whose current state should be\n            persisted.\n\n    Returns:\n        None\n\n    Warning:\n        * This method will mutate ``message`` by updating it\n          regardless of whether a lock is linked to it.\n          You are responsible for ensuring that any mutation\n          of the message's underlying data is only performed\n          by the lock owner.\n\n    \"\"\"\n    # Determine which key (regular queue or DLQ) should be updated\n    if self.exists(message):\n        key = get_message_name(message)\n    elif self.in_dlq(message):\n        key = get_dlq_message_name(message)\n    else:\n        raise MessageDoesNotExistsError(\n            f\"Message '{message.uuid}' not found in backend\"\n        )\n\n    # Persist the updated message data. We intentionally omit a TTL value\n    # to preserve the existing expiry associated with ``key`` (if any).\n    self.backend.set(key, value=message.data)\n</code></pre>"},{"location":"reference/#alsek.core.concurrency","title":"<code>concurrency</code>","text":"<p>Concurrency</p>"},{"location":"reference/#alsek.core.concurrency.Lock","title":"<code>Lock</code>","text":"<p>Distributed mutual exclusion (MUTEX) lock for controlling concurrency accross machines.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the lock</p> required <code>backend</code> <code>Backend</code> <p>backend for data storage</p> required <code>ttl</code> <code>int</code> <p>time to live in milliseconds. If <code>None</code>, the lock will not expire automatically.</p> <code>60 * 60 * 1000</code> <code>auto_release</code> <code>bool</code> <p>if <code>True</code> automatically release the lock on context exit.</p> <code>True</code> <code>owner_id</code> <code>str</code> <p>unique identifier for the lock. Do not change this value unless you know what you are doing.</p> <code>CURRENT_HOST_OWNER_ID</code> Warning <ul> <li>Locks are global and do not consider queues, unless   included in <code>name</code>.</li> <li>When used as a context manager, the lock is not automatically   acquired. Lock acquisition requires calling <code>acquire()</code>.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from alsek import Lock\n&gt;&gt;&gt; from alsek.storage.backends.redis.standard import RedisBackend\n...\n&gt;&gt;&gt; backend = RedisBackend()\n...\n&gt;&gt;&gt; with Lock(\"mutex\", backend=backend) as lock:\n&gt;&gt;&gt;     if lock.acquire():\n&gt;&gt;&gt;         print(\"Acquired lock.\")\n&gt;&gt;&gt;     else:\n&gt;&gt;&gt;         print(\"Did not acquire lock.\")\n</code></pre> Source code in <code>alsek/core/concurrency.py</code> <pre><code>class Lock:\n    \"\"\"Distributed mutual exclusion (MUTEX) lock for controlling\n    concurrency accross machines.\n\n    Args:\n        name (str): name of the lock\n        backend (Backend): backend for data storage\n        ttl (int, optional): time to live in milliseconds.\n            If ``None``, the lock will not expire automatically.\n        auto_release (bool): if ``True`` automatically release\n            the lock on context exit.\n        owner_id (str): unique identifier for the lock.\n            Do not change this value unless you know what you are doing.\n\n    Warning:\n        * Locks are global and do not consider queues, unless\n          included in ``name``.\n        * When used as a context manager, the lock is *not* automatically\n          acquired. Lock acquisition requires calling ``acquire()``.\n\n    Examples:\n        &gt;&gt;&gt; from alsek import Lock\n        &gt;&gt;&gt; from alsek.storage.backends.redis.standard import RedisBackend\n        ...\n        &gt;&gt;&gt; backend = RedisBackend()\n        ...\n        &gt;&gt;&gt; with Lock(\"mutex\", backend=backend) as lock:\n        &gt;&gt;&gt;     if lock.acquire():\n        &gt;&gt;&gt;         print(\"Acquired lock.\")\n        &gt;&gt;&gt;     else:\n        &gt;&gt;&gt;         print(\"Did not acquire lock.\")\n\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        backend: Backend,\n        ttl: Optional[int] = 60 * 60 * 1000,\n        auto_release: bool = True,\n        owner_id: str = CURRENT_HOST_OWNER_ID,\n    ) -&gt; None:\n        self.name = name\n        self.backend = backend\n        self.ttl = ttl\n        self.auto_release = auto_release\n        self._owner_id = owner_id\n\n        if not isinstance(backend, RedisBackend):\n            raise NotImplementedError(\"Only RedisBackend is supported.\")\n\n        self.validate()\n\n        self._lock = redis_lock.Lock(\n            backend.conn,\n            name=self.full_name,\n            expire=None if ttl is None else round(ttl / 1000),\n            id=self.owner_id,\n        )\n\n    def validate(self) -&gt; None:\n        if not self.name:\n            raise ValueError(\"`name` must be provided.\")\n        elif not self.owner_id:\n            raise ValueError(\"`owner_id` must be provided.\")\n\n    @property\n    def owner_id(self) -&gt; str:\n        return self._owner_id\n\n    def __repr__(self) -&gt; str:\n        return auto_repr(\n            self,\n            name=self.name,\n            backend=self.backend,\n            ttl=self.ttl,\n            auto_release=self.auto_release,\n        )\n\n    @property\n    def full_name(self) -&gt; str:\n        \"\"\"The full name of the lock including its namespace prefix.\"\"\"\n        return f\"{self.backend.namespace}:{self.name}\"\n\n    @property\n    def holder(self) -&gt; Optional[str]:\n        \"\"\"Name of the owner that currently holds the lock, if any.\"\"\"\n        return self._lock.get_owner_id()\n\n    @property\n    def held(self) -&gt; bool:\n        \"\"\"If the lock is held by the current owner.\"\"\"\n        return self.holder == self.owner_id\n\n    def acquire(\n        self,\n        wait: Optional[int] = None,\n        if_already_acquired: IF_ALREADY_ACQUIRED_TYPE = \"raise_error\",\n    ) -&gt; bool:\n        \"\"\"Try to acquire the lock.\n\n        Args:\n            wait (int, optional): the amount of time wait to acquire\n                the lock (in seconds). If ``None`` do not block.\n            if_already_acquired (str): if ``True`` do not raise if the lock\n                is already held by the current owner.\n\n        Returns:\n            acquired (bool): ``True`` if the message is\n                acquired or already acquired by the current owner.\n\n        \"\"\"\n        if if_already_acquired not in get_args(IF_ALREADY_ACQUIRED_TYPE):\n            raise ValueError(f\"Invalid `on_already_acquired`, got  {if_already_acquired}\")  # fmt: skip\n\n        try:\n            return self._lock.acquire(blocking=bool(wait), timeout=wait)\n        except redis_lock.AlreadyAcquired as error:\n            if if_already_acquired == \"return_true\":\n                return True\n            elif if_already_acquired == \"return_false\":\n                return False\n            else:\n                raise error\n\n    def release(self, raise_if_not_acquired: bool = False) -&gt; bool:\n        \"\"\"Release the lock.\n\n        Args:\n            raise_if_not_acquired (bool): raise if the lock was not\n                acquired for release.\n\n        Returns:\n            released (bool): whether the lock was\n                found and released.\n\n        \"\"\"\n        try:\n            self._lock.release()\n            return True\n        except redis_lock.NotAcquired as error:\n            if raise_if_not_acquired:\n                raise error\n            else:\n                return False\n\n    def __enter__(self) -&gt; Lock:\n        \"\"\"Enter the context and try to acquire the lock.\n\n        Returns:\n            lock (Lock): underlying lock object.\n\n        \"\"\"\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -&gt; None:\n        \"\"\"Exit the context. If ``auto_release`` is enabled,\n         the lock will be released.\n\n        Args:\n            exc_val (BaseException, optional): an exception from within the context\n            exc_val (BaseException, optional): value of any exception from\n                within the context\n            exc_tb (TracebackType, optional): the traceback from the context\n\n        Returns:\n            None\n\n        \"\"\"\n        if self.auto_release:\n            self.release()\n</code></pre>"},{"location":"reference/#alsek.core.concurrency.Lock.full_name","title":"<code>full_name</code>  <code>property</code>","text":"<p>The full name of the lock including its namespace prefix.</p>"},{"location":"reference/#alsek.core.concurrency.Lock.held","title":"<code>held</code>  <code>property</code>","text":"<p>If the lock is held by the current owner.</p>"},{"location":"reference/#alsek.core.concurrency.Lock.holder","title":"<code>holder</code>  <code>property</code>","text":"<p>Name of the owner that currently holds the lock, if any.</p>"},{"location":"reference/#alsek.core.concurrency.Lock.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter the context and try to acquire the lock.</p> <p>Returns:</p> Name Type Description <code>lock</code> <code>Lock</code> <p>underlying lock object.</p> Source code in <code>alsek/core/concurrency.py</code> <pre><code>def __enter__(self) -&gt; Lock:\n    \"\"\"Enter the context and try to acquire the lock.\n\n    Returns:\n        lock (Lock): underlying lock object.\n\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/#alsek.core.concurrency.Lock.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Exit the context. If <code>auto_release</code> is enabled,  the lock will be released.</p> <p>Parameters:</p> Name Type Description Default <code>exc_val</code> <code>BaseException</code> <p>an exception from within the context</p> required <code>exc_val</code> <code>BaseException</code> <p>value of any exception from within the context</p> required <code>exc_tb</code> <code>TracebackType</code> <p>the traceback from the context</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/concurrency.py</code> <pre><code>def __exit__(\n    self,\n    exc_type: Optional[Type[BaseException]],\n    exc_val: Optional[BaseException],\n    exc_tb: Optional[TracebackType],\n) -&gt; None:\n    \"\"\"Exit the context. If ``auto_release`` is enabled,\n     the lock will be released.\n\n    Args:\n        exc_val (BaseException, optional): an exception from within the context\n        exc_val (BaseException, optional): value of any exception from\n            within the context\n        exc_tb (TracebackType, optional): the traceback from the context\n\n    Returns:\n        None\n\n    \"\"\"\n    if self.auto_release:\n        self.release()\n</code></pre>"},{"location":"reference/#alsek.core.concurrency.Lock.acquire","title":"<code>acquire(wait=None, if_already_acquired='raise_error')</code>","text":"<p>Try to acquire the lock.</p> <p>Parameters:</p> Name Type Description Default <code>wait</code> <code>int</code> <p>the amount of time wait to acquire the lock (in seconds). If <code>None</code> do not block.</p> <code>None</code> <code>if_already_acquired</code> <code>str</code> <p>if <code>True</code> do not raise if the lock is already held by the current owner.</p> <code>'raise_error'</code> <p>Returns:</p> Name Type Description <code>acquired</code> <code>bool</code> <p><code>True</code> if the message is acquired or already acquired by the current owner.</p> Source code in <code>alsek/core/concurrency.py</code> <pre><code>def acquire(\n    self,\n    wait: Optional[int] = None,\n    if_already_acquired: IF_ALREADY_ACQUIRED_TYPE = \"raise_error\",\n) -&gt; bool:\n    \"\"\"Try to acquire the lock.\n\n    Args:\n        wait (int, optional): the amount of time wait to acquire\n            the lock (in seconds). If ``None`` do not block.\n        if_already_acquired (str): if ``True`` do not raise if the lock\n            is already held by the current owner.\n\n    Returns:\n        acquired (bool): ``True`` if the message is\n            acquired or already acquired by the current owner.\n\n    \"\"\"\n    if if_already_acquired not in get_args(IF_ALREADY_ACQUIRED_TYPE):\n        raise ValueError(f\"Invalid `on_already_acquired`, got  {if_already_acquired}\")  # fmt: skip\n\n    try:\n        return self._lock.acquire(blocking=bool(wait), timeout=wait)\n    except redis_lock.AlreadyAcquired as error:\n        if if_already_acquired == \"return_true\":\n            return True\n        elif if_already_acquired == \"return_false\":\n            return False\n        else:\n            raise error\n</code></pre>"},{"location":"reference/#alsek.core.concurrency.Lock.release","title":"<code>release(raise_if_not_acquired=False)</code>","text":"<p>Release the lock.</p> <p>Parameters:</p> Name Type Description Default <code>raise_if_not_acquired</code> <code>bool</code> <p>raise if the lock was not acquired for release.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>released</code> <code>bool</code> <p>whether the lock was found and released.</p> Source code in <code>alsek/core/concurrency.py</code> <pre><code>def release(self, raise_if_not_acquired: bool = False) -&gt; bool:\n    \"\"\"Release the lock.\n\n    Args:\n        raise_if_not_acquired (bool): raise if the lock was not\n            acquired for release.\n\n    Returns:\n        released (bool): whether the lock was\n            found and released.\n\n    \"\"\"\n    try:\n        self._lock.release()\n        return True\n    except redis_lock.NotAcquired as error:\n        if raise_if_not_acquired:\n            raise error\n        else:\n            return False\n</code></pre>"},{"location":"reference/#alsek.core.concurrency.ProcessLock","title":"<code>ProcessLock</code>","text":"<p>               Bases: <code>Lock</code></p> <p>Distributed mutual exclusion (MUTEX) lock for controlling concurrency accross processes on the same host.</p> Source code in <code>alsek/core/concurrency.py</code> <pre><code>class ProcessLock(Lock):\n    \"\"\"Distributed mutual exclusion (MUTEX) lock for controlling\n    concurrency accross processes on the same host.\n    \"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        super().__init__(*args, **kwargs, owner_id=\"\")\n\n    def validate(self) -&gt; None:\n        if not self.name:\n            raise ValueError(\"`name` must be provided.\")\n\n    @property\n    def owner_id(self) -&gt; str:\n        # We compute this \"fresh\" every time so that\n        # It's always accurate even if the lock is moved\n        # to a different process than it was created in.\n        return _get_process_lock_owner_id()\n</code></pre>"},{"location":"reference/#alsek.core.concurrency.ThreadLock","title":"<code>ThreadLock</code>","text":"<p>               Bases: <code>Lock</code></p> <p>Distributed mutual exclusion (MUTEX) lock for controlling concurrency accross processes and threads on the same host.</p> Source code in <code>alsek/core/concurrency.py</code> <pre><code>class ThreadLock(Lock):\n    \"\"\"Distributed mutual exclusion (MUTEX) lock for controlling\n    concurrency accross processes and threads on the same host.\n    \"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        super().__init__(*args, **kwargs, owner_id=\"\")\n\n    def validate(self) -&gt; None:\n        if not self.name:\n            raise ValueError(\"`name` must be provided.\")\n\n    @property\n    def owner_id(self) -&gt; str:\n        # We compute this \"fresh\" every time so that\n        # It's always accurate even if the lock is moved\n        # to a different thread than it was created in.\n        return _get_thread_lock_owner_id()\n</code></pre>"},{"location":"reference/#alsek.core.consumer","title":"<code>consumer</code>","text":"<p>Consumer</p>"},{"location":"reference/#alsek.core.consumer.Consumer","title":"<code>Consumer</code>","text":"<p>Tool for consuming messages generated by the broker.</p> <p>Parameters:</p> Name Type Description Default <code>broker</code> <code>Broker</code> <p>an Alsek broker</p> required <code>subset</code> <code>(list[str], dict[str, list[str]])</code> <p>subset of messages to consume Must be one of the following</p> <pre><code>* ``None``: consume messages from all queues and tasks\n* ``list``: a list of queues of the form ``[\"queue_a\", \"queue_b\", \"queue_c\", ...]``\n* ``dict``: a dictionary of queues and tasks of the form\n    ``{\"queue_a\": [\"task_name_a\", \"task_name_b\", \"task_name_c\", ...], ...}``\n</code></pre> <code>None</code> <code>backoff</code> <code>Backoff</code> <p>backoff to use in response to passes over the backend which did not yield any actionable messages.</p> <code>LinearBackoff(1 * 1000, floor=1000, ceiling=30000, zero_override=False)</code> Notes <ul> <li>If <code>subset</code> is a <code>list</code> or <code>dict</code>, queue priority is derived from the   order of the items. Items which appear earlier are given higher priority.</li> <li>If <code>subset</code> is a <code>dict</code>, task priority is derived from the order of   task names in the value associated with each key (queue).</li> </ul> Warning <ul> <li>If <code>subset</code> is of type <code>dict</code>, task names not included   in any of the values will be ignored.</li> </ul> Source code in <code>alsek/core/consumer.py</code> <pre><code>class Consumer:\n    \"\"\"Tool for consuming messages generated by the broker.\n\n    Args:\n        broker (Broker): an Alsek broker\n        subset (list[str], dict[str, list[str]], optional): subset of messages to consume\n            Must be one of the following\n\n                * ``None``: consume messages from all queues and tasks\n                * ``list``: a list of queues of the form ``[\"queue_a\", \"queue_b\", \"queue_c\", ...]``\n                * ``dict``: a dictionary of queues and tasks of the form\n                    ``{\"queue_a\": [\"task_name_a\", \"task_name_b\", \"task_name_c\", ...], ...}``\n\n        backoff (Backoff, optional): backoff to use in response to passes over the backend\n            which did not yield any actionable messages.\n\n    Notes:\n        * If ``subset`` is a ``list`` or ``dict``, queue priority is derived from the\n          order of the items. Items which appear earlier are given higher priority.\n        * If ``subset`` is a ``dict``, task priority is derived from the order of\n          task names in the value associated with each key (queue).\n\n    Warning:\n        * If ``subset`` is of type ``dict``, task names not included\n          in any of the values will be ignored.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        broker: Broker,\n        subset: Optional[Union[list[str], dict[str, list[str]]]] = None,\n        backoff: Optional[Backoff] = LinearBackoff(\n            1 * 1000,\n            floor=1000,\n            ceiling=30_000,\n            zero_override=False,\n        ),\n    ) -&gt; None:\n        self.subset = subset\n        self.broker = broker\n        self.backoff = backoff or ConstantBackoff(0, floor=0, ceiling=0)\n\n        self._empty_passes: int = 0\n        self.stop_signal = StopSignalListener()\n\n    def _scan_subnamespaces(self) -&gt; Iterable[str]:\n        if not self.subset:\n            subnamespaces = [get_subnamespace(None)]\n        elif isinstance(self.subset, list):\n            subnamespaces = [get_subnamespace(q) for q in self.subset]\n        else:\n            subnamespaces = [\n                get_subnamespace(q, task_name=t)\n                for (q, tasks) in self.subset.items()\n                for t in tasks\n            ]\n\n        for s in subnamespaces:\n            if self.stop_signal.received:\n                break\n            for i in self.broker.backend.scan(f\"{get_priority_namespace(s)}*\"):\n                if self.stop_signal.received:\n                    break\n                yield i\n\n    def _poll(self) -&gt; list[Message]:\n        # NOTE: with this approach, we 'drain' / exhaust queues in\n        #       the order they're provided, and then drain the next.\n        #       So if we had queues A,B,C we'd drain A, then drain B\n        #       and, finally, drain C.\n        # ToDo: implement a 'flat' option that moves to the next queue\n        #       So, A then B then C, round and round.\n        output: list[Message] = list()\n\n        def main_loop() -&gt; None:\n            for s in self._scan_subnamespaces():\n                for name in self.broker.backend.priority_iter(s):\n                    message_data = self.broker.backend.get(name)\n                    if message_data is None:\n                        # Message data can be None if it has been deleted (by a TTL or\n                        # another worker) between the `priority_iter()` and `get()` operations.\n                        continue\n\n                    message = Message(**message_data)\n                    if message.ready and not self.stop_signal.received:\n                        with MessageMutex(message, self.broker.backend) as lock:\n                            if lock.acquire(if_already_acquired=\"return_false\"):\n                                output.append(message.link_lock(lock, override=True))\n\n        try:\n            main_loop()\n        except KeyboardInterrupt:\n            pass\n        except redis.exceptions.ConnectionError as error:\n            if not self.stop_signal.received:\n                raise error\n\n        self._empty_passes = 0 if output else self._empty_passes + 1\n        return _dedup_messages(output)\n\n    def stream(self) -&gt; Iterable[Message]:\n        \"\"\"Generate a stream of messages to process from\n        the data backend.\n\n        Returns:\n            stream (Iterable[Message]): an iterable of messages to process\n\n        \"\"\"\n        while not self.stop_signal.received:\n            for message in self._poll():\n                yield message\n            self.stop_signal.wait(self.backoff.get(self._empty_passes))\n</code></pre>"},{"location":"reference/#alsek.core.consumer.Consumer.stream","title":"<code>stream()</code>","text":"<p>Generate a stream of messages to process from the data backend.</p> <p>Returns:</p> Name Type Description <code>stream</code> <code>Iterable[Message]</code> <p>an iterable of messages to process</p> Source code in <code>alsek/core/consumer.py</code> <pre><code>def stream(self) -&gt; Iterable[Message]:\n    \"\"\"Generate a stream of messages to process from\n    the data backend.\n\n    Returns:\n        stream (Iterable[Message]): an iterable of messages to process\n\n    \"\"\"\n    while not self.stop_signal.received:\n        for message in self._poll():\n            yield message\n        self.stop_signal.wait(self.backoff.get(self._empty_passes))\n</code></pre>"},{"location":"reference/#alsek.core.futures","title":"<code>futures</code>","text":"<p>Futures</p>"},{"location":"reference/#alsek.core.futures.ProcessTaskFuture","title":"<code>ProcessTaskFuture</code>","text":"<p>               Bases: <code>TaskFuture</code></p> <p>Future for task execution in a separate process.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>a task to perform</p> required <code>message</code> <code>Message</code> <p>a message to run <code>task</code> against</p> required <code>patience</code> <code>int</code> <p>time to wait (in milliseconds) after issuing a SIGTERM signal to the process at shutdown. If the process is still active after this time, a SIGKILL will be issued.</p> <code>1 * 1000</code> Source code in <code>alsek/core/futures.py</code> <pre><code>class ProcessTaskFuture(TaskFuture):\n    \"\"\"Future for task execution in a separate process.\n\n    Args:\n        task (Task): a task to perform\n        message (Message): a message to run ``task`` against\n        patience (int): time to wait (in milliseconds) after issuing\n            a SIGTERM signal to the process at shutdown. If the process\n            is still active after this time, a SIGKILL will be issued.\n\n    \"\"\"\n\n    def __init__(self, task: Task, message: Message, patience: int = 1 * 1000) -&gt; None:\n        super().__init__(task, message=message)\n        self.patience = patience\n\n        self._wrapper_exit_queue: Queue = Queue()\n        self._process = Process(\n            target=self._wrapper,\n            args=(\n                _process_future_encoder(task, message=message),\n                get_logger().level,\n                self._wrapper_exit_queue,\n            ),\n            daemon=True,\n        )\n        self._process.start()\n\n        # Note: this must go here b/c the scan depends on\n        #   `.complete`, which in turn depends on `_process`.\n        self._revocation_scan_thread.start()\n\n    @property\n    def complete(self) -&gt; bool:\n        \"\"\"Whether the task has finished.\"\"\"\n        return not self._process.is_alive()\n\n    @staticmethod\n    def _wrapper(\n        encoded_data: bytes,\n        log_level: int,\n        wrapper_exit_queue: Queue,\n    ) -&gt; None:\n        set_alsek_worker_pool_env_var()\n        setup_logging(log_level)\n        task, message = _process_future_decoder(encoded_data)\n        log.info(\"Received %s...\", message.summary)\n        task.update_status(message, status=TaskStatus.RUNNING)\n\n        result, exception = None, None\n        try:\n            task.pre_op(message)\n            result = task.execute(message)\n            if task.is_revoked(message):\n                log.info(\n                    \"Result for %s recovered after revocation. Discarding.\",\n                    message.summary,\n                )\n                return None\n\n            message.update(exception_details=None)  # clear any existing errors\n            log.info(\"Successfully processed %s.\", message.summary)\n        except BaseException as error:\n            log.error(\"Error processing %s.\", message.summary, exc_info=True)\n            exception = error\n            message.update(exception_details=parse_exception(exception).as_dict())\n\n        # Post op is called here so that exception_details can be set\n        task.post_op(message, result=result)\n\n        if not wrapper_exit_queue.empty():\n            log.debug(\"Process task future finished after termination.\")\n        elif exception is not None:\n            _error_encountered_future_handler(\n                task,\n                message=message,\n                exception=exception,\n                update_exception_on_message=False,\n            )\n        else:\n            _complete_future_handler(task, message=message, result=result)\n\n        wrapper_exit_queue.put(1)\n\n    def _shutdown(self) -&gt; None:\n        self._process.terminate()\n        self._process.join(self.patience / 1000)\n        if self._process.is_alive():\n            self._process.kill()\n\n    def stop(self, exception: Type[BaseException]) -&gt; None:\n        \"\"\"Stop the future.\n\n        Returns:\n            None\n\n        \"\"\"\n        if self._process.ident is None:  # type: ignore\n            log.error(\n                \"Process task future for %s did not start.\",\n                self.message.summary,\n            )\n            return None\n\n        self._shutdown()\n        if self._wrapper_exit_queue.empty():\n            self._wrapper_exit_queue.put(1)\n            try:\n                raise exception(f\"Stopped process {self._process.ident}\")  # type: ignore\n            except BaseException as error:\n                log.error(\"Error processing %s.\", self.message.summary, exc_info=True)\n                _error_encountered_future_handler(\n                    self.task,\n                    self.message,\n                    exception=error,\n                )\n</code></pre>"},{"location":"reference/#alsek.core.futures.ProcessTaskFuture.complete","title":"<code>complete</code>  <code>property</code>","text":"<p>Whether the task has finished.</p>"},{"location":"reference/#alsek.core.futures.ProcessTaskFuture.stop","title":"<code>stop(exception)</code>","text":"<p>Stop the future.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/futures.py</code> <pre><code>def stop(self, exception: Type[BaseException]) -&gt; None:\n    \"\"\"Stop the future.\n\n    Returns:\n        None\n\n    \"\"\"\n    if self._process.ident is None:  # type: ignore\n        log.error(\n            \"Process task future for %s did not start.\",\n            self.message.summary,\n        )\n        return None\n\n    self._shutdown()\n    if self._wrapper_exit_queue.empty():\n        self._wrapper_exit_queue.put(1)\n        try:\n            raise exception(f\"Stopped process {self._process.ident}\")  # type: ignore\n        except BaseException as error:\n            log.error(\"Error processing %s.\", self.message.summary, exc_info=True)\n            _error_encountered_future_handler(\n                self.task,\n                self.message,\n                exception=error,\n            )\n</code></pre>"},{"location":"reference/#alsek.core.futures.TaskFuture","title":"<code>TaskFuture</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Future for background task execution.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>a task to perform</p> required <code>message</code> <code>Message</code> <p>a message to run <code>task</code> against</p> required Source code in <code>alsek/core/futures.py</code> <pre><code>class TaskFuture(ABC):\n    \"\"\"Future for background task execution.\n\n    Args:\n        task (Task): a task to perform\n        message (Message): a message to run ``task`` against\n\n    \"\"\"\n\n    def __init__(self, task: Task, message: Message) -&gt; None:\n        self.task = task\n        self.message = message\n\n        self.created_at = utcnow_timestamp_ms()\n\n        self._revocation_stop_event = Event()\n        self._revocation_scan_thread = Thread(\n            target=self._revocation_scan,\n            daemon=True,\n        )\n\n    @property\n    @abstractmethod\n    def complete(self) -&gt; bool:\n        \"\"\"Whether the task has finished.\"\"\"\n        raise NotImplementedError()\n\n    @property\n    def time_limit_exceeded(self) -&gt; bool:\n        \"\"\"Whether task has been running longer\n        than the allowed time window.\"\"\"\n        if self.complete:\n            return False\n        return (utcnow_timestamp_ms() - self.created_at) &gt; self.message.timeout\n\n    @abstractmethod\n    def stop(self, exception: Type[BaseException]) -&gt; None:\n        \"\"\"Stop the future.\n\n        Args:\n            exception (Type[BaseException]): exception type to raise.\n\n        Returns:\n            None\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @suppress_exception(\n        TerminationError,\n        on_suppress=lambda error: log.info(\"Termination Detected\"),\n    )\n    def _revocation_scan(self, check_interval: int | float = 0.5) -&gt; None:\n        while not self.complete and not self._revocation_stop_event.is_set():\n            if self.task.is_revoked(self.message):\n                log.info(\n                    \"Evicting '%s' due to task revocation...\",\n                    self.message.summary,\n                )\n                self.stop(RevokedError)\n                _handle_failure(\n                    task=self.task,\n                    message=self.message,\n                    exception=RevokedError(f\"Task '{self.task.name}' was revoked.\"),\n                )\n                log.info(\"Evicted '%s'.\", self.message.summary)\n                break\n            self._revocation_stop_event.wait(check_interval)\n\n    def clean_up(self, ignore_errors: bool = False) -&gt; None:\n        try:\n            self._revocation_stop_event.set()\n            self._revocation_scan_thread.join(timeout=0)\n        except BaseException as error:  # noqa\n            log.error(\n                \"Clean up error encountered for task %s with message %s.\",\n                self.task.name,\n                self.message.summary,\n            )\n            if not ignore_errors:\n                raise error\n</code></pre>"},{"location":"reference/#alsek.core.futures.TaskFuture.complete","title":"<code>complete</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Whether the task has finished.</p>"},{"location":"reference/#alsek.core.futures.TaskFuture.time_limit_exceeded","title":"<code>time_limit_exceeded</code>  <code>property</code>","text":"<p>Whether task has been running longer than the allowed time window.</p>"},{"location":"reference/#alsek.core.futures.TaskFuture.stop","title":"<code>stop(exception)</code>  <code>abstractmethod</code>","text":"<p>Stop the future.</p> <p>Parameters:</p> Name Type Description Default <code>exception</code> <code>Type[BaseException]</code> <p>exception type to raise.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/futures.py</code> <pre><code>@abstractmethod\ndef stop(self, exception: Type[BaseException]) -&gt; None:\n    \"\"\"Stop the future.\n\n    Args:\n        exception (Type[BaseException]): exception type to raise.\n\n    Returns:\n        None\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/#alsek.core.futures.ThreadTaskFuture","title":"<code>ThreadTaskFuture</code>","text":"<p>               Bases: <code>TaskFuture</code></p> <p>Future for task execution in a separate thread.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>a task to perform</p> required <code>message</code> <code>Message</code> <p>a message to run <code>task</code> against</p> required <code>complete_only_on_thread_exit</code> <code>bool</code> <p>if <code>True</code>, only mark the future as complete when the thread formally exits (i.e., is not alive). Pro: more rigorous \u2014 avoids marking the task complete until the thread fully terminates. Useful when you need strict control over thread lifecycle (e.g., for resource management). Con: may lead to hanging if the thread doesn't terminate quickly (e.g., when using <code>thread_raise()</code> during revocation). This can also temporarily result in more than the allotted number of threads running, because it entails treating a thread as expired regardless of its actual status.</p> <code>False</code> Source code in <code>alsek/core/futures.py</code> <pre><code>class ThreadTaskFuture(TaskFuture):\n    \"\"\"Future for task execution in a separate thread.\n\n    Args:\n        task (Task): a task to perform\n        message (Message): a message to run ``task`` against\n        complete_only_on_thread_exit (bool): if ``True``, only mark the future\n            as complete when the thread formally exits (i.e., is not alive).\n            Pro: more rigorous \u2014 avoids marking the task complete until the thread fully terminates.\n            Useful when you need strict control over thread lifecycle (e.g., for resource management).\n            Con: may lead to hanging if the thread doesn't terminate quickly (e.g., when using\n            `thread_raise()` during revocation). This can also temporarily result in more than the\n            allotted number of threads running, because it entails treating a thread as\n            expired regardless of its actual status.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        task: Task,\n        message: Message,\n        complete_only_on_thread_exit: bool = False,\n    ) -&gt; None:\n        super().__init__(task, message=message)\n        self.complete_only_on_thread_exit = complete_only_on_thread_exit\n\n        self._wrapper_exit: bool = False\n        self._thread = Thread(target=self._wrapper, daemon=True)\n        self._thread.start()\n\n        # Note: this must go here b/c the scan depends on\n        #   `.complete`, which in turn depends on `_thread`.\n        self._revocation_scan_thread.start()\n\n    @property\n    def complete(self) -&gt; bool:\n        \"\"\"Whether the task has finished.\"\"\"\n        thread_alive = self._thread.is_alive()\n        if self.complete_only_on_thread_exit:\n            return not thread_alive\n        else:\n            # If _wrapper_exit is True, consider the task complete even if the thread is still running\n            # This ensures the future gets removed from the worker pool's _futures list\n            # and new tasks can be polled even if a revoked task's thread is still running\n            return self._wrapper_exit or not thread_alive\n\n    def _wrapper(self) -&gt; None:\n        log.info(\"Received %s...\", self.message.summary)\n        self.task.update_status(self.message, status=TaskStatus.RUNNING)\n\n        result, exception = None, None\n        try:\n            self.task.pre_op(self.message)\n            result = self.task.execute(self.message)\n            if self.task.is_revoked(self.message):\n                log.info(\n                    \"Result for %s recovered after revocation. Discarding.\",\n                    self.message.summary,\n                )\n                return None\n\n            self.message.update(exception_details=None)  # clear any existing errors\n            log.info(\"Successfully processed %s.\", self.message.summary)\n        except BaseException as error:\n            log.error(\"Error processing %s.\", self.message.summary, exc_info=True)\n            exception = error\n            self.message.update(exception_details=parse_exception(exception).as_dict())\n\n        # Post op is called here so that exception_details can be set\n        self.task.post_op(self.message, result=result)\n\n        if self._wrapper_exit:\n            log.debug(\"Thread task future finished after termination.\")\n        elif exception is not None:\n            _error_encountered_future_handler(\n                task=self.task,\n                message=self.message,\n                exception=exception,\n            )\n        else:\n            _complete_future_handler(self.task, self.message, result=result)\n\n        self._wrapper_exit = True\n\n    def stop(self, exception: Type[BaseException]) -&gt; None:\n        \"\"\"Stop the future.\n\n        Args:\n            exception (Type[BaseException]): exception type to raise.\n\n        Returns:\n            None\n\n        \"\"\"\n        if self._thread.ident is None:\n            log.error(\n                \"Thread task future for %s did not start.\",\n                self.message.summary,\n            )\n            return None\n        elif python_implementation() != \"CPython\":\n            log.error(\n                f\"Unable to raise exception {exception} in thread {self._thread.ident}. \"\n                f\"Unsupported platform '{python_implementation()}'.\"\n            )\n            return None\n\n        thread_raise(self._thread.ident, exception=exception)\n        if not self._wrapper_exit:\n            self._wrapper_exit = True\n            _error_encountered_future_handler(\n                self.task,\n                message=self.message,\n                exception=exception(f\"Stopped thread {self._thread.ident}\"),\n            )\n</code></pre>"},{"location":"reference/#alsek.core.futures.ThreadTaskFuture.complete","title":"<code>complete</code>  <code>property</code>","text":"<p>Whether the task has finished.</p>"},{"location":"reference/#alsek.core.futures.ThreadTaskFuture.stop","title":"<code>stop(exception)</code>","text":"<p>Stop the future.</p> <p>Parameters:</p> Name Type Description Default <code>exception</code> <code>Type[BaseException]</code> <p>exception type to raise.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/futures.py</code> <pre><code>def stop(self, exception: Type[BaseException]) -&gt; None:\n    \"\"\"Stop the future.\n\n    Args:\n        exception (Type[BaseException]): exception type to raise.\n\n    Returns:\n        None\n\n    \"\"\"\n    if self._thread.ident is None:\n        log.error(\n            \"Thread task future for %s did not start.\",\n            self.message.summary,\n        )\n        return None\n    elif python_implementation() != \"CPython\":\n        log.error(\n            f\"Unable to raise exception {exception} in thread {self._thread.ident}. \"\n            f\"Unsupported platform '{python_implementation()}'.\"\n        )\n        return None\n\n    thread_raise(self._thread.ident, exception=exception)\n    if not self._wrapper_exit:\n        self._wrapper_exit = True\n        _error_encountered_future_handler(\n            self.task,\n            message=self.message,\n            exception=exception(f\"Stopped thread {self._thread.ident}\"),\n        )\n</code></pre>"},{"location":"reference/#alsek.core.message","title":"<code>message</code>","text":"<p>Message</p>"},{"location":"reference/#alsek.core.message.Message","title":"<code>Message</code>","text":"<p>Alsek Message.</p> <p>Parameters:</p> Name Type Description Default <code>task_name</code> <code>str</code> <p>the name of the task for which the message is intended</p> required <code>queue</code> <code>str</code> <p>the queue for which the message was intended. If <code>None</code> the default queue will be set.</p> <code>None</code> <code>args</code> <code>(list, tuple)</code> <p>positional arguments to pass to the task's function during the execution of <code>op()</code></p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>keyword arguments to pass to the task's function during the execution of <code>op()</code></p> <code>None</code> <code>priority</code> <code>int</code> <p>priority of the message within the task. Messages with lower values will be executed before messages with higher values.</p> <code>0</code> <code>metadata</code> <code>dict</code> <p>a dictionary of user-defined message metadata. This can store any data types supported by the backend's serializer.</p> <code>None</code> <code>exception_details</code> <code>dict</code> <p>information about any exception raised while executing this message. See <code>ExceptionDetails()</code>.</p> <code>None</code> <code>result_ttl</code> <code>int</code> <p>time to live (in milliseconds) for the result in the result store. If a result store is provided and this parameter is <code>None</code>, the result will be persisted indefinitely.</p> <code>None</code> <code>uuid</code> <code>str</code> <p>universal unique identifier for the message. If <code>None</code>, one will be generated automatically.</p> <code>None</code> <code>progenitor_uuid</code> <code>str</code> <p>universal unique identifier for the message from which this message descended. (This field is only set in for tasks with triggers and/or callbacks.)</p> <code>None</code> <code>retries</code> <code>int</code> <p>number of retries</p> <code>0</code> <code>timeout</code> <code>int</code> <p>the maximum amount of time (in milliseconds) a task is permitted to run against this message.</p> <code>DEFAULT_TASK_TIMEOUT</code> <code>created_at</code> <code>int</code> <p>UTC timestamp (in milliseconds) for when the message was created</p> <code>None</code> <code>updated_at</code> <code>int</code> <p>UTC timestamp (in milliseconds) for when the message was last updated</p> <code>None</code> <code>delay</code> <code>int</code> <p>delay before the message becomes ready (in milliseconds).</p> <code>None</code> <code>previous_result</code> <code>any</code> <p>the output of any previously executed task. (This will only be non-null in cases where callbacks are used.)</p> <code>None</code> <code>previous_message_uuid</code> <code>str</code> <p>universal unique identifier for the message for the preceding message (This will only be non-null in cases where callbacks are used.)</p> <code>None</code> <code>callback_message_data</code> <code>dict</code> <p>data to construct a new message as part of a callback operation</p> <code>None</code> <code>backoff_settings</code> <code>dict</code> <p>parameters to control backoff. Expected to be of the form <code>{\"algorithm\": str, \"parameters\": dict}</code>.</p> <code>None</code> <code>mechanism</code> <code>SupportedMechanismType</code> <p>mechanism for executing the task. Must be either \"process\" or \"thread\".</p> <code>DEFAULT_MECHANISM</code> Notes <ul> <li>While not recommended, <code>timeout</code> can be disabled,   in effect, by setting it to a very large integer.</li> <li>Messages have <code>ephemeral_state</code>, which is a dictionary   where items can be added and removed as needed. However,   this state is NOT persisted to the backend, and only intended   to be used within the lifetime of a single task execution,   e.g., updating the state in <code>pre_op()</code> for use in <code>op()</code>.</li> </ul> Source code in <code>alsek/core/message.py</code> <pre><code>class Message:\n    \"\"\"Alsek Message.\n\n    Args:\n        task_name (str): the name of the task for which\n            the message is intended\n        queue (str, optional): the queue for which the message was intended.\n            If ``None`` the default queue will be set.\n        args (list, tuple, optional): positional arguments to pass to\n            the task's function during the execution of ``op()``\n        kwargs (dict, optional): keyword arguments to pass to\n            the task's function during the execution of ``op()``\n        priority (int): priority of the message within the task.\n            Messages with lower values will be executed before messages with higher values.\n        metadata (dict, optional): a dictionary of user-defined message metadata.\n            This can store any data types supported by the backend's serializer.\n        exception_details (dict, optional): information about any exception raised\n            while executing this message. See ``ExceptionDetails()``.\n        result_ttl (int, optional): time to live (in milliseconds) for the\n            result in the result store. If a result store is provided and\n            this parameter is ``None``, the result will be persisted indefinitely.\n        uuid (str, optional): universal unique identifier for the message.\n            If ``None``, one will be generated automatically.\n        progenitor_uuid (str, optional): universal unique identifier for the message\n            from which this message descended. (This field is only set in for tasks\n            with triggers and/or callbacks.)\n        retries (int): number of retries\n        timeout (int): the maximum amount of time (in milliseconds)\n            a task is permitted to run against this message.\n        created_at (int): UTC timestamp (in milliseconds) for\n            when the message was created\n        updated_at (int): UTC timestamp (in milliseconds) for\n            when the message was last updated\n        delay (int): delay before the message becomes ready (in milliseconds).\n        previous_result (any, optional): the output of any\n            previously executed task. (This will only be non-null\n            in cases where callbacks are used.)\n        previous_message_uuid (str, optional): universal unique identifier\n            for the message for the preceding message (This will only be\n            non-null in cases where callbacks are used.)\n        callback_message_data (dict, optional): data to construct\n            a new message as part of a callback operation\n        backoff_settings (dict, optional): parameters to control\n            backoff. Expected to be of the form\n            ``{\"algorithm\": str, \"parameters\": dict}``.\n        mechanism (SupportedMechanismType): mechanism for executing the task. Must\n            be either \"process\" or \"thread\".\n\n    Notes:\n        * While *not* recommended, ``timeout`` can be disabled,\n          in effect, by setting it to a very large integer.\n        * Messages have `ephemeral_state`, which is a dictionary\n          where items can be added and removed as needed. However,\n          this state is NOT persisted to the backend, and only intended\n          to be used within the lifetime of a single task execution,\n          e.g., updating the state in `pre_op()` for use in `op()`.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        task_name: str,\n        queue: Optional[str] = None,\n        args: Optional[Union[list[Any], tuple[Any, ...]]] = None,\n        kwargs: Optional[dict[Any, Any]] = None,\n        priority: int = 0,\n        metadata: Optional[dict[Any, Any]] = None,\n        exception_details: Optional[Union[dict[str, Any], ExceptionDetails]] = None,\n        result_ttl: Optional[int] = None,\n        uuid: Optional[str] = None,\n        progenitor_uuid: Optional[str] = None,\n        retries: int = 0,\n        timeout: int = DEFAULT_TASK_TIMEOUT,\n        created_at: Optional[int] = None,\n        updated_at: Optional[int] = None,\n        delay: Optional[int] = None,\n        previous_result: Optional[Any] = None,\n        previous_message_uuid: Optional[str] = None,\n        callback_message_data: Optional[dict[str, Any]] = None,\n        backoff_settings: Optional[dict[str, Any]] = None,\n        mechanism: SupportedMechanismType = DEFAULT_MECHANISM,\n        linked_lock: Optional[LinkedLock] = None,\n    ) -&gt; None:\n        self.task_name = task_name\n        self.queue = queue or DEFAULT_QUEUE\n        self.args = tuple(args) if args else tuple()\n        self.kwargs = kwargs or dict()\n        self.priority = priority\n        self.metadata = metadata\n        self._exception_details = exception_details\n        self.result_ttl = result_ttl\n        self.retries = retries\n        self.timeout = timeout\n        self.uuid = uuid or _make_uuid()\n        self.progenitor_uuid = progenitor_uuid\n        self.delay = delay or 0\n        self.previous_result = previous_result\n        self.previous_message_uuid = previous_message_uuid\n        self.callback_message_data = callback_message_data\n        self.backoff_settings = backoff_settings or ExponentialBackoff().settings\n        self.mechanism = mechanism\n        self.linked_lock = linked_lock\n\n        if created_at is None and updated_at is None:\n            self.created_at = self.updated_at = utcnow_timestamp_ms()\n        elif created_at is None or updated_at is None:\n            raise ValueError(\"Time data is corrupt\")\n        else:\n            self.created_at, self.updated_at = created_at, updated_at\n\n        self.ephemeral_state: dict[Any, Any] = dict()\n\n    @property\n    def exception_details(self) -&gt; Optional[ExceptionDetails]:\n        \"\"\"information about any exception raised.\"\"\"\n        if self._exception_details is None:\n            return None\n        elif isinstance(self._exception_details, ExceptionDetails):\n            return self._exception_details\n        elif isinstance(self._exception_details, dict):\n            return ExceptionDetails(**self._exception_details)\n        else:\n            raise ValueError(\"Unexpected `exception_details` type\")\n\n    @exception_details.setter\n    def exception_details(\n        self,\n        value: Optional[Union[ExceptionDetails, dict[str, Any]]],\n    ) -&gt; None:\n        \"\"\"Set information about any exception raised.\"\"\"\n        if isinstance(value, (ExceptionDetails, dict, type(None))):\n            self._exception_details = value\n        else:\n            raise TypeError(\"`exception_details` is invalid\")\n\n    @property\n    def data(self) -&gt; dict[str, Any]:\n        \"\"\"Underlying message data.\"\"\"\n        return dict(\n            task_name=self.task_name,\n            queue=self.queue,\n            args=self.args,\n            kwargs=self.kwargs,\n            priority=self.priority,\n            metadata=self.metadata,\n            exception_details=(\n                None\n                if self.exception_details is None\n                else self.exception_details.as_dict()\n            ),\n            result_ttl=self.result_ttl,\n            uuid=self.uuid,\n            progenitor_uuid=self.progenitor_uuid,\n            retries=self.retries,\n            timeout=self.timeout,\n            created_at=self.created_at,\n            updated_at=self.updated_at,\n            delay=self.delay,\n            previous_result=self.previous_result,\n            previous_message_uuid=self.previous_message_uuid,\n            callback_message_data=self.callback_message_data,\n            backoff_settings=self.backoff_settings,\n            mechanism=self.mechanism,\n            linked_lock=self.linked_lock,\n        )\n\n    def __repr__(self) -&gt; str:\n        params = self.data\n        for k in (\"created_at\", \"updated_at\"):\n            params[k] = from_timestamp_ms(params[k])\n        return auto_repr(self, **params)\n\n    @property\n    def summary(self) -&gt; str:\n        \"\"\"High-level summary of the message object.\"\"\"\n        return auto_repr(\n            self,\n            new_line_threshold=None,\n            uuid=self.uuid,\n            queue=self.queue,\n            task=self.task_name,\n        )\n\n    def get_backoff_duration(self) -&gt; int:\n        \"\"\"Get the amount of time to backoff (wait)\n        before the message is eligible for processing again,\n        should it fail.\n\n        Returns:\n            duration (int): duration of the backoff in milliseconds\n\n        \"\"\"\n        return settings2backoff(self.backoff_settings).get(self.retries)\n\n    @property\n    def ready_at(self) -&gt; int:\n        \"\"\"Timestamp denoting when the message will be ready for processing.\"\"\"\n        return self.created_at + self.delay + self.get_backoff_duration()\n\n    @property\n    def ready(self) -&gt; bool:\n        \"\"\"If the messages is currently ready for processing.\"\"\"\n        return self.ready_at &lt;= utcnow_timestamp_ms()\n\n    @property\n    def ttr(self) -&gt; int:\n        \"\"\"Time to ready in milliseconds.\"\"\"\n        if self.ready:\n            return 0\n        return max(self.ready_at - utcnow_timestamp_ms(), 0)\n\n    @property\n    def descendant_uuids(self) -&gt; Optional[list[str]]:\n        \"\"\"A list of uuids which have or will decent from this message.\"\"\"\n        if self.callback_message_data:\n            return list(_collect_callback_uuids(self.callback_message_data))\n        else:\n            return None\n\n    def link_lock(self, lock: Lock, override: bool = False) -&gt; Message:\n        \"\"\"Link a lock to the current message.\n\n        Links are formed against the ``long_name`` of ``lock``.\n\n        Args:\n            lock (Lock): a concurrency lock\n            override (bool): if ``True`` replace any existing lock\n\n        Returns:\n            message (Message): the updated message\n\n        Warning:\n            * Locks links are formed in memory and are\n              never persisted to the data backend.\n\n        \"\"\"\n        if self.linked_lock and not override:\n            raise AttributeError(f\"Message already linked to a lock\")\n        else:\n            self.linked_lock = LinkedLock(\n                name=lock.name,\n                owner_id=lock.owner_id,\n            )\n        return self\n\n    def release_lock(self, not_linked_ok: bool, target_backend: Backend) -&gt; bool:\n        \"\"\"Release the lock linked to the message.\n\n        Args:\n            not_linked_ok (bool): if ``True`` do not raise if no lock is found\n            target_backend (Backend): a backend to release the lock from.\n\n        Returns:\n            success (bool): if the lock was released successfully.\n\n        Raises:\n            AttributeError: if no lock is associated with the message\n                and ``missing_ok`` is not ``True``.\n\n        \"\"\"\n        log.info(\"Releasing lock for %s...\", self.summary)\n        if self.linked_lock:\n            # ToDo: the backend passed into might not be the same\n            #   one that was used to create the lock. Without also\n            #   saving the backend information along with 'name' and\n            #   'owner_id' we have no way of knowing that. Fix.\n            try:\n                Lock(\n                    self.linked_lock[\"name\"],\n                    backend=target_backend,\n                    owner_id=self.linked_lock[\"owner_id\"],\n                ).release(raise_if_not_acquired=True)\n                log.info(\"Released lock for %s.\", self.summary)\n                self.linked_lock = None\n                return True\n            except redis_lock.NotAcquired:  # noqa\n                log.critical(\n                    \"Failed to release lock for %s\",\n                    self.summary,\n                    exc_info=True,\n                )\n                return False\n        elif not_linked_ok:\n            return False\n        else:\n            raise AttributeError(\"No lock linked to message\")\n\n    def clone(self) -&gt; Message:\n        \"\"\"Create an exact copy of the current message.\n\n        Returns:\n            clone (Message): the cloned message\n\n        \"\"\"\n        return Message(**deepcopy(self.data))\n\n    def update(self, **data: Any) -&gt; Message:\n        \"\"\"Update the ``data`` in the current message.\n\n        Args:\n            **data (Keyword Args): key value pairs of\n                data to update\n\n        Returns:\n            updated_message (Message): the updated message\n\n        Warning:\n            * This method operates 'in place'. To avoid changing the current\n              message, first call ``.clone()``, e.g., ``message.clone().update(...)``.\n            * Changes are *not* automatically persisted to the backend.\n\n        \"\"\"\n        for k, v in data.items():\n            if k in self.data:\n                setattr(self, k, v)\n            else:\n                raise KeyError(f\"Unsupported key '{k}'\")\n        return self\n\n    def add_to_metadata(self, **data: Any) -&gt; Message:\n        \"\"\"Adds metadata to the current instance by merging provided data into\n        the existing metadata. The function performs a non-inplace merge operation,\n        ensuring the original metadata is not directly altered unless returned and\n        reassigned.\n\n        Args:\n            **data: Key-value pairs to merge into the existing metadata.\n\n        Returns:\n            Message: The updated instance with the merged metadata.\n        \"\"\"\n        if not data:\n            raise ValueError(\"No data provided to add to metadata.\")\n\n        self.metadata = dict_merge_update_into_origin(\n            origin=self.metadata or dict(),\n            update=data,\n            inplace=False,\n        )\n        return self\n\n    def add_to_ephemeral_state(self, **data: Any) -&gt; Message:\n        \"\"\"Adds ephemeral information to the current instance by merging provided data into\n        the existing `ephemeral_state`. The function performs a non-inplace merge operation,\n        ensuring the original metadata is not directly altered unless returned\n        and reassigned.\n\n        Args:\n            **data: Key-value pairs to merge into the existing metadata.\n\n        Returns:\n            Message: The updated instance with the merged metadata.\n        \"\"\"\n        if not data:\n            raise ValueError(\"No data provided to add to metadata.\")\n\n        self.ephemeral_state = dict_merge_update_into_origin(\n            origin=self.ephemeral_state or dict(),\n            update=data,\n            inplace=False,\n        )\n        return self\n\n    def duplicate(self, uuid: Optional[str] = None) -&gt; Message:\n        \"\"\"Create a duplicate of the current message, changing only ``uuid``.\n\n        Args:\n            uuid (str, optional): universal unique identifier for the new message.\n                If ``None``, one will be generated automatically.\n\n        Returns:\n            duplicate_message (Message): the duplicate message\n\n        Warning:\n            * Linked locks are not conserved\n\n        \"\"\"\n        return self.clone().update(uuid=uuid or _make_uuid())\n\n    def increment_retries(self) -&gt; Message:\n        \"\"\"Update a message by increasing the number\n        of retries.\n\n        Returns:\n            message (Message): the updated message\n\n        Notes:\n            * ``updated_at`` will be updated to the\n               current time.\n\n        Warning:\n            * Changes are *not* automatically persisted to the backend.\n\n        \"\"\"\n        return self.update(\n            retries=self.retries + 1,\n            updated_at=utcnow_timestamp_ms(),\n        )\n</code></pre>"},{"location":"reference/#alsek.core.message.Message.data","title":"<code>data</code>  <code>property</code>","text":"<p>Underlying message data.</p>"},{"location":"reference/#alsek.core.message.Message.descendant_uuids","title":"<code>descendant_uuids</code>  <code>property</code>","text":"<p>A list of uuids which have or will decent from this message.</p>"},{"location":"reference/#alsek.core.message.Message.exception_details","title":"<code>exception_details</code>  <code>property</code> <code>writable</code>","text":"<p>information about any exception raised.</p>"},{"location":"reference/#alsek.core.message.Message.ready","title":"<code>ready</code>  <code>property</code>","text":"<p>If the messages is currently ready for processing.</p>"},{"location":"reference/#alsek.core.message.Message.ready_at","title":"<code>ready_at</code>  <code>property</code>","text":"<p>Timestamp denoting when the message will be ready for processing.</p>"},{"location":"reference/#alsek.core.message.Message.summary","title":"<code>summary</code>  <code>property</code>","text":"<p>High-level summary of the message object.</p>"},{"location":"reference/#alsek.core.message.Message.ttr","title":"<code>ttr</code>  <code>property</code>","text":"<p>Time to ready in milliseconds.</p>"},{"location":"reference/#alsek.core.message.Message.add_to_ephemeral_state","title":"<code>add_to_ephemeral_state(**data)</code>","text":"<p>Adds ephemeral information to the current instance by merging provided data into the existing <code>ephemeral_state</code>. The function performs a non-inplace merge operation, ensuring the original metadata is not directly altered unless returned and reassigned.</p> <p>Parameters:</p> Name Type Description Default <code>**data</code> <code>Any</code> <p>Key-value pairs to merge into the existing metadata.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Message</code> <code>Message</code> <p>The updated instance with the merged metadata.</p> Source code in <code>alsek/core/message.py</code> <pre><code>def add_to_ephemeral_state(self, **data: Any) -&gt; Message:\n    \"\"\"Adds ephemeral information to the current instance by merging provided data into\n    the existing `ephemeral_state`. The function performs a non-inplace merge operation,\n    ensuring the original metadata is not directly altered unless returned\n    and reassigned.\n\n    Args:\n        **data: Key-value pairs to merge into the existing metadata.\n\n    Returns:\n        Message: The updated instance with the merged metadata.\n    \"\"\"\n    if not data:\n        raise ValueError(\"No data provided to add to metadata.\")\n\n    self.ephemeral_state = dict_merge_update_into_origin(\n        origin=self.ephemeral_state or dict(),\n        update=data,\n        inplace=False,\n    )\n    return self\n</code></pre>"},{"location":"reference/#alsek.core.message.Message.add_to_metadata","title":"<code>add_to_metadata(**data)</code>","text":"<p>Adds metadata to the current instance by merging provided data into the existing metadata. The function performs a non-inplace merge operation, ensuring the original metadata is not directly altered unless returned and reassigned.</p> <p>Parameters:</p> Name Type Description Default <code>**data</code> <code>Any</code> <p>Key-value pairs to merge into the existing metadata.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Message</code> <code>Message</code> <p>The updated instance with the merged metadata.</p> Source code in <code>alsek/core/message.py</code> <pre><code>def add_to_metadata(self, **data: Any) -&gt; Message:\n    \"\"\"Adds metadata to the current instance by merging provided data into\n    the existing metadata. The function performs a non-inplace merge operation,\n    ensuring the original metadata is not directly altered unless returned and\n    reassigned.\n\n    Args:\n        **data: Key-value pairs to merge into the existing metadata.\n\n    Returns:\n        Message: The updated instance with the merged metadata.\n    \"\"\"\n    if not data:\n        raise ValueError(\"No data provided to add to metadata.\")\n\n    self.metadata = dict_merge_update_into_origin(\n        origin=self.metadata or dict(),\n        update=data,\n        inplace=False,\n    )\n    return self\n</code></pre>"},{"location":"reference/#alsek.core.message.Message.clone","title":"<code>clone()</code>","text":"<p>Create an exact copy of the current message.</p> <p>Returns:</p> Name Type Description <code>clone</code> <code>Message</code> <p>the cloned message</p> Source code in <code>alsek/core/message.py</code> <pre><code>def clone(self) -&gt; Message:\n    \"\"\"Create an exact copy of the current message.\n\n    Returns:\n        clone (Message): the cloned message\n\n    \"\"\"\n    return Message(**deepcopy(self.data))\n</code></pre>"},{"location":"reference/#alsek.core.message.Message.duplicate","title":"<code>duplicate(uuid=None)</code>","text":"<p>Create a duplicate of the current message, changing only <code>uuid</code>.</p> <p>Parameters:</p> Name Type Description Default <code>uuid</code> <code>str</code> <p>universal unique identifier for the new message. If <code>None</code>, one will be generated automatically.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>duplicate_message</code> <code>Message</code> <p>the duplicate message</p> Warning <ul> <li>Linked locks are not conserved</li> </ul> Source code in <code>alsek/core/message.py</code> <pre><code>def duplicate(self, uuid: Optional[str] = None) -&gt; Message:\n    \"\"\"Create a duplicate of the current message, changing only ``uuid``.\n\n    Args:\n        uuid (str, optional): universal unique identifier for the new message.\n            If ``None``, one will be generated automatically.\n\n    Returns:\n        duplicate_message (Message): the duplicate message\n\n    Warning:\n        * Linked locks are not conserved\n\n    \"\"\"\n    return self.clone().update(uuid=uuid or _make_uuid())\n</code></pre>"},{"location":"reference/#alsek.core.message.Message.get_backoff_duration","title":"<code>get_backoff_duration()</code>","text":"<p>Get the amount of time to backoff (wait) before the message is eligible for processing again, should it fail.</p> <p>Returns:</p> Name Type Description <code>duration</code> <code>int</code> <p>duration of the backoff in milliseconds</p> Source code in <code>alsek/core/message.py</code> <pre><code>def get_backoff_duration(self) -&gt; int:\n    \"\"\"Get the amount of time to backoff (wait)\n    before the message is eligible for processing again,\n    should it fail.\n\n    Returns:\n        duration (int): duration of the backoff in milliseconds\n\n    \"\"\"\n    return settings2backoff(self.backoff_settings).get(self.retries)\n</code></pre>"},{"location":"reference/#alsek.core.message.Message.increment_retries","title":"<code>increment_retries()</code>","text":"<p>Update a message by increasing the number of retries.</p> <p>Returns:</p> Name Type Description <code>message</code> <code>Message</code> <p>the updated message</p> Notes <ul> <li><code>updated_at</code> will be updated to the    current time.</li> </ul> Warning <ul> <li>Changes are not automatically persisted to the backend.</li> </ul> Source code in <code>alsek/core/message.py</code> <pre><code>def increment_retries(self) -&gt; Message:\n    \"\"\"Update a message by increasing the number\n    of retries.\n\n    Returns:\n        message (Message): the updated message\n\n    Notes:\n        * ``updated_at`` will be updated to the\n           current time.\n\n    Warning:\n        * Changes are *not* automatically persisted to the backend.\n\n    \"\"\"\n    return self.update(\n        retries=self.retries + 1,\n        updated_at=utcnow_timestamp_ms(),\n    )\n</code></pre>"},{"location":"reference/#alsek.core.message.Message.link_lock","title":"<code>link_lock(lock, override=False)</code>","text":"<p>Link a lock to the current message.</p> <p>Links are formed against the <code>long_name</code> of <code>lock</code>.</p> <p>Parameters:</p> Name Type Description Default <code>lock</code> <code>Lock</code> <p>a concurrency lock</p> required <code>override</code> <code>bool</code> <p>if <code>True</code> replace any existing lock</p> <code>False</code> <p>Returns:</p> Name Type Description <code>message</code> <code>Message</code> <p>the updated message</p> Warning <ul> <li>Locks links are formed in memory and are   never persisted to the data backend.</li> </ul> Source code in <code>alsek/core/message.py</code> <pre><code>def link_lock(self, lock: Lock, override: bool = False) -&gt; Message:\n    \"\"\"Link a lock to the current message.\n\n    Links are formed against the ``long_name`` of ``lock``.\n\n    Args:\n        lock (Lock): a concurrency lock\n        override (bool): if ``True`` replace any existing lock\n\n    Returns:\n        message (Message): the updated message\n\n    Warning:\n        * Locks links are formed in memory and are\n          never persisted to the data backend.\n\n    \"\"\"\n    if self.linked_lock and not override:\n        raise AttributeError(f\"Message already linked to a lock\")\n    else:\n        self.linked_lock = LinkedLock(\n            name=lock.name,\n            owner_id=lock.owner_id,\n        )\n    return self\n</code></pre>"},{"location":"reference/#alsek.core.message.Message.release_lock","title":"<code>release_lock(not_linked_ok, target_backend)</code>","text":"<p>Release the lock linked to the message.</p> <p>Parameters:</p> Name Type Description Default <code>not_linked_ok</code> <code>bool</code> <p>if <code>True</code> do not raise if no lock is found</p> required <code>target_backend</code> <code>Backend</code> <p>a backend to release the lock from.</p> required <p>Returns:</p> Name Type Description <code>success</code> <code>bool</code> <p>if the lock was released successfully.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>if no lock is associated with the message and <code>missing_ok</code> is not <code>True</code>.</p> Source code in <code>alsek/core/message.py</code> <pre><code>def release_lock(self, not_linked_ok: bool, target_backend: Backend) -&gt; bool:\n    \"\"\"Release the lock linked to the message.\n\n    Args:\n        not_linked_ok (bool): if ``True`` do not raise if no lock is found\n        target_backend (Backend): a backend to release the lock from.\n\n    Returns:\n        success (bool): if the lock was released successfully.\n\n    Raises:\n        AttributeError: if no lock is associated with the message\n            and ``missing_ok`` is not ``True``.\n\n    \"\"\"\n    log.info(\"Releasing lock for %s...\", self.summary)\n    if self.linked_lock:\n        # ToDo: the backend passed into might not be the same\n        #   one that was used to create the lock. Without also\n        #   saving the backend information along with 'name' and\n        #   'owner_id' we have no way of knowing that. Fix.\n        try:\n            Lock(\n                self.linked_lock[\"name\"],\n                backend=target_backend,\n                owner_id=self.linked_lock[\"owner_id\"],\n            ).release(raise_if_not_acquired=True)\n            log.info(\"Released lock for %s.\", self.summary)\n            self.linked_lock = None\n            return True\n        except redis_lock.NotAcquired:  # noqa\n            log.critical(\n                \"Failed to release lock for %s\",\n                self.summary,\n                exc_info=True,\n            )\n            return False\n    elif not_linked_ok:\n        return False\n    else:\n        raise AttributeError(\"No lock linked to message\")\n</code></pre>"},{"location":"reference/#alsek.core.message.Message.update","title":"<code>update(**data)</code>","text":"<p>Update the <code>data</code> in the current message.</p> <p>Parameters:</p> Name Type Description Default <code>**data</code> <code>Keyword Args</code> <p>key value pairs of data to update</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>updated_message</code> <code>Message</code> <p>the updated message</p> Warning <ul> <li>This method operates 'in place'. To avoid changing the current   message, first call <code>.clone()</code>, e.g., <code>message.clone().update(...)</code>.</li> <li>Changes are not automatically persisted to the backend.</li> </ul> Source code in <code>alsek/core/message.py</code> <pre><code>def update(self, **data: Any) -&gt; Message:\n    \"\"\"Update the ``data`` in the current message.\n\n    Args:\n        **data (Keyword Args): key value pairs of\n            data to update\n\n    Returns:\n        updated_message (Message): the updated message\n\n    Warning:\n        * This method operates 'in place'. To avoid changing the current\n          message, first call ``.clone()``, e.g., ``message.clone().update(...)``.\n        * Changes are *not* automatically persisted to the backend.\n\n    \"\"\"\n    for k, v in data.items():\n        if k in self.data:\n            setattr(self, k, v)\n        else:\n            raise KeyError(f\"Unsupported key '{k}'\")\n    return self\n</code></pre>"},{"location":"reference/#alsek.core.status","title":"<code>status</code>","text":""},{"location":"reference/#alsek.core.status.abstract","title":"<code>abstract</code>","text":"<p>Abstract Status</p>"},{"location":"reference/#alsek.core.status.abstract.BaseStatusTracker","title":"<code>BaseStatusTracker</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Alsek Status Tracker.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>BaseBackend</code> <p>backend to persists results to. (In almost all cases, this should be the same backend used by the Broker).</p> required <code>ttl</code> <code>int</code> <p>time to live (in milliseconds) for the status</p> <code>DEFAULT_TTL</code> <code>enable_pubsub</code> <code>bool</code> <p>if <code>True</code> automatically publish PUBSUB updates. If <code>None</code> determine automatically given the capabilities of the backend used by <code>broker</code>.</p> <code>None</code> Source code in <code>alsek/core/status/abstract.py</code> <pre><code>class BaseStatusTracker(ABC):\n    \"\"\"Alsek Status Tracker.\n\n    Args:\n        backend (BaseBackend): backend to persists results to. (In almost all cases, this\n            should be the same backend used by the Broker).\n        ttl (int, optional): time to live (in milliseconds) for the status\n        enable_pubsub (bool, optional): if ``True`` automatically publish PUBSUB updates.\n            If ``None`` determine automatically given the capabilities of the backend\n            used by ``broker``.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        backend: BaseBackend,\n        ttl: Optional[int] = DEFAULT_TTL,\n        enable_pubsub: Optional[bool] = None,\n    ) -&gt; None:\n        self.backend = backend\n        self.ttl = ttl\n        self.enable_pubsub = backend.SUPPORTS_PUBSUB if enable_pubsub is None else enable_pubsub  # fmt: skip\n\n        if enable_pubsub and not backend.SUPPORTS_PUBSUB:\n            raise AssertionError(\"Backend does not support PUBSUB\")\n\n    def serialize(self) -&gt; dict[str, Any]:\n        return {\n            \"backend\": self.backend.encode(),\n            \"ttl\": self.ttl,\n            \"enable_pubsub\": self.enable_pubsub,\n        }\n\n    @staticmethod\n    @abstractmethod\n    def deserialize(data: dict[str, Any]) -&gt; BaseStatusTracker:\n        raise NotImplementedError()\n\n    @staticmethod\n    def get_storage_name(message: Message) -&gt; str:\n        \"\"\"Get the key for the status information about the message\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            name (string): the key for the status information\n\n        \"\"\"\n        if not message.queue or not message.task_name or not message.uuid:\n            raise ValidationError(\"Required attributes not set for message\")\n        return f\"status:{message.queue}:{message.task_name}:{message.uuid}\"\n\n    @staticmethod\n    def get_pubsub_name(message: Message) -&gt; str:\n        \"\"\"Get the channel for status updates about the message.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            name (string): the channel for the status information\n\n        \"\"\"\n        if not message.queue or not message.task_name or not message.uuid:\n            raise ValidationError(\"Required attributes not set for message\")\n        return f\"channel:{message.queue}:{message.task_name}:{message.uuid}\"\n\n    @abstractmethod\n    def exists(self, message: Message) -&gt; bool:\n        \"\"\"Check if a status for ``message`` exists in the backend.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            bool\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def publish_update(self, message: Message, update: StatusUpdate) -&gt; None:\n        \"\"\"Publish a PUBSUB update for a message.\n\n        Args:\n            message (Message): an Alsek message\n            update (StatusUpdate): a status to publish\n\n        Returns:\n            None\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def listen_to_updates(\n        self,\n        message: Message,\n        auto_exit: bool = True,\n    ) -&gt; Iterable[StatusUpdate] | AsyncIterable[StatusUpdate]:\n        \"\"\"Listen to PUBSUB updates for ``message``.\n\n        Args:\n            message (Message): an Alsek message\n            auto_exit (bool): if ``True`` stop listening if a terminal status for the\n                task is encountered (succeeded or failed).\n\n        Returns:\n            stream (Iterable[StatusUpdate] | AsyncIterable[StatusUpdate]): A stream of updates from the pubsub channel\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def set(\n        self,\n        message: Message,\n        status: TaskStatus,\n        details: Optional[Any] = None,\n    ) -&gt; None:\n        \"\"\"Set a ``status`` for ``message``.\n\n        Args:\n            message (Message): an Alsek message\n            status (TaskStatus): a status to set\n            details (Any, optional): additional information about the status (e.g., progress percentage)\n\n        Returns:\n            None\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def get(self, message: Message) -&gt; StatusUpdate:\n        \"\"\"Get the status of ``message``.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            status (StatusUpdate): the status of ``message``\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def wait_for(\n        self,\n        message: Message,\n        status: TaskStatus | tuple[TaskStatus, ...] | list[TaskStatus],\n        timeout: Optional[float] = 5.0,\n        poll_interval: float = 0.05,\n        raise_on_timeout: bool = True,\n    ) -&gt; TaskStatus:\n        \"\"\"Wait for a message to reach a desired status.\n\n        Args:\n            message (Message): the message to monitor\n            status (TaskStatus, tuple[TaskStatus...], list[TaskStatus]): the target status\n            timeout (float, optional): max time to wait (in seconds). None means wait forever.\n            poll_interval (float): how often to check (in seconds)\n           raise_on_timeout (bool): if ``True`` raise a ``TimeoutError`` if waiting times out\n                otherwise return the current status\n\n        Returns:\n            status (TaskStatus): the status of ``message`` after waiting.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def delete(self, message: Message, check: bool = True) -&gt; None:\n        \"\"\"Delete the status of ``message``.\n\n        Args:\n            message (Message): an Alsek message\n            check (bool): check that it is safe to delete the status.\n                This is done by ensuring that the current status of ``message``\n                is terminal (i.e., ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``).\n\n        Returns:\n            None\n\n        Raises:\n            ValidationError: if ``check`` is ``True`` and the status of\n                ``message`` is not ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``.\n\n        \"\"\"\n        raise NotImplementedError()\n</code></pre> <code>delete(message, check=True)</code> <code>abstractmethod</code> <p>Delete the status of <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>check</code> <code>bool</code> <p>check that it is safe to delete the status. This is done by ensuring that the current status of <code>message</code> is terminal (i.e., <code>TaskStatus.FAILED</code> or <code>TaskStatus.SUCCEEDED</code>).</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>if <code>check</code> is <code>True</code> and the status of <code>message</code> is not <code>TaskStatus.FAILED</code> or <code>TaskStatus.SUCCEEDED</code>.</p> Source code in <code>alsek/core/status/abstract.py</code> <pre><code>@abstractmethod\ndef delete(self, message: Message, check: bool = True) -&gt; None:\n    \"\"\"Delete the status of ``message``.\n\n    Args:\n        message (Message): an Alsek message\n        check (bool): check that it is safe to delete the status.\n            This is done by ensuring that the current status of ``message``\n            is terminal (i.e., ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``).\n\n    Returns:\n        None\n\n    Raises:\n        ValidationError: if ``check`` is ``True`` and the status of\n            ``message`` is not ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>exists(message)</code> <code>abstractmethod</code> <p>Check if a status for <code>message</code> exists in the backend.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>alsek/core/status/abstract.py</code> <pre><code>@abstractmethod\ndef exists(self, message: Message) -&gt; bool:\n    \"\"\"Check if a status for ``message`` exists in the backend.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        bool\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>get(message)</code> <code>abstractmethod</code> <p>Get the status of <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>status</code> <code>StatusUpdate</code> <p>the status of <code>message</code></p> Source code in <code>alsek/core/status/abstract.py</code> <pre><code>@abstractmethod\ndef get(self, message: Message) -&gt; StatusUpdate:\n    \"\"\"Get the status of ``message``.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        status (StatusUpdate): the status of ``message``\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>get_pubsub_name(message)</code> <code>staticmethod</code> <p>Get the channel for status updates about the message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>name</code> <code>string</code> <p>the channel for the status information</p> Source code in <code>alsek/core/status/abstract.py</code> <pre><code>@staticmethod\ndef get_pubsub_name(message: Message) -&gt; str:\n    \"\"\"Get the channel for status updates about the message.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        name (string): the channel for the status information\n\n    \"\"\"\n    if not message.queue or not message.task_name or not message.uuid:\n        raise ValidationError(\"Required attributes not set for message\")\n    return f\"channel:{message.queue}:{message.task_name}:{message.uuid}\"\n</code></pre> <code>get_storage_name(message)</code> <code>staticmethod</code> <p>Get the key for the status information about the message</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>name</code> <code>string</code> <p>the key for the status information</p> Source code in <code>alsek/core/status/abstract.py</code> <pre><code>@staticmethod\ndef get_storage_name(message: Message) -&gt; str:\n    \"\"\"Get the key for the status information about the message\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        name (string): the key for the status information\n\n    \"\"\"\n    if not message.queue or not message.task_name or not message.uuid:\n        raise ValidationError(\"Required attributes not set for message\")\n    return f\"status:{message.queue}:{message.task_name}:{message.uuid}\"\n</code></pre> <code>listen_to_updates(message, auto_exit=True)</code> <code>abstractmethod</code> <p>Listen to PUBSUB updates for <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>auto_exit</code> <code>bool</code> <p>if <code>True</code> stop listening if a terminal status for the task is encountered (succeeded or failed).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>stream</code> <code>Iterable[StatusUpdate] | AsyncIterable[StatusUpdate]</code> <p>A stream of updates from the pubsub channel</p> Source code in <code>alsek/core/status/abstract.py</code> <pre><code>@abstractmethod\ndef listen_to_updates(\n    self,\n    message: Message,\n    auto_exit: bool = True,\n) -&gt; Iterable[StatusUpdate] | AsyncIterable[StatusUpdate]:\n    \"\"\"Listen to PUBSUB updates for ``message``.\n\n    Args:\n        message (Message): an Alsek message\n        auto_exit (bool): if ``True`` stop listening if a terminal status for the\n            task is encountered (succeeded or failed).\n\n    Returns:\n        stream (Iterable[StatusUpdate] | AsyncIterable[StatusUpdate]): A stream of updates from the pubsub channel\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>publish_update(message, update)</code> <code>abstractmethod</code> <p>Publish a PUBSUB update for a message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>update</code> <code>StatusUpdate</code> <p>a status to publish</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/status/abstract.py</code> <pre><code>@abstractmethod\ndef publish_update(self, message: Message, update: StatusUpdate) -&gt; None:\n    \"\"\"Publish a PUBSUB update for a message.\n\n    Args:\n        message (Message): an Alsek message\n        update (StatusUpdate): a status to publish\n\n    Returns:\n        None\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>set(message, status, details=None)</code> <code>abstractmethod</code> <p>Set a <code>status</code> for <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>status</code> <code>TaskStatus</code> <p>a status to set</p> required <code>details</code> <code>Any</code> <p>additional information about the status (e.g., progress percentage)</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/status/abstract.py</code> <pre><code>@abstractmethod\ndef set(\n    self,\n    message: Message,\n    status: TaskStatus,\n    details: Optional[Any] = None,\n) -&gt; None:\n    \"\"\"Set a ``status`` for ``message``.\n\n    Args:\n        message (Message): an Alsek message\n        status (TaskStatus): a status to set\n        details (Any, optional): additional information about the status (e.g., progress percentage)\n\n    Returns:\n        None\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>wait_for(message, status, timeout=5.0, poll_interval=0.05, raise_on_timeout=True)</code> <code>abstractmethod</code> <p>Wait for a message to reach a desired status.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>the message to monitor</p> required <code>status</code> <code>TaskStatus, tuple[TaskStatus...], list[TaskStatus]</code> <p>the target status</p> required <code>timeout</code> <code>float</code> <p>max time to wait (in seconds). None means wait forever.</p> <code>5.0</code> <code>poll_interval</code> <code>float</code> <p>how often to check (in seconds)</p> <code>0.05</code> <p>raise_on_timeout (bool): if <code>True</code> raise a <code>TimeoutError</code> if waiting times out         otherwise return the current status</p> <p>Returns:</p> Name Type Description <code>status</code> <code>TaskStatus</code> <p>the status of <code>message</code> after waiting.</p> Source code in <code>alsek/core/status/abstract.py</code> <pre><code>@abstractmethod\ndef wait_for(\n    self,\n    message: Message,\n    status: TaskStatus | tuple[TaskStatus, ...] | list[TaskStatus],\n    timeout: Optional[float] = 5.0,\n    poll_interval: float = 0.05,\n    raise_on_timeout: bool = True,\n) -&gt; TaskStatus:\n    \"\"\"Wait for a message to reach a desired status.\n\n    Args:\n        message (Message): the message to monitor\n        status (TaskStatus, tuple[TaskStatus...], list[TaskStatus]): the target status\n        timeout (float, optional): max time to wait (in seconds). None means wait forever.\n        poll_interval (float): how often to check (in seconds)\n       raise_on_timeout (bool): if ``True`` raise a ``TimeoutError`` if waiting times out\n            otherwise return the current status\n\n    Returns:\n        status (TaskStatus): the status of ``message`` after waiting.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/#alsek.core.status.asyncio","title":"<code>asyncio</code>","text":"<p>Async Status Tracker</p>"},{"location":"reference/#alsek.core.status.asyncio.AsyncStatusTracker","title":"<code>AsyncStatusTracker</code>","text":"<p>               Bases: <code>BaseStatusTracker</code></p> Source code in <code>alsek/core/status/asyncio.py</code> <pre><code>class AsyncStatusTracker(BaseStatusTracker):\n    __doc__ = f\"Async {BaseStatusTracker.__doc__}\"\n\n    def __init__(self, backend: AsyncBackend, **kwargs: Any) -&gt; None:\n        super().__init__(backend=backend, **kwargs)\n        # Redundant, but needed for the PyCharm's type\n        # checker to understand that self.backend is `AsyncBackend`.\n        self.backend = cast(AsyncBackend, self.backend)\n\n        if not self.backend.IS_ASYNC:\n            raise AssertionError(\"Backend is not async\")\n\n    @staticmethod\n    def deserialize(data: dict[str, Any]) -&gt; AsyncStatusTracker:\n        backend_data = dill.loads(data[\"backend\"])\n        backend = backend_data[\"backend\"].from_settings(backend_data[\"settings\"])\n        return AsyncStatusTracker(\n            backend=backend,\n            ttl=data[\"ttl\"],\n            enable_pubsub=data[\"enable_pubsub\"],\n        )\n\n    async def exists(self, message: Message) -&gt; bool:\n        \"\"\"Check if a status for ``message`` exists in the backend.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            bool\n\n        \"\"\"\n        return await self.backend.exists(self.get_storage_name(message))\n\n    async def publish_update(self, message: Message, update: StatusUpdate) -&gt; None:\n        \"\"\"Publish a PUBSUB update for a message.\n\n        Args:\n            message (Message): an Alsek message\n            update (StatusUpdate): a status to publish\n\n        Returns:\n            None\n\n        \"\"\"\n        await self.backend.pub(\n            self.get_pubsub_name(message),\n            value=update.as_dict(),  # converting to dict makes this serializer-agnostic\n        )\n\n    async def listen_to_updates(\n        self,\n        message: Message,\n        auto_exit: bool = True,\n    ) -&gt; AsyncIterable[StatusUpdate]:\n        \"\"\"Listen to PUBSUB updates for ``message``.\n\n        Args:\n            message (Message): an Alsek message\n            auto_exit (bool): if ``True`` stop listening if a terminal status for the\n                task is encountered (succeeded or failed).\n\n        Returns:\n            stream (AsyncIterable[StatusUpdate]): A stream of updates from the pubsub channel\n\n        \"\"\"\n        if not self.enable_pubsub:\n            raise ValueError(\"PUBSUB not enabled\")\n\n        async for i in self.backend.sub(self.get_pubsub_name(message)):\n            if i.get(\"type\", \"\").lower() == \"message\":\n                update = StatusUpdate(\n                    status=TaskStatus[i[\"data\"][\"status\"]],  # noqa\n                    details=i[\"data\"][\"details\"],  # noqa\n                )\n                yield update\n                if auto_exit and update.status in TERMINAL_TASK_STATUSES:\n                    break\n\n    async def set(\n        self,\n        message: Message,\n        status: TaskStatus,\n        details: Optional[Any] = None,\n    ) -&gt; None:\n        \"\"\"Set a ``status`` for ``message``.\n\n        Args:\n            message (Message): an Alsek message\n            status (TaskStatus): a status to set\n            details (Any, optional): additional information about the status (e.g., progress percentage)\n\n        Returns:\n            None\n\n        \"\"\"\n        update = StatusUpdate(status=status, details=details)\n        await self.backend.set(\n            self.get_storage_name(message),\n            value=update.as_dict(),\n            ttl=self.ttl if status == TaskStatus.SUBMITTED else None,\n        )\n        if self.enable_pubsub:\n            await self.publish_update(message, update=update)\n\n    async def get(self, message: Message) -&gt; StatusUpdate:\n        \"\"\"Get the status of ``message``.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            status (StatusUpdate): the status of ``message``\n\n        \"\"\"\n        if value := await self.backend.get(self.get_storage_name(message)):\n            return StatusUpdate(\n                status=TaskStatus[value[\"status\"]],  # noqa\n                details=value[\"details\"],\n            )\n        else:\n            raise KeyError(f\"No status found for message '{message.summary}'\")\n\n    async def wait_for(\n        self,\n        message: Message,\n        status: TaskStatus | tuple[TaskStatus, ...] | list[TaskStatus],\n        timeout: Optional[float] = 5.0,\n        poll_interval: float = 0.05,\n        raise_on_timeout: bool = True,\n    ) -&gt; TaskStatus:\n        \"\"\"Wait for a message to reach a desired status.\n\n        Args:\n            message (Message): the message to monitor\n            status (TaskStatus, tuple[TaskStatus...], list[TaskStatus]): the target status\n            timeout (float, optional): max time to wait (in seconds). None means wait forever.\n            poll_interval (float): how often to check (in seconds)\n            raise_on_timeout (bool): if ``True`` raise a ``TimeoutError`` if waiting times out\n                otherwise return the current status\n\n        Returns:\n            status (TaskStatus): the status of ``message`` after waiting\n\n        \"\"\"\n        current_status: Optional[TaskStatus] = None\n        if not isinstance(status, TaskStatus) and not isinstance(status, (list, tuple)):\n            raise ValueError(f\"Invalid status type: {type(status)}\")\n\n        def is_current_status_match() -&gt; bool:\n            if current_status is None:\n                return False\n            elif isinstance(status, TaskStatus):\n                return current_status == status\n            elif isinstance(status, (list, tuple)):\n                return current_status in status\n            else:\n                raise ValueError(f\"Invalid status type: {type(status)}\")\n\n        deadline = None if timeout is None else time.time() + timeout\n        while True:\n            try:\n                current_status = (await self.get(message)).status\n                if is_current_status_match():\n                    return current_status\n            except KeyError:\n                pass\n            if deadline is not None and time.time() &gt; deadline:\n                if raise_on_timeout:\n                    raise TimeoutError(f\"Timeout waiting for '{message.summary}'\")\n                else:\n                    return TaskStatus.UNKNOWN if current_status is None else current_status  # fmt: skip\n            await asyncio.sleep(poll_interval)\n\n    async def delete(self, message: Message, check: bool = True) -&gt; None:\n        \"\"\"Delete the status of ``message``.\n\n        Args:\n            message (Message): an Alsek message\n            check (bool): check that it is safe to delete the status.\n                This is done by ensuring that the current status of ``message``\n                is terminal (i.e., ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``).\n\n        Returns:\n            None\n\n        Raises:\n            ValidationError: if ``check`` is ``True`` and the status of\n                ``message`` is not ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``.\n\n        \"\"\"\n        if check and (await self.get(message)).status not in TERMINAL_TASK_STATUSES:\n            raise ValidationError(f\"Message '{message.uuid}' in a non-terminal state\")\n        await self.backend.delete(self.get_storage_name(message), missing_ok=False)\n</code></pre> <code>delete(message, check=True)</code> <code>async</code> <p>Delete the status of <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>check</code> <code>bool</code> <p>check that it is safe to delete the status. This is done by ensuring that the current status of <code>message</code> is terminal (i.e., <code>TaskStatus.FAILED</code> or <code>TaskStatus.SUCCEEDED</code>).</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>if <code>check</code> is <code>True</code> and the status of <code>message</code> is not <code>TaskStatus.FAILED</code> or <code>TaskStatus.SUCCEEDED</code>.</p> Source code in <code>alsek/core/status/asyncio.py</code> <pre><code>async def delete(self, message: Message, check: bool = True) -&gt; None:\n    \"\"\"Delete the status of ``message``.\n\n    Args:\n        message (Message): an Alsek message\n        check (bool): check that it is safe to delete the status.\n            This is done by ensuring that the current status of ``message``\n            is terminal (i.e., ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``).\n\n    Returns:\n        None\n\n    Raises:\n        ValidationError: if ``check`` is ``True`` and the status of\n            ``message`` is not ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``.\n\n    \"\"\"\n    if check and (await self.get(message)).status not in TERMINAL_TASK_STATUSES:\n        raise ValidationError(f\"Message '{message.uuid}' in a non-terminal state\")\n    await self.backend.delete(self.get_storage_name(message), missing_ok=False)\n</code></pre> <code>exists(message)</code> <code>async</code> <p>Check if a status for <code>message</code> exists in the backend.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>alsek/core/status/asyncio.py</code> <pre><code>async def exists(self, message: Message) -&gt; bool:\n    \"\"\"Check if a status for ``message`` exists in the backend.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        bool\n\n    \"\"\"\n    return await self.backend.exists(self.get_storage_name(message))\n</code></pre> <code>get(message)</code> <code>async</code> <p>Get the status of <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>status</code> <code>StatusUpdate</code> <p>the status of <code>message</code></p> Source code in <code>alsek/core/status/asyncio.py</code> <pre><code>async def get(self, message: Message) -&gt; StatusUpdate:\n    \"\"\"Get the status of ``message``.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        status (StatusUpdate): the status of ``message``\n\n    \"\"\"\n    if value := await self.backend.get(self.get_storage_name(message)):\n        return StatusUpdate(\n            status=TaskStatus[value[\"status\"]],  # noqa\n            details=value[\"details\"],\n        )\n    else:\n        raise KeyError(f\"No status found for message '{message.summary}'\")\n</code></pre> <code>listen_to_updates(message, auto_exit=True)</code> <code>async</code> <p>Listen to PUBSUB updates for <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>auto_exit</code> <code>bool</code> <p>if <code>True</code> stop listening if a terminal status for the task is encountered (succeeded or failed).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>stream</code> <code>AsyncIterable[StatusUpdate]</code> <p>A stream of updates from the pubsub channel</p> Source code in <code>alsek/core/status/asyncio.py</code> <pre><code>async def listen_to_updates(\n    self,\n    message: Message,\n    auto_exit: bool = True,\n) -&gt; AsyncIterable[StatusUpdate]:\n    \"\"\"Listen to PUBSUB updates for ``message``.\n\n    Args:\n        message (Message): an Alsek message\n        auto_exit (bool): if ``True`` stop listening if a terminal status for the\n            task is encountered (succeeded or failed).\n\n    Returns:\n        stream (AsyncIterable[StatusUpdate]): A stream of updates from the pubsub channel\n\n    \"\"\"\n    if not self.enable_pubsub:\n        raise ValueError(\"PUBSUB not enabled\")\n\n    async for i in self.backend.sub(self.get_pubsub_name(message)):\n        if i.get(\"type\", \"\").lower() == \"message\":\n            update = StatusUpdate(\n                status=TaskStatus[i[\"data\"][\"status\"]],  # noqa\n                details=i[\"data\"][\"details\"],  # noqa\n            )\n            yield update\n            if auto_exit and update.status in TERMINAL_TASK_STATUSES:\n                break\n</code></pre> <code>publish_update(message, update)</code> <code>async</code> <p>Publish a PUBSUB update for a message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>update</code> <code>StatusUpdate</code> <p>a status to publish</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/status/asyncio.py</code> <pre><code>async def publish_update(self, message: Message, update: StatusUpdate) -&gt; None:\n    \"\"\"Publish a PUBSUB update for a message.\n\n    Args:\n        message (Message): an Alsek message\n        update (StatusUpdate): a status to publish\n\n    Returns:\n        None\n\n    \"\"\"\n    await self.backend.pub(\n        self.get_pubsub_name(message),\n        value=update.as_dict(),  # converting to dict makes this serializer-agnostic\n    )\n</code></pre> <code>set(message, status, details=None)</code> <code>async</code> <p>Set a <code>status</code> for <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>status</code> <code>TaskStatus</code> <p>a status to set</p> required <code>details</code> <code>Any</code> <p>additional information about the status (e.g., progress percentage)</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/status/asyncio.py</code> <pre><code>async def set(\n    self,\n    message: Message,\n    status: TaskStatus,\n    details: Optional[Any] = None,\n) -&gt; None:\n    \"\"\"Set a ``status`` for ``message``.\n\n    Args:\n        message (Message): an Alsek message\n        status (TaskStatus): a status to set\n        details (Any, optional): additional information about the status (e.g., progress percentage)\n\n    Returns:\n        None\n\n    \"\"\"\n    update = StatusUpdate(status=status, details=details)\n    await self.backend.set(\n        self.get_storage_name(message),\n        value=update.as_dict(),\n        ttl=self.ttl if status == TaskStatus.SUBMITTED else None,\n    )\n    if self.enable_pubsub:\n        await self.publish_update(message, update=update)\n</code></pre> <code>wait_for(message, status, timeout=5.0, poll_interval=0.05, raise_on_timeout=True)</code> <code>async</code> <p>Wait for a message to reach a desired status.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>the message to monitor</p> required <code>status</code> <code>TaskStatus, tuple[TaskStatus...], list[TaskStatus]</code> <p>the target status</p> required <code>timeout</code> <code>float</code> <p>max time to wait (in seconds). None means wait forever.</p> <code>5.0</code> <code>poll_interval</code> <code>float</code> <p>how often to check (in seconds)</p> <code>0.05</code> <code>raise_on_timeout</code> <code>bool</code> <p>if <code>True</code> raise a <code>TimeoutError</code> if waiting times out otherwise return the current status</p> <code>True</code> <p>Returns:</p> Name Type Description <code>status</code> <code>TaskStatus</code> <p>the status of <code>message</code> after waiting</p> Source code in <code>alsek/core/status/asyncio.py</code> <pre><code>async def wait_for(\n    self,\n    message: Message,\n    status: TaskStatus | tuple[TaskStatus, ...] | list[TaskStatus],\n    timeout: Optional[float] = 5.0,\n    poll_interval: float = 0.05,\n    raise_on_timeout: bool = True,\n) -&gt; TaskStatus:\n    \"\"\"Wait for a message to reach a desired status.\n\n    Args:\n        message (Message): the message to monitor\n        status (TaskStatus, tuple[TaskStatus...], list[TaskStatus]): the target status\n        timeout (float, optional): max time to wait (in seconds). None means wait forever.\n        poll_interval (float): how often to check (in seconds)\n        raise_on_timeout (bool): if ``True`` raise a ``TimeoutError`` if waiting times out\n            otherwise return the current status\n\n    Returns:\n        status (TaskStatus): the status of ``message`` after waiting\n\n    \"\"\"\n    current_status: Optional[TaskStatus] = None\n    if not isinstance(status, TaskStatus) and not isinstance(status, (list, tuple)):\n        raise ValueError(f\"Invalid status type: {type(status)}\")\n\n    def is_current_status_match() -&gt; bool:\n        if current_status is None:\n            return False\n        elif isinstance(status, TaskStatus):\n            return current_status == status\n        elif isinstance(status, (list, tuple)):\n            return current_status in status\n        else:\n            raise ValueError(f\"Invalid status type: {type(status)}\")\n\n    deadline = None if timeout is None else time.time() + timeout\n    while True:\n        try:\n            current_status = (await self.get(message)).status\n            if is_current_status_match():\n                return current_status\n        except KeyError:\n            pass\n        if deadline is not None and time.time() &gt; deadline:\n            if raise_on_timeout:\n                raise TimeoutError(f\"Timeout waiting for '{message.summary}'\")\n            else:\n                return TaskStatus.UNKNOWN if current_status is None else current_status  # fmt: skip\n        await asyncio.sleep(poll_interval)\n</code></pre>"},{"location":"reference/#alsek.core.status.integrity","title":"<code>integrity</code>","text":"<p>Integrity</p>"},{"location":"reference/#alsek.core.status.integrity.StatusTrackerIntegrityScanner","title":"<code>StatusTrackerIntegrityScanner</code>","text":"<p>Tool to ensure the integrity of statuses scanning a <code>StatusTracker()</code> with non-terminal statuses (i.e., <code>TaskStatus.FAILED</code> or <code>TaskStatus.SUCCEEDED</code>) that no longer exist in the broker. Entries which meet this criteria will have their status set to <code>TaskStatus.UNKNOWN</code>.</p> <p>Parameters:</p> Name Type Description Default <code>status_tracker</code> <code>StatusTracker</code> <p>status tracker to scan for messages with non-terminal status</p> required <code>trigger</code> <code>(CronTrigger, DateTrigger, IntervalTrigger)</code> <p>trigger which determines how often to perform the scan.</p> <code>IntervalTrigger(hours=1)</code> Source code in <code>alsek/core/status/integrity.py</code> <pre><code>class StatusTrackerIntegrityScanner:\n    \"\"\"Tool to ensure the integrity of statuses scanning a ``StatusTracker()``\n    with non-terminal statuses (i.e., ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``)\n    that no longer exist in the broker. Entries which meet this criteria will have\n    their status set to ``TaskStatus.UNKNOWN``.\n\n    Args:\n        status_tracker (StatusTracker): status tracker to scan for messages with non-terminal status\n        trigger (CronTrigger, DateTrigger, IntervalTrigger, optional):\n            trigger which determines how often to perform the scan.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        status_tracker: StatusTracker,\n        broker: Broker,\n        trigger: Union[CronTrigger, DateTrigger, IntervalTrigger] = IntervalTrigger(hours=1),  # fmt: skip\n    ) -&gt; None:\n        self.status_tracker = status_tracker\n        self.broker = broker\n        self.trigger = trigger\n\n        if status_tracker.backend.IS_ASYNC:\n            raise ValueError(\"Async backends not supported\")\n\n        self.scheduler: BackgroundScheduler = BackgroundScheduler()\n        if trigger:\n            self.scheduler.start()\n            self.scheduler.add_job(\n                self.scan,\n                trigger=trigger,\n                id=\"integrity_scan\",\n            )\n\n    def scan(self) -&gt; None:\n        \"\"\"Run the integrity scan.\n\n        Returns:\n            None\n\n        \"\"\"\n        for name in self.status_tracker.backend.scan(\"status*\"):\n            message = _name2message(name)\n            status = self.status_tracker.get(message).status\n            if (\n                status is not None\n                and status not in TERMINAL_TASK_STATUSES\n                and not self.broker.exists(message)\n            ):\n                self.status_tracker.set(message, status=TaskStatus.UNKNOWN)\n</code></pre> <code>scan()</code> <p>Run the integrity scan.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/status/integrity.py</code> <pre><code>def scan(self) -&gt; None:\n    \"\"\"Run the integrity scan.\n\n    Returns:\n        None\n\n    \"\"\"\n    for name in self.status_tracker.backend.scan(\"status*\"):\n        message = _name2message(name)\n        status = self.status_tracker.get(message).status\n        if (\n            status is not None\n            and status not in TERMINAL_TASK_STATUSES\n            and not self.broker.exists(message)\n        ):\n            self.status_tracker.set(message, status=TaskStatus.UNKNOWN)\n</code></pre>"},{"location":"reference/#alsek.core.status.standard","title":"<code>standard</code>","text":"<p>Status Tracking</p>"},{"location":"reference/#alsek.core.status.standard.StatusTracker","title":"<code>StatusTracker</code>","text":"<p>               Bases: <code>BaseStatusTracker</code></p> Source code in <code>alsek/core/status/standard.py</code> <pre><code>class StatusTracker(BaseStatusTracker):\n    __doc__ = BaseStatusTracker.__doc__\n\n    @classmethod\n    def deserialize(cls, data: dict[str, Any]) -&gt; StatusTracker:\n        backend_data = dill.loads(data[\"backend\"])\n        backend = backend_data[\"backend\"].from_settings(backend_data[\"settings\"])\n        return cls(\n            backend=backend,\n            ttl=data[\"ttl\"],\n            enable_pubsub=data[\"enable_pubsub\"],\n        )\n\n    def exists(self, message: Message) -&gt; bool:\n        \"\"\"Check if a status for ``message`` exists in the backend.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            bool\n\n        \"\"\"\n        return self.backend.exists(self.get_storage_name(message))\n\n    def publish_update(self, message: Message, update: StatusUpdate) -&gt; None:\n        \"\"\"Publish a PUBSUB update for a message.\n\n        Args:\n            message (Message): an Alsek message\n            update (StatusUpdate): a status to publish\n\n        Returns:\n            None\n\n        \"\"\"\n        self.backend.pub(\n            self.get_pubsub_name(message),\n            value=update.as_dict(),  # converting to dict makes this serializer-agnostic\n        )\n\n    def listen_to_updates(\n        self,\n        message: Message,\n        auto_exit: bool = True,\n    ) -&gt; Iterable[StatusUpdate]:\n        \"\"\"Listen to PUBSUB updates for ``message``.\n\n        Args:\n            message (Message): an Alsek message\n            auto_exit (bool): if ``True`` stop listening if a terminal status for the\n                task is encountered (succeeded or failed).\n\n        Returns:\n            stream (Iterable[StatusUpdate]): A stream of updates from the pubsub channel\n\n        \"\"\"\n        if not self.enable_pubsub:\n            raise ValueError(\"PUBSUB not enabled\")\n\n        for i in self.backend.sub(self.get_pubsub_name(message)):\n            if i.get(\"type\", \"\").lower() == \"message\":\n                update = StatusUpdate(\n                    status=TaskStatus[i[\"data\"][\"status\"]],  # noqa\n                    details=i[\"data\"][\"details\"],  # noqa\n                )\n                yield update\n                if auto_exit and update.status in TERMINAL_TASK_STATUSES:\n                    break\n\n    def set(\n        self,\n        message: Message,\n        status: TaskStatus,\n        details: Optional[Any] = None,\n    ) -&gt; None:\n        \"\"\"Set a ``status`` for ``message``.\n\n        Args:\n            message (Message): an Alsek message\n            status (TaskStatus): a status to set\n            details (Any, optional): additional information about the status (e.g., progress percentage)\n\n        Returns:\n            None\n\n        \"\"\"\n        update = StatusUpdate(status=status, details=details)\n        self.backend.set(\n            self.get_storage_name(message),\n            value=update.as_dict(),\n            ttl=self.ttl if status == TaskStatus.SUBMITTED else None,\n        )\n        if self.enable_pubsub:\n            self.publish_update(message, update=update)\n\n    def get(self, message: Message) -&gt; StatusUpdate:\n        \"\"\"Get the status of ``message``.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            status (StatusUpdate): the status of ``message``\n\n        \"\"\"\n        if value := self.backend.get(self.get_storage_name(message)):\n            return StatusUpdate(\n                status=TaskStatus[value[\"status\"]],  # noqa\n                details=value[\"details\"],\n            )\n        else:\n            raise KeyError(f\"No status found for message '{message.summary}'\")\n\n    def wait_for(\n        self,\n        message: Message,\n        status: TaskStatus | tuple[TaskStatus, ...] | list[TaskStatus],\n        timeout: Optional[float] = 5.0,\n        poll_interval: float = 0.05,\n        raise_on_timeout: bool = True,\n    ) -&gt; TaskStatus:\n        \"\"\"Wait for a message to reach a desired status.\n\n        Args:\n            message (Message): the message to monitor\n            status (TaskStatus, tuple[TaskStatus...], list[TaskStatus]): the target status\n            timeout (float, optional): max time to wait (in seconds). None means wait forever.\n            poll_interval (float): how often to check (in seconds)\n            raise_on_timeout (bool): if ``True`` raise a ``TimeoutError`` if waiting times out\n                otherwise return the current status\n\n        Returns:\n            status (TaskStatus): the status of ``message`` after waiting\n\n        \"\"\"\n        current_status: Optional[TaskStatus] = None\n        if not isinstance(status, TaskStatus) and not isinstance(status, (list, tuple)):\n            raise ValueError(f\"Invalid status type: {type(status)}\")\n\n        def is_current_status_match() -&gt; bool:\n            if current_status is None:\n                return False\n            elif isinstance(status, TaskStatus):\n                return current_status == status\n            elif isinstance(status, (list, tuple)):\n                return current_status in status\n            else:\n                raise ValueError(f\"Invalid status type: {type(status)}\")\n\n        deadline = None if timeout is None else time.time() + timeout\n        while True:\n            try:\n                current_status: TaskStatus = self.get(message).status\n                if is_current_status_match():\n                    return current_status\n            except KeyError:\n                pass\n            if deadline is not None and time.time() &gt; deadline:\n                if raise_on_timeout:\n                    raise TimeoutError(f\"Timeout waiting for '{message.summary}'\")\n                else:\n                    return TaskStatus.UNKNOWN if current_status is None else current_status  # fmt: skip\n            time.sleep(poll_interval)\n\n    def delete(self, message: Message, check: bool = True) -&gt; None:\n        \"\"\"Delete the status of ``message``.\n\n        Args:\n            message (Message): an Alsek message\n            check (bool): check that it is safe to delete the status.\n                This is done by ensuring that the current status of ``message``\n                is terminal (i.e., ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``).\n\n        Returns:\n            None\n\n        Raises:\n            ValidationError: if ``check`` is ``True`` and the status of\n                ``message`` is not ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``.\n\n        \"\"\"\n        if check and self.get(message).status not in TERMINAL_TASK_STATUSES:\n            raise ValidationError(f\"Message '{message.uuid}' in a non-terminal state\")\n        self.backend.delete(self.get_storage_name(message), missing_ok=False)\n</code></pre> <code>delete(message, check=True)</code> <p>Delete the status of <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>check</code> <code>bool</code> <p>check that it is safe to delete the status. This is done by ensuring that the current status of <code>message</code> is terminal (i.e., <code>TaskStatus.FAILED</code> or <code>TaskStatus.SUCCEEDED</code>).</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>if <code>check</code> is <code>True</code> and the status of <code>message</code> is not <code>TaskStatus.FAILED</code> or <code>TaskStatus.SUCCEEDED</code>.</p> Source code in <code>alsek/core/status/standard.py</code> <pre><code>def delete(self, message: Message, check: bool = True) -&gt; None:\n    \"\"\"Delete the status of ``message``.\n\n    Args:\n        message (Message): an Alsek message\n        check (bool): check that it is safe to delete the status.\n            This is done by ensuring that the current status of ``message``\n            is terminal (i.e., ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``).\n\n    Returns:\n        None\n\n    Raises:\n        ValidationError: if ``check`` is ``True`` and the status of\n            ``message`` is not ``TaskStatus.FAILED`` or ``TaskStatus.SUCCEEDED``.\n\n    \"\"\"\n    if check and self.get(message).status not in TERMINAL_TASK_STATUSES:\n        raise ValidationError(f\"Message '{message.uuid}' in a non-terminal state\")\n    self.backend.delete(self.get_storage_name(message), missing_ok=False)\n</code></pre> <code>exists(message)</code> <p>Check if a status for <code>message</code> exists in the backend.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>alsek/core/status/standard.py</code> <pre><code>def exists(self, message: Message) -&gt; bool:\n    \"\"\"Check if a status for ``message`` exists in the backend.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        bool\n\n    \"\"\"\n    return self.backend.exists(self.get_storage_name(message))\n</code></pre> <code>get(message)</code> <p>Get the status of <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>status</code> <code>StatusUpdate</code> <p>the status of <code>message</code></p> Source code in <code>alsek/core/status/standard.py</code> <pre><code>def get(self, message: Message) -&gt; StatusUpdate:\n    \"\"\"Get the status of ``message``.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        status (StatusUpdate): the status of ``message``\n\n    \"\"\"\n    if value := self.backend.get(self.get_storage_name(message)):\n        return StatusUpdate(\n            status=TaskStatus[value[\"status\"]],  # noqa\n            details=value[\"details\"],\n        )\n    else:\n        raise KeyError(f\"No status found for message '{message.summary}'\")\n</code></pre> <code>listen_to_updates(message, auto_exit=True)</code> <p>Listen to PUBSUB updates for <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>auto_exit</code> <code>bool</code> <p>if <code>True</code> stop listening if a terminal status for the task is encountered (succeeded or failed).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>stream</code> <code>Iterable[StatusUpdate]</code> <p>A stream of updates from the pubsub channel</p> Source code in <code>alsek/core/status/standard.py</code> <pre><code>def listen_to_updates(\n    self,\n    message: Message,\n    auto_exit: bool = True,\n) -&gt; Iterable[StatusUpdate]:\n    \"\"\"Listen to PUBSUB updates for ``message``.\n\n    Args:\n        message (Message): an Alsek message\n        auto_exit (bool): if ``True`` stop listening if a terminal status for the\n            task is encountered (succeeded or failed).\n\n    Returns:\n        stream (Iterable[StatusUpdate]): A stream of updates from the pubsub channel\n\n    \"\"\"\n    if not self.enable_pubsub:\n        raise ValueError(\"PUBSUB not enabled\")\n\n    for i in self.backend.sub(self.get_pubsub_name(message)):\n        if i.get(\"type\", \"\").lower() == \"message\":\n            update = StatusUpdate(\n                status=TaskStatus[i[\"data\"][\"status\"]],  # noqa\n                details=i[\"data\"][\"details\"],  # noqa\n            )\n            yield update\n            if auto_exit and update.status in TERMINAL_TASK_STATUSES:\n                break\n</code></pre> <code>publish_update(message, update)</code> <p>Publish a PUBSUB update for a message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>update</code> <code>StatusUpdate</code> <p>a status to publish</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/status/standard.py</code> <pre><code>def publish_update(self, message: Message, update: StatusUpdate) -&gt; None:\n    \"\"\"Publish a PUBSUB update for a message.\n\n    Args:\n        message (Message): an Alsek message\n        update (StatusUpdate): a status to publish\n\n    Returns:\n        None\n\n    \"\"\"\n    self.backend.pub(\n        self.get_pubsub_name(message),\n        value=update.as_dict(),  # converting to dict makes this serializer-agnostic\n    )\n</code></pre> <code>set(message, status, details=None)</code> <p>Set a <code>status</code> for <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>status</code> <code>TaskStatus</code> <p>a status to set</p> required <code>details</code> <code>Any</code> <p>additional information about the status (e.g., progress percentage)</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/status/standard.py</code> <pre><code>def set(\n    self,\n    message: Message,\n    status: TaskStatus,\n    details: Optional[Any] = None,\n) -&gt; None:\n    \"\"\"Set a ``status`` for ``message``.\n\n    Args:\n        message (Message): an Alsek message\n        status (TaskStatus): a status to set\n        details (Any, optional): additional information about the status (e.g., progress percentage)\n\n    Returns:\n        None\n\n    \"\"\"\n    update = StatusUpdate(status=status, details=details)\n    self.backend.set(\n        self.get_storage_name(message),\n        value=update.as_dict(),\n        ttl=self.ttl if status == TaskStatus.SUBMITTED else None,\n    )\n    if self.enable_pubsub:\n        self.publish_update(message, update=update)\n</code></pre> <code>wait_for(message, status, timeout=5.0, poll_interval=0.05, raise_on_timeout=True)</code> <p>Wait for a message to reach a desired status.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>the message to monitor</p> required <code>status</code> <code>TaskStatus, tuple[TaskStatus...], list[TaskStatus]</code> <p>the target status</p> required <code>timeout</code> <code>float</code> <p>max time to wait (in seconds). None means wait forever.</p> <code>5.0</code> <code>poll_interval</code> <code>float</code> <p>how often to check (in seconds)</p> <code>0.05</code> <code>raise_on_timeout</code> <code>bool</code> <p>if <code>True</code> raise a <code>TimeoutError</code> if waiting times out otherwise return the current status</p> <code>True</code> <p>Returns:</p> Name Type Description <code>status</code> <code>TaskStatus</code> <p>the status of <code>message</code> after waiting</p> Source code in <code>alsek/core/status/standard.py</code> <pre><code>def wait_for(\n    self,\n    message: Message,\n    status: TaskStatus | tuple[TaskStatus, ...] | list[TaskStatus],\n    timeout: Optional[float] = 5.0,\n    poll_interval: float = 0.05,\n    raise_on_timeout: bool = True,\n) -&gt; TaskStatus:\n    \"\"\"Wait for a message to reach a desired status.\n\n    Args:\n        message (Message): the message to monitor\n        status (TaskStatus, tuple[TaskStatus...], list[TaskStatus]): the target status\n        timeout (float, optional): max time to wait (in seconds). None means wait forever.\n        poll_interval (float): how often to check (in seconds)\n        raise_on_timeout (bool): if ``True`` raise a ``TimeoutError`` if waiting times out\n            otherwise return the current status\n\n    Returns:\n        status (TaskStatus): the status of ``message`` after waiting\n\n    \"\"\"\n    current_status: Optional[TaskStatus] = None\n    if not isinstance(status, TaskStatus) and not isinstance(status, (list, tuple)):\n        raise ValueError(f\"Invalid status type: {type(status)}\")\n\n    def is_current_status_match() -&gt; bool:\n        if current_status is None:\n            return False\n        elif isinstance(status, TaskStatus):\n            return current_status == status\n        elif isinstance(status, (list, tuple)):\n            return current_status in status\n        else:\n            raise ValueError(f\"Invalid status type: {type(status)}\")\n\n    deadline = None if timeout is None else time.time() + timeout\n    while True:\n        try:\n            current_status: TaskStatus = self.get(message).status\n            if is_current_status_match():\n                return current_status\n        except KeyError:\n            pass\n        if deadline is not None and time.time() &gt; deadline:\n            if raise_on_timeout:\n                raise TimeoutError(f\"Timeout waiting for '{message.summary}'\")\n            else:\n                return TaskStatus.UNKNOWN if current_status is None else current_status  # fmt: skip\n        time.sleep(poll_interval)\n</code></pre>"},{"location":"reference/#alsek.core.status.types","title":"<code>types</code>","text":"<p>Types</p>"},{"location":"reference/#alsek.core.status.types.StatusUpdate","title":"<code>StatusUpdate</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Status information.</p> Source code in <code>alsek/core/status/types.py</code> <pre><code>class StatusUpdate(NamedTuple):\n    \"\"\"Status information.\"\"\"\n\n    status: TaskStatus\n    details: Optional[Any]\n\n    def as_dict(self) -&gt; dict[str, Any]:\n        return dict(\n            status=self.status.name,\n            details=self.details,\n        )\n</code></pre>"},{"location":"reference/#alsek.core.status.types.TaskStatus","title":"<code>TaskStatus</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Alsek task statuses.</p> Source code in <code>alsek/core/status/types.py</code> <pre><code>class TaskStatus(Enum):\n    \"\"\"Alsek task statuses.\"\"\"\n\n    UNKNOWN = 0\n    SUBMITTED = 1\n    RUNNING = 2\n    RETRYING = 3\n    FAILED = 4\n    SUCCEEDED = 5\n</code></pre>"},{"location":"reference/#alsek.core.task","title":"<code>task</code>","text":"<p>Task</p>"},{"location":"reference/#alsek.core.task.Task","title":"<code>Task</code>","text":"<p>Alsek Task.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>callable</code> <p>function to use for the main operation</p> required <code>broker</code> <code>Broker</code> <p>an Alsek broker</p> required <code>name</code> <code>str</code> <p>the name of the task. If <code>None</code>, the class name will be used.</p> <code>None</code> <code>queue</code> <code>str</code> <p>the name of the queue to generate the task on. If <code>None</code>, the default queue will be used.</p> <code>None</code> <code>timeout</code> <code>int</code> <p>the maximum amount of time (in milliseconds) this task is permitted to run.</p> <code>DEFAULT_TASK_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>maximum number of allowed retries</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff</code> <code>Backoff</code> <p>backoff algorithm and parameters to use when computing delay between retries</p> <code>ExponentialBackoff()</code> <code>result_store</code> <code>ResultStore</code> <p>store for persisting task results</p> <code>None</code> <code>status_tracker</code> <code>StatusTracker</code> <p>store for persisting task statuses</p> <code>None</code> <code>mechanism</code> <code>SupportedMechanismType</code> <p>mechanism for executing the task. Must be either \"process\" or \"thread\".</p> <code>DEFAULT_MECHANISM</code> <code>no_positional_args</code> <code>bool</code> <p>if <code>True</code>, the task will not accept positional arguments.</p> <code>False</code> Notes <ul> <li><code>do_retry()</code> can be overridden in cases where <code>max_retries</code>    is not sufficiently complex to determine if a retry should occur.</li> </ul> Warning <ul> <li>Timeouts are not supported for <code>mechanism='thread'</code> on Python   implementations other than CPython.</li> </ul> Source code in <code>alsek/core/task.py</code> <pre><code>class Task:\n    \"\"\"Alsek Task.\n\n    Args:\n        function (callable): function to use for the main operation\n        broker (Broker): an Alsek broker\n        name (str, optional): the name of the task. If ``None``,\n            the class name will be used.\n        queue (str, optional): the name of the queue to generate the task on.\n            If ``None``, the default queue will be used.\n        timeout (int): the maximum amount of time (in milliseconds)\n            this task is permitted to run.\n        max_retries (int, optional): maximum number of allowed retries\n        backoff (Backoff, optional): backoff algorithm and parameters to use when computing\n            delay between retries\n        result_store (ResultStore, optional): store for persisting task results\n        status_tracker (StatusTracker, optional): store for persisting task statuses\n        mechanism (SupportedMechanismType): mechanism for executing the task. Must\n            be either \"process\" or \"thread\".\n        no_positional_args (bool): if ``True``, the task will not accept positional arguments.\n\n    Notes:\n        * ``do_retry()`` can be overridden in cases where ``max_retries``\n           is not sufficiently complex to determine if a retry should occur.\n\n    Warning:\n        * Timeouts are not supported for ``mechanism='thread'`` on Python\n          implementations other than CPython.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        function: Callable[..., Any],\n        broker: Broker,\n        name: Optional[str] = None,\n        queue: Optional[str] = None,\n        timeout: int = DEFAULT_TASK_TIMEOUT,\n        max_retries: Optional[int] = DEFAULT_MAX_RETRIES,\n        backoff: Optional[Backoff] = ExponentialBackoff(),\n        result_store: Optional[ResultStore] = None,\n        status_tracker: Optional[StatusTracker] = None,\n        mechanism: SupportedMechanismType = DEFAULT_MECHANISM,\n        no_positional_args: bool = False,\n    ) -&gt; None:\n        self.function = function\n        self.broker = broker\n        self.queue = queue or DEFAULT_QUEUE\n        self.timeout = timeout\n        self._name = name\n        self.max_retries = max_retries\n        self.backoff = backoff or ConstantBackoff(\n            constant=0,\n            floor=0,\n            ceiling=0,\n            zero_override=True,\n        )\n        self.result_store = result_store\n        self.status_tracker = status_tracker\n        self.mechanism = mechanism\n        self.no_positional_args = no_positional_args\n\n        if mechanism not in SUPPORTED_MECHANISMS:\n            raise ValueError(f\"Unsupported mechanism '{mechanism}'\")\n        elif status_tracker and status_tracker.backend.IS_ASYNC:\n            raise ValueError(\"Status tracker does not support async backends\")\n\n        self._deferred: bool = False\n\n    def serialize(self) -&gt; dict[str, Any]:\n        settings = gather_init_params(\n            self,\n            ignore=(\"broker\", \"status_tracker\", \"result_store\"),\n        )\n\n        # Broker\n        settings[\"broker_class\"] = self.broker.__class__\n        settings[\"broker_state\"] = self.broker.serialize()\n\n        # Status Tracker\n        if self.status_tracker:\n            settings[\"status_tracker_class\"] = self.status_tracker.__class__\n            settings[\"status_tracker_state\"] = self.status_tracker.serialize()\n\n        # Result Store\n        if self.result_store:\n            settings[\"result_store_class\"] = self.result_store.__class__\n            settings[\"result_store_state\"] = self.result_store.serialize()\n\n        return dict(task=self.__class__, settings=settings)\n\n    @staticmethod\n    def deserialize(data: dict[str, Any]) -&gt; Task:\n        def unwind_settings(settings: dict[str, Any]) -&gt; dict[str, Any]:\n            settings = settings.copy()\n\n            # Broker\n            broker_class = settings.pop(\"broker_class\")\n            settings[\"broker\"] = broker_class.deserialize(settings.pop(\"broker_state\"))\n\n            # Status Tracker\n            if status_tracker_state := settings.pop(\"status_tracker_state\", None):\n                status_tracker_class = settings.pop(\"status_tracker_class\")\n                settings[\"status_tracker\"] = status_tracker_class.deserialize(status_tracker_state)  # fmt: skip\n\n            # Result Store\n            if result_store_state := settings.pop(\"result_store_state\", None):\n                result_store_class = settings.pop(\"result_store_class\")\n                settings[\"result_store\"] = result_store_class.deserialize(result_store_state)  # fmt: skip\n\n            return settings\n\n        rebuilt_task = data[\"task\"](**unwind_settings(data[\"settings\"]))\n        return cast(Task, rebuilt_task)\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Name of the task.\"\"\"\n        return self._name if self._name else self.function.__name__\n\n    def __repr__(self) -&gt; str:\n        return auto_repr(\n            self,\n            function=self.function,\n            broker=self.broker,\n            name=self.name,\n            queue=self.queue,\n            max_retries=self.max_retries,\n            backoff=self.backoff,\n            mechanism=self.mechanism,\n            deferred_mode=\"enabled\" if self._deferred else \"disabled\",\n        )\n\n    def __call__(self, *args: Any, **kwargs: Any) -&gt; Any:\n        return self.function(*args, **kwargs)\n\n    def update_status(self, message: Message, status: TaskStatus) -&gt; None:\n        \"\"\"Update the status of a message.\n\n        Args:\n            message (Message): message to update the status of.\n            status (TaskStatus): status to update the message to.\n\n        Returns:\n            None\n\n        \"\"\"\n        if self.status_tracker:\n            log.debug(f\"Setting status of '{message.uuid}' to {status}...\")\n            self.status_tracker.set(message, status=status)\n\n    @property\n    def deferred(self) -&gt; bool:\n        \"\"\"Whether deferred mode is currently enabled.\"\"\"\n        return self._deferred\n\n    def defer(self) -&gt; Task:\n        \"\"\"Enter \"deferred\" mode.\n\n        Do not submit the next message created by ``generate()``\n        to the broker.\n\n        Returns:\n            task (Task): the current task\n\n        Warning:\n            * Deferred mode is automatically cancelled by ``generate()``\n              prior to it returning.\n\n        \"\"\"\n        self._deferred = True\n        return self\n\n    def cancel_defer(self) -&gt; Task:\n        \"\"\"Cancel \"deferred\" mode.\n\n        Returns:\n            task (Task): the current task\n\n        \"\"\"\n        self._deferred = False\n        return self\n\n    def on_submit(self, message: Message) -&gt; None:\n        \"\"\"Handles the action to be performed when a message is submitted.\n        This method processes  the provided message and executes the required\n        behavior upon submission.\n\n        Args:\n            message (Message): The message object submitted for processing.\n\n        Returns:\n            None\n\n        \"\"\"\n\n    def _submit(self, message: Message, **options: Any) -&gt; None:\n        self.broker.submit(message, **options)\n\n    def generate(\n        self,\n        args: Optional[Union[list[Any], tuple[Any, ...]]] = None,\n        kwargs: Optional[dict[Any, Any]] = None,\n        priority: int = 0,\n        metadata: Optional[dict[Any, Any]] = None,\n        result_ttl: Optional[int] = None,\n        uuid: Optional[str] = None,\n        timeout_override: Optional[int] = None,\n        delay: Optional[int] = None,\n        previous_result: Any = None,\n        callback: Optional[Union[Message, tuple[Message, ...]]] = None,\n        queue: Optional[str] = None,\n        submit: bool = True,\n        **options: Any,\n    ) -&gt; Message:\n        \"\"\"Generate an instance of the task for processing.\n\n        This method generates a new message for the task and\n        submit it to the broker.\n\n        Args:\n            args (list, tuple, optional): positional arguments to pass to ``function``\n            kwargs (dict, optional): keyword arguments to pass to ``function``\n            priority (int): priority of the message within the task.\n                Messages with lower values will be executed before messages with higher values.\n            metadata (dict, optional): a dictionary of user-defined message metadata.\n                This can store any data types supported by the backend's serializer.\n            result_ttl (int, optional): time to live (in milliseconds) for the\n                result in the result store. If a result store is provided and\n            this parameter is ``None``, the result will be persisted indefinitely.\n            uuid (str, optional): universal unique identifier for the message.\n                If ``None``, one will be generated automatically.\n            timeout_override (int, optional): override the default maximum runtime\n                (in milliseconds) for instances of this task.\n            set maximum amount of time (in milliseconds)\n                this message is permitted to run. This will override the default\n                for the task.\n            delay (int, optional): delay before message is ready (in milliseconds)\n            previous_result (Any): result of a previous task.\n            callback (Message, tuple[Message, ...], optional): one or more messages\n                to be submitted to the broker after the proceeding message has been\n                successfully processed by a worker.\n            queue (str, optional): queue to use for the task. If none, the default\n                queue for this task will be used.\n            submit (bool): if ``True`` submit the task to the broker\n            options (Keyword Args): options to use when submitting\n                the message via the broker. See ``Broker.submit()``.\n\n        Returns:\n            message (Message): message generated for the task\n\n        Warning:\n            * ``submit`` is overridden to ``False`` if deferred mode is active\n            * ``uuid`` is refreshed after the first event when using a trigger.\n            * If manually overriding ``queue`` such that it differs from the default\n              for this task, Worker Pools built using ``task_specific_mode=True`` will\n              fail acknowledge its existence.\n\n        \"\"\"\n        if result_ttl and not self.result_store:\n            raise ValidationError(f\"`result_ttl` invalid. No result store set.\")\n        elif args and self.no_positional_args:\n            raise ValidationError(f\"Task does not accept positional arguments.\")\n        elif not isinstance(priority, int) or priority &lt; 0:\n            raise ValueError(\"`priority` must be an int greater than or equal to zero\")\n\n        message = Message(\n            task_name=self.name,\n            queue=queue or self.queue,\n            args=args,\n            kwargs=kwargs,\n            priority=priority,\n            metadata=metadata,\n            result_ttl=result_ttl,\n            uuid=uuid,\n            timeout=timeout_override or self.timeout,\n            delay=delay,\n            previous_result=previous_result,\n            callback_message_data=_parse_callback(callback).data if callback else None,\n            backoff_settings=self.backoff.settings,\n            mechanism=self.mechanism,\n        )\n        if self._deferred:\n            self.cancel_defer()\n        elif submit:\n            self._submit(message, **options)\n            self.update_status(message, status=TaskStatus.SUBMITTED)\n            self.on_submit(message)\n        return message\n\n    def pre_op(self, message: Message) -&gt; None:\n        \"\"\"Operation to perform before running ``op``.\n\n        Args:\n            message (Message): message ``op`` will be run against.\n\n        Returns:\n            None\n\n        \"\"\"\n\n    def op(self, message: Message) -&gt; Any:\n        \"\"\"Pass ``message`` data to ``function`` for processing.\n\n        Args:\n            message (Message): message to perform the operation against\n\n        Returns:\n            result (Any): output of the function\n\n        Notes:\n            * If, and only if, the signature of ``function`` contains\n              a ``message`` parameter, ``message`` itself will be passed\n              along with any ``args`` and ``kwargs`` contained in the message.\n\n        Warning:\n            * ``message`` will not be passed in cases where a \"message\"\n              exists in ``message.kwargs``.\n\n        \"\"\"\n        if \"message\" not in message.kwargs and _expects_message(self.function):\n            return self.function(*message.args, **message.kwargs, message=message)\n        else:\n            return self.function(*message.args, **message.kwargs)\n\n    def post_op(self, message: Message, result: Any) -&gt; None:\n        \"\"\"Operation to perform after running ``op``.\n\n        Args:\n            message (Message): message ``op()`` was run against\n            result (Any): output of ``op()``\n\n        Returns:\n            None\n\n        \"\"\"\n\n    def on_revocation(\n        self,\n        message: Message,\n        exception: Optional[BaseException],\n        result: Any,\n    ) -&gt; None:\n        \"\"\"Handles the event when a message is revoked and logs the associated exception.\n\n        Args:\n            message: The message instance that was revoked.\n            exception: The exception instance that represents the reason for the\n                revocation.\n            result (Any): The result of the revoked operation. This is only provided\n                if the task succeeds\n\n        Returns:\n            None\n\n        \"\"\"\n\n    def on_retry(self, message: Message, exception: BaseException) -&gt; None:\n        \"\"\"Handles the retry logic when a processing failure occurs.\n\n        Args:\n            message: The message object that failed during processing and is\n                subject to a retry attempt.\n            exception: The exception instance that was raised during the\n                failure of processing the message.\n\n        Returns:\n            None\n\n        \"\"\"\n\n    def on_failure(self, message: Message, exception: BaseException) -&gt; None:\n        \"\"\"\n        Handles the actions to be performed when an operation fails.\n\n        Args:\n            message: The message object containing the details of the failed\n                operation.\n            exception: The exception object associated with the failure, providing\n                additional context or details about what caused the failure.\n\n        Returns:\n            None\n\n        \"\"\"\n\n    def on_success(self, message: Message, result: Any) -&gt; None:\n        \"\"\"Handles successful outcomes of an operation by processing the given message\n        and corresponding result.\n\n        Args:\n            message: An instance of the Message class that contains relevant information\n                about the operation.\n            result: The result of the completed operation, which can be of any type.\n\n        Returns:\n            None\n\n        \"\"\"\n\n    def execute(self, message: Message) -&gt; Any:\n        \"\"\"Execute the task against a message.\n\n        Args:\n            message (Message): message to process\n\n        Returns:\n            result (Any): output of ``op()``\n\n        \"\"\"\n        return self.op(message)\n\n    def do_retry(self, message: Message, exception: BaseException) -&gt; bool:  # noqa\n        \"\"\"Whether a failed task should be retried.\n\n        Args:\n            message (Message): message which failed\n            exception (BaseException): the exception which was raised\n\n        Returns:\n            bool\n\n        \"\"\"\n        if self.is_revoked(message):\n            return False\n        return self.max_retries is None or message.retries &lt; self.max_retries\n\n    def do_callback(self, message: Message, result: Any) -&gt; bool:  # noqa\n        \"\"\"Whether or to submit the callback provided.\n\n        Args:\n            message (Message): message with the callback\n            result (Any): output of ``op()``\n\n        Returns:\n            bool\n\n        Warning:\n            * If the task message does not have a callback this\n              method will *not* be invoked.\n\n        \"\"\"\n        return True\n\n    @staticmethod\n    def _make_revoked_key_name(message: Message) -&gt; str:\n        return f\"revoked:{get_message_name(message)}\"\n\n    @magic_logger(\n        before=lambda message: log.info(\"Revoking %s...\", message.summary),\n        after=lambda input_: log.debug(\"Revoked %s.\", input_[\"message\"].summary),\n    )\n    def revoke(self, message: Message, skip_if_running: bool = False) -&gt; None:\n        \"\"\"Revoke the task.\n\n        Args:\n            message (Message): message to revoke\n            skip_if_running (bool): if ``True``, skip revoking the task if it is currently RUNNING.\n                Notes: requires ``status_tracker`` to be set.\n\n        Returns:\n            None\n\n        \"\"\"\n        log.info(\"Revoking %s...\", message.summary)\n        if (\n            self.status_tracker\n            and self.status_tracker.get(message).status in TERMINAL_TASK_STATUSES\n        ):\n            log.info(\"Message is already terminal: %s\", message.summary)\n            return\n        elif skip_if_running and not self.status_tracker:\n            raise AttributeError(\"`skip_if_running` requires `status_tracker` to be set\")  # fmt: skip\n        elif skip_if_running and (\n            (status_update := self.status_tracker.get(message))\n            and status_update.status == TaskStatus.RUNNING\n        ):\n            log.info(\"Message is currently running: %s\", message.summary)\n            return\n\n        self.broker.backend.set(\n            self._make_revoked_key_name(message),\n            value=True,\n            ttl=DEFAULT_TTL,\n        )\n        message.update(\n            exception_details=ExceptionDetails(\n                name=get_exception_name(RevokedError),\n                text=\"Task Revoked\",\n                traceback=None,\n            ).as_dict()\n        )\n        self.update_status(message, status=TaskStatus.FAILED)\n        self.broker.fail(message)\n\n    def is_revoked(self, message: Message) -&gt; bool:\n        \"\"\"Check if a message is revoked.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            None\n\n        \"\"\"\n        if self.broker.backend.get(self._make_revoked_key_name(message)):\n            return True\n        else:\n            return False\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.deferred","title":"<code>deferred</code>  <code>property</code>","text":"<p>Whether deferred mode is currently enabled.</p>"},{"location":"reference/#alsek.core.task.Task.name","title":"<code>name</code>  <code>property</code>","text":"<p>Name of the task.</p>"},{"location":"reference/#alsek.core.task.Task.cancel_defer","title":"<code>cancel_defer()</code>","text":"<p>Cancel \"deferred\" mode.</p> <p>Returns:</p> Name Type Description <code>task</code> <code>Task</code> <p>the current task</p> Source code in <code>alsek/core/task.py</code> <pre><code>def cancel_defer(self) -&gt; Task:\n    \"\"\"Cancel \"deferred\" mode.\n\n    Returns:\n        task (Task): the current task\n\n    \"\"\"\n    self._deferred = False\n    return self\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.defer","title":"<code>defer()</code>","text":"<p>Enter \"deferred\" mode.</p> <p>Do not submit the next message created by <code>generate()</code> to the broker.</p> <p>Returns:</p> Name Type Description <code>task</code> <code>Task</code> <p>the current task</p> Warning <ul> <li>Deferred mode is automatically cancelled by <code>generate()</code>   prior to it returning.</li> </ul> Source code in <code>alsek/core/task.py</code> <pre><code>def defer(self) -&gt; Task:\n    \"\"\"Enter \"deferred\" mode.\n\n    Do not submit the next message created by ``generate()``\n    to the broker.\n\n    Returns:\n        task (Task): the current task\n\n    Warning:\n        * Deferred mode is automatically cancelled by ``generate()``\n          prior to it returning.\n\n    \"\"\"\n    self._deferred = True\n    return self\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.do_callback","title":"<code>do_callback(message, result)</code>","text":"<p>Whether or to submit the callback provided.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>message with the callback</p> required <code>result</code> <code>Any</code> <p>output of <code>op()</code></p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Warning <ul> <li>If the task message does not have a callback this   method will not be invoked.</li> </ul> Source code in <code>alsek/core/task.py</code> <pre><code>def do_callback(self, message: Message, result: Any) -&gt; bool:  # noqa\n    \"\"\"Whether or to submit the callback provided.\n\n    Args:\n        message (Message): message with the callback\n        result (Any): output of ``op()``\n\n    Returns:\n        bool\n\n    Warning:\n        * If the task message does not have a callback this\n          method will *not* be invoked.\n\n    \"\"\"\n    return True\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.do_retry","title":"<code>do_retry(message, exception)</code>","text":"<p>Whether a failed task should be retried.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>message which failed</p> required <code>exception</code> <code>BaseException</code> <p>the exception which was raised</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>alsek/core/task.py</code> <pre><code>def do_retry(self, message: Message, exception: BaseException) -&gt; bool:  # noqa\n    \"\"\"Whether a failed task should be retried.\n\n    Args:\n        message (Message): message which failed\n        exception (BaseException): the exception which was raised\n\n    Returns:\n        bool\n\n    \"\"\"\n    if self.is_revoked(message):\n        return False\n    return self.max_retries is None or message.retries &lt; self.max_retries\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.execute","title":"<code>execute(message)</code>","text":"<p>Execute the task against a message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>message to process</p> required <p>Returns:</p> Name Type Description <code>result</code> <code>Any</code> <p>output of <code>op()</code></p> Source code in <code>alsek/core/task.py</code> <pre><code>def execute(self, message: Message) -&gt; Any:\n    \"\"\"Execute the task against a message.\n\n    Args:\n        message (Message): message to process\n\n    Returns:\n        result (Any): output of ``op()``\n\n    \"\"\"\n    return self.op(message)\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.generate","title":"<code>generate(args=None, kwargs=None, priority=0, metadata=None, result_ttl=None, uuid=None, timeout_override=None, delay=None, previous_result=None, callback=None, queue=None, submit=True, **options)</code>","text":"<p>Generate an instance of the task for processing.</p> <p>This method generates a new message for the task and submit it to the broker.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>(list, tuple)</code> <p>positional arguments to pass to <code>function</code></p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>keyword arguments to pass to <code>function</code></p> <code>None</code> <code>priority</code> <code>int</code> <p>priority of the message within the task. Messages with lower values will be executed before messages with higher values.</p> <code>0</code> <code>metadata</code> <code>dict</code> <p>a dictionary of user-defined message metadata. This can store any data types supported by the backend's serializer.</p> <code>None</code> <code>result_ttl</code> <code>int</code> <p>time to live (in milliseconds) for the result in the result store. If a result store is provided and</p> <code>None</code> <code>uuid</code> <code>str</code> <p>universal unique identifier for the message. If <code>None</code>, one will be generated automatically.</p> <code>None</code> <code>timeout_override</code> <code>int</code> <p>override the default maximum runtime (in milliseconds) for instances of this task.</p> <code>None</code> <code>delay</code> <code>int</code> <p>delay before message is ready (in milliseconds)</p> <code>None</code> <code>previous_result</code> <code>Any</code> <p>result of a previous task.</p> <code>None</code> <code>callback</code> <code>(Message, tuple[Message, ...])</code> <p>one or more messages to be submitted to the broker after the proceeding message has been successfully processed by a worker.</p> <code>None</code> <code>queue</code> <code>str</code> <p>queue to use for the task. If none, the default queue for this task will be used.</p> <code>None</code> <code>submit</code> <code>bool</code> <p>if <code>True</code> submit the task to the broker</p> <code>True</code> <code>options</code> <code>Keyword Args</code> <p>options to use when submitting the message via the broker. See <code>Broker.submit()</code>.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>message</code> <code>Message</code> <p>message generated for the task</p> Warning <ul> <li><code>submit</code> is overridden to <code>False</code> if deferred mode is active</li> <li><code>uuid</code> is refreshed after the first event when using a trigger.</li> <li>If manually overriding <code>queue</code> such that it differs from the default   for this task, Worker Pools built using <code>task_specific_mode=True</code> will   fail acknowledge its existence.</li> </ul> Source code in <code>alsek/core/task.py</code> <pre><code>def generate(\n    self,\n    args: Optional[Union[list[Any], tuple[Any, ...]]] = None,\n    kwargs: Optional[dict[Any, Any]] = None,\n    priority: int = 0,\n    metadata: Optional[dict[Any, Any]] = None,\n    result_ttl: Optional[int] = None,\n    uuid: Optional[str] = None,\n    timeout_override: Optional[int] = None,\n    delay: Optional[int] = None,\n    previous_result: Any = None,\n    callback: Optional[Union[Message, tuple[Message, ...]]] = None,\n    queue: Optional[str] = None,\n    submit: bool = True,\n    **options: Any,\n) -&gt; Message:\n    \"\"\"Generate an instance of the task for processing.\n\n    This method generates a new message for the task and\n    submit it to the broker.\n\n    Args:\n        args (list, tuple, optional): positional arguments to pass to ``function``\n        kwargs (dict, optional): keyword arguments to pass to ``function``\n        priority (int): priority of the message within the task.\n            Messages with lower values will be executed before messages with higher values.\n        metadata (dict, optional): a dictionary of user-defined message metadata.\n            This can store any data types supported by the backend's serializer.\n        result_ttl (int, optional): time to live (in milliseconds) for the\n            result in the result store. If a result store is provided and\n        this parameter is ``None``, the result will be persisted indefinitely.\n        uuid (str, optional): universal unique identifier for the message.\n            If ``None``, one will be generated automatically.\n        timeout_override (int, optional): override the default maximum runtime\n            (in milliseconds) for instances of this task.\n        set maximum amount of time (in milliseconds)\n            this message is permitted to run. This will override the default\n            for the task.\n        delay (int, optional): delay before message is ready (in milliseconds)\n        previous_result (Any): result of a previous task.\n        callback (Message, tuple[Message, ...], optional): one or more messages\n            to be submitted to the broker after the proceeding message has been\n            successfully processed by a worker.\n        queue (str, optional): queue to use for the task. If none, the default\n            queue for this task will be used.\n        submit (bool): if ``True`` submit the task to the broker\n        options (Keyword Args): options to use when submitting\n            the message via the broker. See ``Broker.submit()``.\n\n    Returns:\n        message (Message): message generated for the task\n\n    Warning:\n        * ``submit`` is overridden to ``False`` if deferred mode is active\n        * ``uuid`` is refreshed after the first event when using a trigger.\n        * If manually overriding ``queue`` such that it differs from the default\n          for this task, Worker Pools built using ``task_specific_mode=True`` will\n          fail acknowledge its existence.\n\n    \"\"\"\n    if result_ttl and not self.result_store:\n        raise ValidationError(f\"`result_ttl` invalid. No result store set.\")\n    elif args and self.no_positional_args:\n        raise ValidationError(f\"Task does not accept positional arguments.\")\n    elif not isinstance(priority, int) or priority &lt; 0:\n        raise ValueError(\"`priority` must be an int greater than or equal to zero\")\n\n    message = Message(\n        task_name=self.name,\n        queue=queue or self.queue,\n        args=args,\n        kwargs=kwargs,\n        priority=priority,\n        metadata=metadata,\n        result_ttl=result_ttl,\n        uuid=uuid,\n        timeout=timeout_override or self.timeout,\n        delay=delay,\n        previous_result=previous_result,\n        callback_message_data=_parse_callback(callback).data if callback else None,\n        backoff_settings=self.backoff.settings,\n        mechanism=self.mechanism,\n    )\n    if self._deferred:\n        self.cancel_defer()\n    elif submit:\n        self._submit(message, **options)\n        self.update_status(message, status=TaskStatus.SUBMITTED)\n        self.on_submit(message)\n    return message\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.is_revoked","title":"<code>is_revoked(message)</code>","text":"<p>Check if a message is revoked.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Type Description <code>bool</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>def is_revoked(self, message: Message) -&gt; bool:\n    \"\"\"Check if a message is revoked.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        None\n\n    \"\"\"\n    if self.broker.backend.get(self._make_revoked_key_name(message)):\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.on_failure","title":"<code>on_failure(message, exception)</code>","text":"<p>Handles the actions to be performed when an operation fails.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>The message object containing the details of the failed operation.</p> required <code>exception</code> <code>BaseException</code> <p>The exception object associated with the failure, providing additional context or details about what caused the failure.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>def on_failure(self, message: Message, exception: BaseException) -&gt; None:\n    \"\"\"\n    Handles the actions to be performed when an operation fails.\n\n    Args:\n        message: The message object containing the details of the failed\n            operation.\n        exception: The exception object associated with the failure, providing\n            additional context or details about what caused the failure.\n\n    Returns:\n        None\n\n    \"\"\"\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.on_retry","title":"<code>on_retry(message, exception)</code>","text":"<p>Handles the retry logic when a processing failure occurs.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>The message object that failed during processing and is subject to a retry attempt.</p> required <code>exception</code> <code>BaseException</code> <p>The exception instance that was raised during the failure of processing the message.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>def on_retry(self, message: Message, exception: BaseException) -&gt; None:\n    \"\"\"Handles the retry logic when a processing failure occurs.\n\n    Args:\n        message: The message object that failed during processing and is\n            subject to a retry attempt.\n        exception: The exception instance that was raised during the\n            failure of processing the message.\n\n    Returns:\n        None\n\n    \"\"\"\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.on_revocation","title":"<code>on_revocation(message, exception, result)</code>","text":"<p>Handles the event when a message is revoked and logs the associated exception.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>The message instance that was revoked.</p> required <code>exception</code> <code>Optional[BaseException]</code> <p>The exception instance that represents the reason for the revocation.</p> required <code>result</code> <code>Any</code> <p>The result of the revoked operation. This is only provided if the task succeeds</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>def on_revocation(\n    self,\n    message: Message,\n    exception: Optional[BaseException],\n    result: Any,\n) -&gt; None:\n    \"\"\"Handles the event when a message is revoked and logs the associated exception.\n\n    Args:\n        message: The message instance that was revoked.\n        exception: The exception instance that represents the reason for the\n            revocation.\n        result (Any): The result of the revoked operation. This is only provided\n            if the task succeeds\n\n    Returns:\n        None\n\n    \"\"\"\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.on_submit","title":"<code>on_submit(message)</code>","text":"<p>Handles the action to be performed when a message is submitted. This method processes  the provided message and executes the required behavior upon submission.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>The message object submitted for processing.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>def on_submit(self, message: Message) -&gt; None:\n    \"\"\"Handles the action to be performed when a message is submitted.\n    This method processes  the provided message and executes the required\n    behavior upon submission.\n\n    Args:\n        message (Message): The message object submitted for processing.\n\n    Returns:\n        None\n\n    \"\"\"\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.on_success","title":"<code>on_success(message, result)</code>","text":"<p>Handles successful outcomes of an operation by processing the given message and corresponding result.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>An instance of the Message class that contains relevant information about the operation.</p> required <code>result</code> <code>Any</code> <p>The result of the completed operation, which can be of any type.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>def on_success(self, message: Message, result: Any) -&gt; None:\n    \"\"\"Handles successful outcomes of an operation by processing the given message\n    and corresponding result.\n\n    Args:\n        message: An instance of the Message class that contains relevant information\n            about the operation.\n        result: The result of the completed operation, which can be of any type.\n\n    Returns:\n        None\n\n    \"\"\"\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.op","title":"<code>op(message)</code>","text":"<p>Pass <code>message</code> data to <code>function</code> for processing.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>message to perform the operation against</p> required <p>Returns:</p> Name Type Description <code>result</code> <code>Any</code> <p>output of the function</p> Notes <ul> <li>If, and only if, the signature of <code>function</code> contains   a <code>message</code> parameter, <code>message</code> itself will be passed   along with any <code>args</code> and <code>kwargs</code> contained in the message.</li> </ul> Warning <ul> <li><code>message</code> will not be passed in cases where a \"message\"   exists in <code>message.kwargs</code>.</li> </ul> Source code in <code>alsek/core/task.py</code> <pre><code>def op(self, message: Message) -&gt; Any:\n    \"\"\"Pass ``message`` data to ``function`` for processing.\n\n    Args:\n        message (Message): message to perform the operation against\n\n    Returns:\n        result (Any): output of the function\n\n    Notes:\n        * If, and only if, the signature of ``function`` contains\n          a ``message`` parameter, ``message`` itself will be passed\n          along with any ``args`` and ``kwargs`` contained in the message.\n\n    Warning:\n        * ``message`` will not be passed in cases where a \"message\"\n          exists in ``message.kwargs``.\n\n    \"\"\"\n    if \"message\" not in message.kwargs and _expects_message(self.function):\n        return self.function(*message.args, **message.kwargs, message=message)\n    else:\n        return self.function(*message.args, **message.kwargs)\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.post_op","title":"<code>post_op(message, result)</code>","text":"<p>Operation to perform after running <code>op</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>message <code>op()</code> was run against</p> required <code>result</code> <code>Any</code> <p>output of <code>op()</code></p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>def post_op(self, message: Message, result: Any) -&gt; None:\n    \"\"\"Operation to perform after running ``op``.\n\n    Args:\n        message (Message): message ``op()`` was run against\n        result (Any): output of ``op()``\n\n    Returns:\n        None\n\n    \"\"\"\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.pre_op","title":"<code>pre_op(message)</code>","text":"<p>Operation to perform before running <code>op</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>message <code>op</code> will be run against.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>def pre_op(self, message: Message) -&gt; None:\n    \"\"\"Operation to perform before running ``op``.\n\n    Args:\n        message (Message): message ``op`` will be run against.\n\n    Returns:\n        None\n\n    \"\"\"\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.revoke","title":"<code>revoke(message, skip_if_running=False)</code>","text":"<p>Revoke the task.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>message to revoke</p> required <code>skip_if_running</code> <code>bool</code> <p>if <code>True</code>, skip revoking the task if it is currently RUNNING. Notes: requires <code>status_tracker</code> to be set.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>@magic_logger(\n    before=lambda message: log.info(\"Revoking %s...\", message.summary),\n    after=lambda input_: log.debug(\"Revoked %s.\", input_[\"message\"].summary),\n)\ndef revoke(self, message: Message, skip_if_running: bool = False) -&gt; None:\n    \"\"\"Revoke the task.\n\n    Args:\n        message (Message): message to revoke\n        skip_if_running (bool): if ``True``, skip revoking the task if it is currently RUNNING.\n            Notes: requires ``status_tracker`` to be set.\n\n    Returns:\n        None\n\n    \"\"\"\n    log.info(\"Revoking %s...\", message.summary)\n    if (\n        self.status_tracker\n        and self.status_tracker.get(message).status in TERMINAL_TASK_STATUSES\n    ):\n        log.info(\"Message is already terminal: %s\", message.summary)\n        return\n    elif skip_if_running and not self.status_tracker:\n        raise AttributeError(\"`skip_if_running` requires `status_tracker` to be set\")  # fmt: skip\n    elif skip_if_running and (\n        (status_update := self.status_tracker.get(message))\n        and status_update.status == TaskStatus.RUNNING\n    ):\n        log.info(\"Message is currently running: %s\", message.summary)\n        return\n\n    self.broker.backend.set(\n        self._make_revoked_key_name(message),\n        value=True,\n        ttl=DEFAULT_TTL,\n    )\n    message.update(\n        exception_details=ExceptionDetails(\n            name=get_exception_name(RevokedError),\n            text=\"Task Revoked\",\n            traceback=None,\n        ).as_dict()\n    )\n    self.update_status(message, status=TaskStatus.FAILED)\n    self.broker.fail(message)\n</code></pre>"},{"location":"reference/#alsek.core.task.Task.update_status","title":"<code>update_status(message, status)</code>","text":"<p>Update the status of a message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>message to update the status of.</p> required <code>status</code> <code>TaskStatus</code> <p>status to update the message to.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>def update_status(self, message: Message, status: TaskStatus) -&gt; None:\n    \"\"\"Update the status of a message.\n\n    Args:\n        message (Message): message to update the status of.\n        status (TaskStatus): status to update the message to.\n\n    Returns:\n        None\n\n    \"\"\"\n    if self.status_tracker:\n        log.debug(f\"Setting status of '{message.uuid}' to {status}...\")\n        self.status_tracker.set(message, status=status)\n</code></pre>"},{"location":"reference/#alsek.core.task.TriggerTask","title":"<code>TriggerTask</code>","text":"<p>               Bases: <code>Task</code></p> <p>Triggered Task.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>callable</code> <p>function to use for the main operation</p> required <code>trigger</code> <code>(CronTrigger, DateTrigger, IntervalTrigger)</code> <p>trigger for task execution.</p> required <code>broker</code> <code>Broker</code> <p>an Alsek broker</p> required <code>name</code> <code>str</code> <p>the name of the task. If <code>None</code>, the class name will be used.</p> <code>None</code> <code>queue</code> <code>str</code> <p>the name of the queue to generate the task on. If <code>None</code>, the default queue will be used.</p> <code>None</code> <code>timeout</code> <code>int</code> <p>the maximum amount of time (in milliseconds) this task is permitted to run.</p> <code>DEFAULT_TASK_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>maximum number of allowed retries</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff</code> <code>Backoff</code> <p>backoff algorithm and parameters to use when computing delay between retries</p> <code>ExponentialBackoff()</code> <code>result_store</code> <code>ResultStore</code> <p>store for persisting task results</p> <code>None</code> <code>status_tracker</code> <code>StatusTracker</code> <p>store for persisting task statuses</p> <code>None</code> <code>mechanism</code> <code>SupportedMechanismType</code> <p>mechanism for executing the task. Must be either \"process\" or \"thread\".</p> <code>DEFAULT_MECHANISM</code> <code>no_positional_args</code> <code>bool</code> <p>if <code>True</code>, the task will not accept positional arguments.</p> <code>False</code> <p>Raises:</p> Type Description <code>* ``SchedulingError``</code> <p>if the signature of <code>function</code> includes parameters.</p> Source code in <code>alsek/core/task.py</code> <pre><code>class TriggerTask(Task):\n    \"\"\"Triggered Task.\n\n    Args:\n        function (callable): function to use for the main operation\n        trigger (CronTrigger, DateTrigger, IntervalTrigger): trigger\n            for task execution.\n        broker (Broker): an Alsek broker\n        name (str, optional): the name of the task. If ``None``,\n            the class name will be used.\n        queue (str, optional): the name of the queue to generate the task on.\n            If ``None``, the default queue will be used.\n        timeout (int): the maximum amount of time (in milliseconds)\n            this task is permitted to run.\n        max_retries (int, optional): maximum number of allowed retries\n        backoff (Backoff, optional): backoff algorithm and parameters to use when computing\n            delay between retries\n        result_store (ResultStore, optional): store for persisting task results\n        status_tracker (StatusTracker, optional): store for persisting task statuses\n        mechanism (SupportedMechanismType): mechanism for executing the task. Must\n            be either \"process\" or \"thread\".\n        no_positional_args (bool): if ``True``, the task will not accept positional arguments.\n\n    Warnings:\n        * The signature of ``function`` cannot contain parameters\n\n    Raises:\n        * ``SchedulingError``: if the signature of ``function`` includes\n            parameters.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        function: Callable[..., Any],\n        trigger: Union[CronTrigger, DateTrigger, IntervalTrigger],\n        broker: Broker,\n        name: Optional[str] = None,\n        queue: Optional[str] = None,\n        timeout: int = DEFAULT_TASK_TIMEOUT,\n        max_retries: Optional[int] = DEFAULT_MAX_RETRIES,\n        backoff: Optional[Backoff] = ExponentialBackoff(),\n        result_store: Optional[ResultStore] = None,\n        status_tracker: Optional[StatusTracker] = None,\n        mechanism: SupportedMechanismType = DEFAULT_MECHANISM,\n        no_positional_args: bool = False,\n    ) -&gt; None:\n        if inspect.signature(function).parameters:\n            raise SchedulingError(\"Function signature cannot includes parameters\")\n        super().__init__(\n            function=function,\n            broker=broker,\n            name=name,\n            queue=queue,\n            timeout=timeout,\n            max_retries=max_retries,\n            backoff=backoff,\n            result_store=result_store,\n            status_tracker=status_tracker,\n            mechanism=mechanism,\n            no_positional_args=no_positional_args,\n        )\n        self.trigger = trigger\n\n        self.scheduler = BackgroundScheduler()\n        self.scheduler.start()\n\n    def serialize(self) -&gt; dict[str, Any]:\n        serialized_task = super().serialize()\n        serialized_task[\"settings\"][\"trigger\"] = self.trigger\n        return serialized_task\n\n    @property\n    def _job(self) -&gt; Optional[Job]:\n        return self.scheduler.get_job(self.name)\n\n    def _submit(self, message: Message, **options: Any) -&gt; None:\n        if self._job:\n            raise SchedulingError(\"Task already scheduled\")\n\n        self.scheduler.add_job(\n            _MultiSubmit(\n                message=message,\n                broker=self.broker,\n                on_submit=self.on_submit,\n                callback_op=partial(self.update_status, status=TaskStatus.SUBMITTED),\n                options=options,\n            ),\n            trigger=self.trigger,\n            id=self.name,\n        )\n\n    @property\n    def generated(self) -&gt; bool:\n        \"\"\"If the task has been generated.\"\"\"\n        return bool(self._job)\n\n    def clear(self) -&gt; None:\n        \"\"\"Clear the currently scheduled task.\n\n        Returns:\n            None\n\n        Raises\n            * AttributeError: if a task has not yet\n                been generated\n\n        \"\"\"\n        try:\n            self.scheduler.remove_job(self.name)\n        except JobLookupError:\n            raise AttributeError(\"Task not generated\")\n\n    def pause(self) -&gt; None:\n        \"\"\"Pause the underlying scheduler.\n\n        Returns:\n            None\n\n        \"\"\"\n        self.scheduler.pause()\n\n    def resume(self) -&gt; None:\n        \"\"\"Resume the underlying scheduler.\n\n        Returns:\n            None\n\n        \"\"\"\n        self.scheduler.resume()\n\n    def shutdown(self) -&gt; None:\n        \"\"\"Shutdown the underlying scheduler.\n\n        Returns:\n            None\n\n        \"\"\"\n        self.scheduler.shutdown()\n</code></pre>"},{"location":"reference/#alsek.core.task.TriggerTask.generated","title":"<code>generated</code>  <code>property</code>","text":"<p>If the task has been generated.</p>"},{"location":"reference/#alsek.core.task.TriggerTask.clear","title":"<code>clear()</code>","text":"<p>Clear the currently scheduled task.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises     * AttributeError: if a task has not yet         been generated</p> Source code in <code>alsek/core/task.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Clear the currently scheduled task.\n\n    Returns:\n        None\n\n    Raises\n        * AttributeError: if a task has not yet\n            been generated\n\n    \"\"\"\n    try:\n        self.scheduler.remove_job(self.name)\n    except JobLookupError:\n        raise AttributeError(\"Task not generated\")\n</code></pre>"},{"location":"reference/#alsek.core.task.TriggerTask.pause","title":"<code>pause()</code>","text":"<p>Pause the underlying scheduler.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>def pause(self) -&gt; None:\n    \"\"\"Pause the underlying scheduler.\n\n    Returns:\n        None\n\n    \"\"\"\n    self.scheduler.pause()\n</code></pre>"},{"location":"reference/#alsek.core.task.TriggerTask.resume","title":"<code>resume()</code>","text":"<p>Resume the underlying scheduler.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>def resume(self) -&gt; None:\n    \"\"\"Resume the underlying scheduler.\n\n    Returns:\n        None\n\n    \"\"\"\n    self.scheduler.resume()\n</code></pre>"},{"location":"reference/#alsek.core.task.TriggerTask.shutdown","title":"<code>shutdown()</code>","text":"<p>Shutdown the underlying scheduler.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/task.py</code> <pre><code>def shutdown(self) -&gt; None:\n    \"\"\"Shutdown the underlying scheduler.\n\n    Returns:\n        None\n\n    \"\"\"\n    self.scheduler.shutdown()\n</code></pre>"},{"location":"reference/#alsek.core.task.task","title":"<code>task(broker, name=None, queue=None, timeout=DEFAULT_TASK_TIMEOUT, max_retries=DEFAULT_MAX_RETRIES, backoff=ExponentialBackoff(), trigger=None, result_store=None, status_tracker=None, mechanism=DEFAULT_MECHANISM, no_positional_args=False, base_task=None)</code>","text":"<p>Wrapper for task construction.</p> <p>Parameters:</p> Name Type Description Default <code>broker</code> <code>Broker</code> <p>an Alsek broker</p> required <code>name</code> <code>str</code> <p>the name of the task. If <code>None</code>, the class name will be used.</p> <code>None</code> <code>queue</code> <code>str</code> <p>the name of the queue to generate the task on. If <code>None</code>, the default queue will be used.</p> <code>None</code> <code>timeout</code> <code>int</code> <p>the maximum amount of time (in milliseconds) this task is permitted to run.</p> <code>DEFAULT_TASK_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>maximum number of allowed retries</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff</code> <code>Backoff</code> <p>backoff algorithm and parameters to use when computing delay between retries</p> <code>ExponentialBackoff()</code> <code>trigger</code> <code>(CronTrigger, DateTrigger, IntervalTrigger)</code> <p>trigger for task execution.</p> <code>None</code> <code>result_store</code> <code>ResultStore</code> <p>store for persisting task results</p> <code>None</code> <code>status_tracker</code> <code>StatusTracker</code> <p>store for persisting task statuses</p> <code>None</code> <code>mechanism</code> <code>SupportedMechanismType</code> <p>mechanism for executing the task. Must be either \"process\" or \"thread\".</p> <code>DEFAULT_MECHANISM</code> <code>no_positional_args</code> <code>bool</code> <p>if <code>True</code>, the task will not accept positional arguments.</p> <code>False</code> <code>base_task</code> <code>Type[Task]</code> <p>base to use for task constuction. If <code>None</code>, a base task will be selected automatically.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>wrapper</code> <code>callable</code> <p>task-wrapped function</p> <p>Raises:</p> Type Description <code>* ValueError</code> <p>if a <code>trigger</code> and not supported by <code>base_task</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from alsek import Broker, task\n&gt;&gt;&gt; from alsek.storage.backends.redis.standard import RedisBackend\n</code></pre> <pre><code>&gt;&gt;&gt; backend = RedisBackend()\n&gt;&gt;&gt; broker = Broker(backend)\n</code></pre> <pre><code>&gt;&gt;&gt; @task(broker)\n... def add(a: int, b: int) -&gt; int:\n...     return a + b\n</code></pre> Source code in <code>alsek/core/task.py</code> <pre><code>def task(\n    broker: Broker,\n    name: Optional[str] = None,\n    queue: Optional[str] = None,\n    timeout: int = DEFAULT_TASK_TIMEOUT,\n    max_retries: Optional[int] = DEFAULT_MAX_RETRIES,\n    backoff: Optional[Backoff] = ExponentialBackoff(),\n    trigger: Optional[Union[CronTrigger, DateTrigger, IntervalTrigger]] = None,\n    result_store: Optional[ResultStore] = None,\n    status_tracker: Optional[StatusTracker] = None,\n    mechanism: SupportedMechanismType = DEFAULT_MECHANISM,\n    no_positional_args: bool = False,\n    base_task: Optional[Type[Task]] = None,\n) -&gt; Callable[..., Task]:\n    \"\"\"Wrapper for task construction.\n\n    Args:\n        broker (Broker): an Alsek broker\n        name (str, optional): the name of the task. If ``None``,\n            the class name will be used.\n        queue (str, optional): the name of the queue to generate the task on.\n            If ``None``, the default queue will be used.\n        timeout (int): the maximum amount of time (in milliseconds)\n            this task is permitted to run.\n        max_retries (int, optional): maximum number of allowed retries\n        backoff (Backoff, optional): backoff algorithm and parameters to use when computing\n            delay between retries\n        trigger (CronTrigger, DateTrigger, IntervalTrigger, optional): trigger\n            for task execution.\n        result_store (ResultStore, optional): store for persisting task results\n        status_tracker (StatusTracker, optional): store for persisting task statuses\n        mechanism (SupportedMechanismType): mechanism for executing the task. Must\n            be either \"process\" or \"thread\".\n        no_positional_args (bool): if ``True``, the task will not accept positional arguments.\n        base_task (Type[Task]): base to use for task constuction.\n            If ``None``, a base task will be selected automatically.\n\n    Returns:\n        wrapper (callable): task-wrapped function\n\n    Raises:\n        * ValueError: if a ``trigger`` and not supported by ``base_task``\n\n    Examples:\n        &gt;&gt;&gt; from alsek import Broker, task\n        &gt;&gt;&gt; from alsek.storage.backends.redis.standard import RedisBackend\n\n        &gt;&gt;&gt; backend = RedisBackend()\n        &gt;&gt;&gt; broker = Broker(backend)\n\n        &gt;&gt;&gt; @task(broker)\n        ... def add(a: int, b: int) -&gt; int:\n        ...     return a + b\n\n    \"\"\"\n    parsed_base_task = _parse_base_task(base_task, trigger=trigger)\n    base_task_signature = inspect.signature(parsed_base_task.__init__)\n\n    if trigger and \"trigger\" not in base_task_signature.parameters:\n        raise ValueError(f\"Trigger not supported by {parsed_base_task}\")\n\n    def wrapper(function: Callable[..., Any]) -&gt; Task:\n        return parsed_base_task(  # type: ignore\n            function=function,\n            name=name,\n            broker=broker,\n            queue=queue,\n            timeout=timeout,\n            max_retries=max_retries,\n            backoff=backoff,\n            mechanism=mechanism,\n            no_positional_args=no_positional_args,\n            result_store=result_store,\n            status_tracker=status_tracker,\n            **(  # noqa (handled above)\n                dict(trigger=trigger)\n                if \"trigger\" in base_task_signature.parameters\n                else dict()\n            ),\n        )\n\n    return wrapper\n</code></pre>"},{"location":"reference/#alsek.core.worker","title":"<code>worker</code>","text":""},{"location":"reference/#alsek.core.worker.process","title":"<code>process</code>","text":"<p>Process Worker Pool</p>"},{"location":"reference/#alsek.core.worker.process.ProcessWorkerPool","title":"<code>ProcessWorkerPool</code>","text":"<p>               Bases: <code>BaseWorkerPool</code></p> <p>Fixed-size pool that runs each task in its own forked process (via <code>ProcessTaskFuture</code>).</p> <p>Parameters:</p> Name Type Description Default <code>n_processes</code> <code>int</code> <p>Maximum number of live <code>ProcessTaskFuture</code>s.</p> <code>None</code> <code>prune_interval</code> <code>int</code> <p>Number of milliseconds between background runs of a scan to prune spent futures.</p> <code>100</code> Source code in <code>alsek/core/worker/process.py</code> <pre><code>class ProcessWorkerPool(BaseWorkerPool):\n    \"\"\"Fixed-size pool that runs each task in its *own* forked process\n    (via `ProcessTaskFuture`).\n\n    Args:\n        n_processes (int): Maximum number of live `ProcessTaskFuture`s.\n        prune_interval (int): Number of milliseconds between background\n            runs of a scan to prune spent futures.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        n_processes: Optional[int] = None,\n        prune_interval: int = 100,\n        **kwargs: Any,\n    ) -&gt; None:\n        super().__init__(mechanism=\"process\", **kwargs)\n        self.n_processes = n_processes or smart_cpu_count()\n        self.prune_interval = prune_interval\n\n        self._futures: List[ProcessTaskFuture] = list()\n        self._shutdown_event = threading.Event()\n\n        # Use a simple daemon thread instead of APScheduler\n        self._prune_thread = threading.Thread(\n            target=self._prune_loop,\n            daemon=True,\n            name=\"ProcessPool-Pruner\",\n        )\n        self._prune_thread.start()\n\n    def _prune_loop(self) -&gt; None:\n        \"\"\"Background thread that periodically prunes futures.\"\"\"\n        while not self._shutdown_event.is_set():\n            try:\n                self.prune()\n            except Exception as e:\n                log.exception(\"Error during future pruning: %s\", e)\n\n            # Sleep until next interval or shutdown\n            self._shutdown_event.wait(self.prune_interval / 1000)\n\n    def on_boot(self) -&gt; None:\n        log.info(\n            \"Starting process-based worker pool with up to %s workers (%s max process%s)...\",\n            self.n_processes,\n            self.n_processes,\n            \"\" if self.n_processes == 1 else \"es\",\n        )\n        super().on_boot()\n\n    def has_slot(self) -&gt; bool:\n        return len(self._futures) &lt; self.n_processes\n\n    def prune(self) -&gt; None:\n        \"\"\"Prune spent futures.\"\"\"\n        kept: list[ProcessTaskFuture] = list()\n        for f in self._futures:\n            if f.time_limit_exceeded:\n                f.stop(TimeoutError)\n                f.clean_up(ignore_errors=True)\n            elif not f.complete:\n                kept.append(f)\n        self._futures = kept\n\n    def on_shutdown(self) -&gt; None:\n        \"\"\"Terminate everything that is still alive.\"\"\"\n        self._shutdown_event.set()\n\n        for f in self._futures:\n            if not f.complete:\n                f.stop(TerminationError)\n                f.clean_up(ignore_errors=True)\n        self._futures.clear()\n\n    def submit_message(self, message: Message) -&gt; bool:\n        \"\"\"Submit a single message\"\"\"\n        submitted = False\n        if self.has_slot():\n            self._futures.append(\n                ProcessTaskFuture(\n                    task=self._task_map[message.task_name],\n                    message=message,\n                )\n            )\n            submitted = True\n        return submitted\n</code></pre> <code>on_shutdown()</code> <p>Terminate everything that is still alive.</p> Source code in <code>alsek/core/worker/process.py</code> <pre><code>def on_shutdown(self) -&gt; None:\n    \"\"\"Terminate everything that is still alive.\"\"\"\n    self._shutdown_event.set()\n\n    for f in self._futures:\n        if not f.complete:\n            f.stop(TerminationError)\n            f.clean_up(ignore_errors=True)\n    self._futures.clear()\n</code></pre> <code>prune()</code> <p>Prune spent futures.</p> Source code in <code>alsek/core/worker/process.py</code> <pre><code>def prune(self) -&gt; None:\n    \"\"\"Prune spent futures.\"\"\"\n    kept: list[ProcessTaskFuture] = list()\n    for f in self._futures:\n        if f.time_limit_exceeded:\n            f.stop(TimeoutError)\n            f.clean_up(ignore_errors=True)\n        elif not f.complete:\n            kept.append(f)\n    self._futures = kept\n</code></pre> <code>submit_message(message)</code> <p>Submit a single message</p> Source code in <code>alsek/core/worker/process.py</code> <pre><code>def submit_message(self, message: Message) -&gt; bool:\n    \"\"\"Submit a single message\"\"\"\n    submitted = False\n    if self.has_slot():\n        self._futures.append(\n            ProcessTaskFuture(\n                task=self._task_map[message.task_name],\n                message=message,\n            )\n        )\n        submitted = True\n    return submitted\n</code></pre>"},{"location":"reference/#alsek.core.worker.thread","title":"<code>thread</code>","text":"<p>Thread Worker Pool</p>"},{"location":"reference/#alsek.core.worker.thread.ProcessGroup","title":"<code>ProcessGroup</code>","text":"Source code in <code>alsek/core/worker/thread.py</code> <pre><code>class ProcessGroup:\n    def __init__(\n        self,\n        n_threads: int,\n        complete_only_on_thread_exit: bool,\n        slot_wait_interval_seconds: float,\n        package_name: Optional[str] = None,\n    ) -&gt; None:\n        self._n_threads = n_threads\n        self.complete_only_on_thread_exit = complete_only_on_thread_exit\n        self.slot_wait_interval_seconds = slot_wait_interval_seconds\n        self.package_name = package_name\n\n        self.queue: Queue = Queue(maxsize=n_threads)\n        self.shutdown_event: Event = Event()\n        self.process = Process(\n            target=_start_thread_worker,\n            args=(\n                self.queue,\n                self.shutdown_event,\n                n_threads,\n                slot_wait_interval_seconds,\n                get_logger().level,\n                package_name,\n            ),\n            daemon=True,\n        )\n        self.process.start()\n\n    def has_slot(self) -&gt; bool:\n        return not self.queue.full()\n\n    def submit(self, task: Task, message: Message) -&gt; bool:\n        payload = (\n            task.serialize(),\n            message.data,\n            self.complete_only_on_thread_exit,\n        )\n        try:\n            self.queue.put(dill.dumps(payload), block=False)\n            return True\n        except queue.Full:\n            return False\n\n    def stop(self, timeout: int | float = 2) -&gt; None:\n        \"\"\"Stop the group of threads in this process group.\n\n        Args:\n            timeout (int, float): the time to wait in seconds\n\n        Returns:\n            None\n\n        \"\"\"\n        # 1. Signal\n        self.shutdown_event.set()\n        # 2. Wait a bit for graceful exit\n        self.process.join(timeout=timeout)\n        # 3. Hard kill if still alive\n        if self.process.is_alive():\n            self.process.kill()\n</code></pre> <code>stop(timeout=2)</code> <p>Stop the group of threads in this process group.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>(int, float)</code> <p>the time to wait in seconds</p> <code>2</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/core/worker/thread.py</code> <pre><code>def stop(self, timeout: int | float = 2) -&gt; None:\n    \"\"\"Stop the group of threads in this process group.\n\n    Args:\n        timeout (int, float): the time to wait in seconds\n\n    Returns:\n        None\n\n    \"\"\"\n    # 1. Signal\n    self.shutdown_event.set()\n    # 2. Wait a bit for graceful exit\n    self.process.join(timeout=timeout)\n    # 3. Hard kill if still alive\n    if self.process.is_alive():\n        self.process.kill()\n</code></pre>"},{"location":"reference/#alsek.core.worker.thread.ThreadWorkerPool","title":"<code>ThreadWorkerPool</code>","text":"<p>               Bases: <code>BaseWorkerPool</code></p> <p>Elastic thread-based pool.</p> <p>Parameters:</p> Name Type Description Default <code>n_threads</code> <code>int</code> <p>the number of threads to use per group.</p> <code>8</code> <code>n_processes</code> <code>int</code> <p>the number of process groups to use</p> <code>None</code> <code>n_process_floor</code> <code>int</code> <p>the minimum number of processes to have active at any given time, regardless of load.</p> <code>1</code> <code>complete_only_on_thread_exit</code> <code>bool</code> <p>if <code>True</code>, only mark the future as complete when the thread formally exits (i.e., is not alive). Pro: more rigorous \u2014 avoids marking the task complete until the thread fully terminates. Useful when you need strict control over thread lifecycle (e.g., for resource management). Con: may lead to hanging if the thread doesn't terminate quickly (e.g., when using <code>thread_raise()</code> during revocation). This can also temporarily result in more than the allotted number of threads running, because it entails treating a thread as expired regardless of its actual status.</p> <code>False</code> <code>package_name</code> <code>str</code> <p>the name of the package to import in worker processes to trigger any initialization code in its <code>__init__.py</code>.</p> <code>None</code> <code>**kwargs</code> <code>Keyword Args</code> <p>Keyword arguments to pass to <code>BaseWorkerPool()</code>.</p> <code>{}</code> Notes <ul> <li>Spawns a new process (ThreadProcessGroup) only when all existing   groups are saturated and the hard ceiling <code>n_processes</code> hasn't been hit.</li> <li>Each group runs up to <code>n_threads</code> true ThreadTaskFutures concurrently.</li> <li>Total worker capacity is <code>n_threads * n_processes</code>.</li> </ul> Source code in <code>alsek/core/worker/thread.py</code> <pre><code>class ThreadWorkerPool(BaseWorkerPool):\n    \"\"\"Elastic thread-based pool.\n\n    Args:\n        n_threads (int): the number of threads to use per group.\n        n_processes (int, optional): the number of process groups to use\n        n_process_floor (int): the minimum number of processes to have active\n            at any given time, regardless of load.\n        complete_only_on_thread_exit (bool): if ``True``, only mark the future\n            as complete when the thread formally exits (i.e., is not alive).\n            Pro: more rigorous \u2014 avoids marking the task complete until the thread fully terminates.\n            Useful when you need strict control over thread lifecycle (e.g., for resource management).\n            Con: may lead to hanging if the thread doesn't terminate quickly (e.g., when using\n            `thread_raise()` during revocation). This can also temporarily result in more than the\n            allotted number of threads running, because it entails treating a thread as\n            expired regardless of its actual status.\n        package_name (str, optional): the name of the package to import in worker processes\n            to trigger any initialization code in its `__init__.py`.\n        **kwargs (Keyword Args): Keyword arguments to pass to ``BaseWorkerPool()``.\n\n    Notes:\n        * Spawns a new **process** (ThreadProcessGroup) only when all existing\n          groups are saturated and the hard ceiling `n_processes` hasn't been hit.\n        * Each group runs up to `n_threads` true ThreadTaskFutures concurrently.\n        * Total worker capacity is ``n_threads * n_processes``.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        n_threads: int = 8,\n        n_processes: Optional[int] = None,\n        n_process_floor: int = 1,\n        complete_only_on_thread_exit: bool = False,\n        package_name: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        super().__init__(mechanism=\"thread\", **kwargs)\n        self.n_threads = n_threads\n        self.n_processes = n_processes or smart_cpu_count()\n        self.n_process_floor = n_process_floor\n        self.complete_only_on_thread_exit = complete_only_on_thread_exit\n        self.package_name = package_name\n\n        if self.n_threads &lt;= 0:\n            raise ValueError(f\"n_threads must be &gt; 0\")\n        elif self.n_processes &lt;= 0:\n            raise ValueError(f\"n_processes must be &gt; 0\")\n        if self.n_process_floor &gt; self.n_processes:\n            raise ValueError(f\"n_process_floor must be &lt;= n_processes.\")\n\n        self._progress_groups: List[ProcessGroup] = list()\n\n    def _make_new_process_group(self) -&gt; Optional[ProcessGroup]:\n        if (\n            self.stop_signal.exit_event.is_set()\n            or len(self._progress_groups) &gt;= self.n_processes\n        ):\n            return None\n\n        log.debug(\"Starting new process group...\")\n        new_process_group = ProcessGroup(\n            n_threads=self.n_threads,\n            complete_only_on_thread_exit=self.complete_only_on_thread_exit,\n            slot_wait_interval_seconds=self._slot_wait_interval_seconds,\n            package_name=self.package_name,\n        )\n        self._progress_groups.append(new_process_group)\n        return new_process_group\n\n    def on_boot(self) -&gt; None:\n        log.info(\n            \"Starting thread-based worker pool with up to %s workers (%s max thread%s and %s max process%s)...\",\n            self.n_threads * self.n_processes,\n            self.n_threads,\n            \"\" if self.n_threads == 1 else \"s\",\n            self.n_processes,\n            \"\" if self.n_processes == 1 else \"es\",\n        )\n        if self.n_process_floor:\n            log.info(\n                \"Provisioning initial collection of %s processes...\",\n                self.n_process_floor,\n            )\n            for _ in range(self.n_process_floor):\n                self._make_new_process_group()\n        super().on_boot()\n\n    def on_shutdown(self) -&gt; None:\n        \"\"\"Stop all futures in the pool.\"\"\"\n        for g in self._progress_groups:\n            g.stop()\n\n    def prune(self) -&gt; None:\n        \"\"\"Prune exited process groups, but only enforce floor if NOT shutting down.\"\"\"\n        # 1. Filter out any groups whose processes have exited\n        self._progress_groups = [\n            g\n            for g in self._progress_groups\n            if g.process.join(timeout=0) or g.process.is_alive()\n        ]\n\n        # 2. Otherwise, ensure at least n_process_floor\n        missing = max(0, self.n_process_floor - len(self._progress_groups))\n        for _ in range(missing):\n            self._make_new_process_group()\n\n    def _acquire_group(self) -&gt; Optional[ProcessGroup]:\n        for g in self._progress_groups:\n            if g.has_slot():\n                return g\n\n        if len(self._progress_groups) &lt; self.n_processes:\n            return self._make_new_process_group()\n        return None\n\n    def submit_message(self, message: Message) -&gt; bool:\n        \"\"\"Submit a single message\"\"\"\n        submitted = False\n        if group := self._acquire_group():  # we have a slot \u2192 run it\n            submitted = group.submit(\n                task=self._task_map[message.task_name],\n                message=message,\n            )\n        return submitted\n</code></pre> <code>on_shutdown()</code> <p>Stop all futures in the pool.</p> Source code in <code>alsek/core/worker/thread.py</code> <pre><code>def on_shutdown(self) -&gt; None:\n    \"\"\"Stop all futures in the pool.\"\"\"\n    for g in self._progress_groups:\n        g.stop()\n</code></pre> <code>prune()</code> <p>Prune exited process groups, but only enforce floor if NOT shutting down.</p> Source code in <code>alsek/core/worker/thread.py</code> <pre><code>def prune(self) -&gt; None:\n    \"\"\"Prune exited process groups, but only enforce floor if NOT shutting down.\"\"\"\n    # 1. Filter out any groups whose processes have exited\n    self._progress_groups = [\n        g\n        for g in self._progress_groups\n        if g.process.join(timeout=0) or g.process.is_alive()\n    ]\n\n    # 2. Otherwise, ensure at least n_process_floor\n    missing = max(0, self.n_process_floor - len(self._progress_groups))\n    for _ in range(missing):\n        self._make_new_process_group()\n</code></pre> <code>submit_message(message)</code> <p>Submit a single message</p> Source code in <code>alsek/core/worker/thread.py</code> <pre><code>def submit_message(self, message: Message) -&gt; bool:\n    \"\"\"Submit a single message\"\"\"\n    submitted = False\n    if group := self._acquire_group():  # we have a slot \u2192 run it\n        submitted = group.submit(\n            task=self._task_map[message.task_name],\n            message=message,\n        )\n    return submitted\n</code></pre>"},{"location":"reference/#alsek.core.worker.thread.ThreadsInProcessGroup","title":"<code>ThreadsInProcessGroup</code>","text":"<p>\u2022 Runs inside a forked process \u2022 Accepts work items via <code>Queue</code> \u2022 Spawns at most <code>n_threads</code> ThreadTaskFutures concurrently</p> Source code in <code>alsek/core/worker/thread.py</code> <pre><code>class ThreadsInProcessGroup:\n    \"\"\"\n    \u2022 Runs inside a forked process\n    \u2022 Accepts work items via `Queue`\n    \u2022 Spawns at most `n_threads` ThreadTaskFutures concurrently\n    \"\"\"\n\n    def __init__(\n        self,\n        q: Queue,\n        shutdown_event: Event,\n        n_threads: int,\n        slot_wait_interval_seconds: float,\n        log_level: int = logging.INFO,\n    ) -&gt; None:\n        self.q = q\n        self.shutdown_event = shutdown_event\n        self.n_threads = n_threads\n        self.slot_wait_interval_seconds = slot_wait_interval_seconds\n        self.log_level = log_level\n\n        setup_logging(self.log_level)\n\n        self._live: list[ThreadTaskFuture] = list()\n\n    def _prune(self) -&gt; None:\n        kept: list[ThreadTaskFuture] = list()\n        for f in self._live:\n            if f.time_limit_exceeded:\n                f.stop(TimeoutError)\n                f.clean_up(ignore_errors=True)\n            elif not f.complete:\n                kept.append(f)\n        self._live = kept\n\n    def _has_capacity(self) -&gt; bool:\n        return len(self._live) &lt; self.n_threads\n\n    def _spawn_future(self, payload: bytes) -&gt; None:\n        task_dict, msg_dict, exit_flag = dill.loads(payload)\n        self._live.append(\n            ThreadTaskFuture(\n                task=Task.deserialize(task_dict),\n                message=Message(**msg_dict),\n                complete_only_on_thread_exit=exit_flag,\n            )\n        )\n\n    def _stop_all_live_futures(self) -&gt; None:\n        for f in self._live:\n            if not f.complete:\n                f.stop(TerminationError)\n                f.clean_up(ignore_errors=True)\n\n    @suppress_exception(\n        KeyboardInterrupt,\n        on_suppress=lambda error: log.info(\"Keyboard Interrupt Detected\"),\n    )\n    def run(self) -&gt; None:\n        try:\n            while not self.shutdown_event.is_set():\n                # 1. reap finished / timed-out futures\n                self._prune()\n\n                # 2. Throttle if thread slots are full\n                if not self._has_capacity():\n                    # Wait *either* for a slot OR the shutdown flag\n                    self.shutdown_event.wait(self.slot_wait_interval_seconds)\n                    continue\n\n                # 3. Try to pull one unit of work\n                try:\n                    payload = self.q.get(timeout=self.slot_wait_interval_seconds)\n                except queue.Empty:\n                    continue\n\n                # 4. Launch a new ThreadTaskFuture\n                self._spawn_future(payload)\n        finally:\n            self._stop_all_live_futures()\n</code></pre>"},{"location":"reference/#alsek.defaults","title":"<code>defaults</code>","text":"<p>Defaults</p>"},{"location":"reference/#alsek.exceptions","title":"<code>exceptions</code>","text":"<p>Exceptions</p>"},{"location":"reference/#alsek.exceptions.AlsekError","title":"<code>AlsekError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base Alsek error.</p> Source code in <code>alsek/exceptions.py</code> <pre><code>class AlsekError(Exception):\n    \"\"\"Base Alsek error.\"\"\"\n</code></pre>"},{"location":"reference/#alsek.exceptions.MessageAlreadyExistsError","title":"<code>MessageAlreadyExistsError</code>","text":"<p>               Bases: <code>AlsekError</code></p> <p>Message already exists in backend.</p> Source code in <code>alsek/exceptions.py</code> <pre><code>class MessageAlreadyExistsError(AlsekError):\n    \"\"\"Message already exists in backend.\"\"\"\n</code></pre>"},{"location":"reference/#alsek.exceptions.MessageDoesNotExistsError","title":"<code>MessageDoesNotExistsError</code>","text":"<p>               Bases: <code>AlsekError</code></p> <p>Message does not exist in backend.</p> Source code in <code>alsek/exceptions.py</code> <pre><code>class MessageDoesNotExistsError(AlsekError):\n    \"\"\"Message does not exist in backend.\"\"\"\n</code></pre>"},{"location":"reference/#alsek.exceptions.MultipleBrokersError","title":"<code>MultipleBrokersError</code>","text":"<p>               Bases: <code>AlsekError</code></p> <p>Multiple brokers in use.</p> Source code in <code>alsek/exceptions.py</code> <pre><code>class MultipleBrokersError(AlsekError):\n    \"\"\"Multiple brokers in use.\"\"\"\n</code></pre>"},{"location":"reference/#alsek.exceptions.NoTasksFoundError","title":"<code>NoTasksFoundError</code>","text":"<p>               Bases: <code>AlsekError</code></p> <p>No tasks found.</p> Source code in <code>alsek/exceptions.py</code> <pre><code>class NoTasksFoundError(AlsekError):\n    \"\"\"No tasks found.\"\"\"\n</code></pre>"},{"location":"reference/#alsek.exceptions.RevokedError","title":"<code>RevokedError</code>","text":"<p>               Bases: <code>AlsekError</code></p> <p>Alsek task revoked error.</p> Source code in <code>alsek/exceptions.py</code> <pre><code>class RevokedError(AlsekError):\n    \"\"\"Alsek task revoked error.\"\"\"\n</code></pre>"},{"location":"reference/#alsek.exceptions.SchedulingError","title":"<code>SchedulingError</code>","text":"<p>               Bases: <code>AlsekError</code></p> <p>Error scheduling work.</p> Source code in <code>alsek/exceptions.py</code> <pre><code>class SchedulingError(AlsekError):\n    \"\"\"Error scheduling work.\"\"\"\n</code></pre>"},{"location":"reference/#alsek.exceptions.TaskNameCollisionError","title":"<code>TaskNameCollisionError</code>","text":"<p>               Bases: <code>AlsekError</code></p> <p>Duplicate task detected.</p> Source code in <code>alsek/exceptions.py</code> <pre><code>class TaskNameCollisionError(AlsekError):\n    \"\"\"Duplicate task detected.\"\"\"\n</code></pre>"},{"location":"reference/#alsek.exceptions.TerminationError","title":"<code>TerminationError</code>","text":"<p>               Bases: <code>AlsekError</code></p> <p>Alsek termination error.</p> Source code in <code>alsek/exceptions.py</code> <pre><code>class TerminationError(AlsekError):\n    \"\"\"Alsek termination error.\"\"\"\n</code></pre>"},{"location":"reference/#alsek.exceptions.ValidationError","title":"<code>ValidationError</code>","text":"<p>               Bases: <code>AlsekError</code></p> <p>Data validation failed.</p> Source code in <code>alsek/exceptions.py</code> <pre><code>class ValidationError(AlsekError):\n    \"\"\"Data validation failed.\"\"\"\n</code></pre>"},{"location":"reference/#alsek.storage","title":"<code>storage</code>","text":"<p>Storage</p>"},{"location":"reference/#alsek.storage.backends","title":"<code>backends</code>","text":"<p>Backend</p>"},{"location":"reference/#alsek.storage.backends.abstract","title":"<code>abstract</code>","text":"<p>Abstract</p>"},{"location":"reference/#alsek.storage.backends.abstract.BaseBackend","title":"<code>BaseBackend</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Backend base class.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str</code> <p>prefix to use when inserting names in the backend</p> <code>DEFAULT_NAMESPACE</code> <code>serializer</code> <code>Serializer</code> <p>tool for encoding and decoding values written into the backend.</p> <code>JsonSerializer()</code> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>class BaseBackend(ABC):\n    \"\"\"Backend base class.\n\n    Args:\n        namespace (str): prefix to use when inserting\n            names in the backend\n        serializer (Serializer): tool for encoding and decoding\n            values written into the backend.\n\n    \"\"\"\n\n    IS_ASYNC: bool = False\n    SUPPORTS_PUBSUB: bool = False\n\n    def __init__(\n        self,\n        namespace: str = DEFAULT_NAMESPACE,\n        serializer: Serializer = JsonSerializer(),\n    ) -&gt; None:\n        self.namespace = namespace\n        self.serializer = serializer\n\n    def __repr__(self) -&gt; str:\n        return auto_repr(\n            self,\n            namespace=self.namespace,\n            serializer=self.serializer,\n        )\n\n    def encode(self) -&gt; bytes:\n        # ToDo: drop `backend` and just dump settings.\n        data = dict(backend=self.__class__, settings=gather_init_params(self))\n        return cast(bytes, dill.dumps(data))\n\n    @classmethod\n    def from_settings(cls, settings: dict[str, Any]) -&gt; BaseBackend:\n        return cls(**settings)\n\n    def in_namespace(self, name: str) -&gt; bool:\n        \"\"\"Determine if ``name`` belong to the current namespace.\n\n        Args:\n            name (str): a name (key)\n\n        Returns:\n            bool\n\n        Warning:\n            * ``name`` should be a complete (i.e., _full_) name.\n\n        \"\"\"\n        return name.startswith(f\"{self.namespace}:\")\n\n    def full_name(self, name: str) -&gt; str:\n        \"\"\"Get an item's complete name, including the namespace\n        in which it exists.\n\n        Args:\n            name (str): the name of an item\n\n        Returns:\n            full_name (str): a name of the form ``\"{NAMESPACE}:{name}\"``\n\n        Notes:\n            * If ``name`` is already the full name, this method\n              will collapse to a no-op.\n\n        \"\"\"\n        if name.startswith(f\"{self.namespace}:\"):\n            return name\n        else:\n            return f\"{self.namespace}:{name}\"\n\n    def short_name(self, name: str) -&gt; str:\n        \"\"\"Get an item's short name, without the namespace\n        in which it exists.\n\n        Args:\n            name (str): the full name of an item\n\n        Returns:\n            short_name (str): ``name`` without the namespace prefix\n\n        Notes:\n            * If ``name`` is already the short name, this method\n              will collapse to a no-op.\n\n        \"\"\"\n        return re.sub(rf\"^{self.namespace}:\", repl=\"\", string=name)\n\n    @abstractmethod\n    def exists(self, name: str) -&gt; bool:\n        \"\"\"Check if ``name`` exists in the backend.\n\n        Args:\n            name (str): name of the item\n\n        Returns:\n            bool\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def set(\n        self,\n        name: str,\n        value: Any,\n        nx: bool = False,\n        ttl: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"Set ``name`` to ``value`` in the backend.\n\n        Args:\n            name (str): name of the item\n            value (Any): value to set for ``name``\n            nx (bool): if ``True`` the item must not exist prior to being set\n            ttl (int, optional): time to live for the entry in milliseconds\n\n        Returns:\n            None\n\n        Raises:\n            KeyError: if ``nx`` is ``True`` and ``name`` already exists\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def get(self, name: str, default: Optional[Union[Any, Type[Empty]]] = None) -&gt; Any:\n        \"\"\"Get ``name`` from the backend.\n\n        Args:\n            name (str): name of the item\n            default (Any, Type[Empty], optional): default value for ``name``\n\n        Returns:\n            Any\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def delete(self, name: str, missing_ok: bool = False) -&gt; None:\n        \"\"\"Delete a ``name`` from the backend.\n\n        Args:\n            name (str): name of the item\n            missing_ok (bool): if ``True``, do not raise for missing\n\n        Returns:\n            None\n\n        Raises:\n            KeyError: if ``missing_ok`` is ``False`` and ``name`` is not found.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def priority_add(self, key: str, unique_id: str, priority: int | float) -&gt; None:\n        \"\"\"Add an item to a priority-sorted set.\n\n        Args:\n            key (str): The name of the sorted set.\n            unique_id (str): The item's (Message's) unique identifier\n            priority (float): The numeric priority score (decide if lower or higher means higher priority).\n\n        Returns:\n            None\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def priority_get(self, key: str) -&gt; Optional[str]:\n        \"\"\"\n        Get (peek) the highest-priority item without removing it.\n\n        Args:\n            key (str): The name of the sorted set.\n\n        Returns:\n            item (str, optional): The member with the highest priority, or None if empty.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def priority_iter(self, key: str) -&gt; Iterable[str]:\n        \"\"\"Iterate over the items in a priority-sorted set.\n\n        Args:\n            key (str): The name of the sorted set.\n\n        Returns:\n            priority (Iterable[str]): An iterable of members in the sorted set, sorted by priority.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def priority_remove(self, key: str, unique_id: str) -&gt; None:\n        \"\"\"Remove an item from a priority-sorted set.\n\n        Args:\n            key (str): The name of the sorted set.\n            unique_id (str): The item's (Message's) unique identifier\n\n        Returns:\n            None\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def pub(self, channel: str, value: Any) -&gt; None:\n        \"\"\"Publish to a channel.\n\n        Args:\n            channel (str): channel name\n            value (Any): value to publish\n\n        Returns:\n            None\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def sub(self, channel: str) -&gt; Iterable[str | dict[str, Any]]:\n        \"\"\"Subscribe to a channel.\n\n        Args:\n            channel (str): channel name\n\n        Returns:\n            Iterable[str | dict[str, Any]]\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def scan(self, pattern: Optional[str] = None) -&gt; Iterable[str]:\n        \"\"\"Scan the backend for matching names.\n\n        Args:\n            pattern (str, optional): pattern to limit search to\n\n        Returns:\n            matches_stream (Iterable[str]): a stream of matching name\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def count(self, pattern: Optional[str] = None) -&gt; int:\n        \"\"\"Count the number of items in the backend.\n\n        Args:\n            pattern (str, optional): pattern to limit count to\n\n        Returns:\n            count (int): number of matching names\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def clear_namespace(self, raise_on_error: bool = True) -&gt; int:\n        \"\"\"Clear all items in backend under the current namespace.\n\n        Args:\n             raise_on_error (bool): raise if a delete operation fails\n\n        Returns:\n            count (int): number of items cleared\n\n        Raises:\n            KeyError: if ``raise_on_error`` and a delete operation fails\n\n        \"\"\"\n        raise NotImplementedError()\n</code></pre> <code>clear_namespace(raise_on_error=True)</code> <code>abstractmethod</code> <p>Clear all items in backend under the current namespace.</p> <p>Parameters:</p> Name Type Description Default <code>raise_on_error</code> <code>bool</code> <p>raise if a delete operation fails</p> <code>True</code> <p>Returns:</p> Name Type Description <code>count</code> <code>int</code> <p>number of items cleared</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if <code>raise_on_error</code> and a delete operation fails</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>@abstractmethod\ndef clear_namespace(self, raise_on_error: bool = True) -&gt; int:\n    \"\"\"Clear all items in backend under the current namespace.\n\n    Args:\n         raise_on_error (bool): raise if a delete operation fails\n\n    Returns:\n        count (int): number of items cleared\n\n    Raises:\n        KeyError: if ``raise_on_error`` and a delete operation fails\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>count(pattern=None)</code> <code>abstractmethod</code> <p>Count the number of items in the backend.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>pattern to limit count to</p> <code>None</code> <p>Returns:</p> Name Type Description <code>count</code> <code>int</code> <p>number of matching names</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>@abstractmethod\ndef count(self, pattern: Optional[str] = None) -&gt; int:\n    \"\"\"Count the number of items in the backend.\n\n    Args:\n        pattern (str, optional): pattern to limit count to\n\n    Returns:\n        count (int): number of matching names\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>delete(name, missing_ok=False)</code> <code>abstractmethod</code> <p>Delete a <code>name</code> from the backend.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the item</p> required <code>missing_ok</code> <code>bool</code> <p>if <code>True</code>, do not raise for missing</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if <code>missing_ok</code> is <code>False</code> and <code>name</code> is not found.</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>@abstractmethod\ndef delete(self, name: str, missing_ok: bool = False) -&gt; None:\n    \"\"\"Delete a ``name`` from the backend.\n\n    Args:\n        name (str): name of the item\n        missing_ok (bool): if ``True``, do not raise for missing\n\n    Returns:\n        None\n\n    Raises:\n        KeyError: if ``missing_ok`` is ``False`` and ``name`` is not found.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>exists(name)</code> <code>abstractmethod</code> <p>Check if <code>name</code> exists in the backend.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the item</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>@abstractmethod\ndef exists(self, name: str) -&gt; bool:\n    \"\"\"Check if ``name`` exists in the backend.\n\n    Args:\n        name (str): name of the item\n\n    Returns:\n        bool\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>full_name(name)</code> <p>Get an item's complete name, including the namespace in which it exists.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>the name of an item</p> required <p>Returns:</p> Name Type Description <code>full_name</code> <code>str</code> <p>a name of the form <code>\"{NAMESPACE}:{name}\"</code></p> Notes <ul> <li>If <code>name</code> is already the full name, this method   will collapse to a no-op.</li> </ul> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>def full_name(self, name: str) -&gt; str:\n    \"\"\"Get an item's complete name, including the namespace\n    in which it exists.\n\n    Args:\n        name (str): the name of an item\n\n    Returns:\n        full_name (str): a name of the form ``\"{NAMESPACE}:{name}\"``\n\n    Notes:\n        * If ``name`` is already the full name, this method\n          will collapse to a no-op.\n\n    \"\"\"\n    if name.startswith(f\"{self.namespace}:\"):\n        return name\n    else:\n        return f\"{self.namespace}:{name}\"\n</code></pre> <code>get(name, default=None)</code> <code>abstractmethod</code> <p>Get <code>name</code> from the backend.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the item</p> required <code>default</code> <code>(Any, Type[Empty])</code> <p>default value for <code>name</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Any</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>@abstractmethod\ndef get(self, name: str, default: Optional[Union[Any, Type[Empty]]] = None) -&gt; Any:\n    \"\"\"Get ``name`` from the backend.\n\n    Args:\n        name (str): name of the item\n        default (Any, Type[Empty], optional): default value for ``name``\n\n    Returns:\n        Any\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>in_namespace(name)</code> <p>Determine if <code>name</code> belong to the current namespace.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>a name (key)</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Warning <ul> <li><code>name</code> should be a complete (i.e., full) name.</li> </ul> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>def in_namespace(self, name: str) -&gt; bool:\n    \"\"\"Determine if ``name`` belong to the current namespace.\n\n    Args:\n        name (str): a name (key)\n\n    Returns:\n        bool\n\n    Warning:\n        * ``name`` should be a complete (i.e., _full_) name.\n\n    \"\"\"\n    return name.startswith(f\"{self.namespace}:\")\n</code></pre> <code>priority_add(key, unique_id, priority)</code> <code>abstractmethod</code> <p>Add an item to a priority-sorted set.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the sorted set.</p> required <code>unique_id</code> <code>str</code> <p>The item's (Message's) unique identifier</p> required <code>priority</code> <code>float</code> <p>The numeric priority score (decide if lower or higher means higher priority).</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>@abstractmethod\ndef priority_add(self, key: str, unique_id: str, priority: int | float) -&gt; None:\n    \"\"\"Add an item to a priority-sorted set.\n\n    Args:\n        key (str): The name of the sorted set.\n        unique_id (str): The item's (Message's) unique identifier\n        priority (float): The numeric priority score (decide if lower or higher means higher priority).\n\n    Returns:\n        None\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>priority_get(key)</code> <code>abstractmethod</code> <p>Get (peek) the highest-priority item without removing it.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the sorted set.</p> required <p>Returns:</p> Name Type Description <code>item</code> <code>(str, optional)</code> <p>The member with the highest priority, or None if empty.</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>@abstractmethod\ndef priority_get(self, key: str) -&gt; Optional[str]:\n    \"\"\"\n    Get (peek) the highest-priority item without removing it.\n\n    Args:\n        key (str): The name of the sorted set.\n\n    Returns:\n        item (str, optional): The member with the highest priority, or None if empty.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>priority_iter(key)</code> <p>Iterate over the items in a priority-sorted set.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the sorted set.</p> required <p>Returns:</p> Name Type Description <code>priority</code> <code>Iterable[str]</code> <p>An iterable of members in the sorted set, sorted by priority.</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>def priority_iter(self, key: str) -&gt; Iterable[str]:\n    \"\"\"Iterate over the items in a priority-sorted set.\n\n    Args:\n        key (str): The name of the sorted set.\n\n    Returns:\n        priority (Iterable[str]): An iterable of members in the sorted set, sorted by priority.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>priority_remove(key, unique_id)</code> <code>abstractmethod</code> <p>Remove an item from a priority-sorted set.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the sorted set.</p> required <code>unique_id</code> <code>str</code> <p>The item's (Message's) unique identifier</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>@abstractmethod\ndef priority_remove(self, key: str, unique_id: str) -&gt; None:\n    \"\"\"Remove an item from a priority-sorted set.\n\n    Args:\n        key (str): The name of the sorted set.\n        unique_id (str): The item's (Message's) unique identifier\n\n    Returns:\n        None\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>pub(channel, value)</code> <p>Publish to a channel.</p> <p>Parameters:</p> Name Type Description Default <code>channel</code> <code>str</code> <p>channel name</p> required <code>value</code> <code>Any</code> <p>value to publish</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>def pub(self, channel: str, value: Any) -&gt; None:\n    \"\"\"Publish to a channel.\n\n    Args:\n        channel (str): channel name\n        value (Any): value to publish\n\n    Returns:\n        None\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>scan(pattern=None)</code> <code>abstractmethod</code> <p>Scan the backend for matching names.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>pattern to limit search to</p> <code>None</code> <p>Returns:</p> Name Type Description <code>matches_stream</code> <code>Iterable[str]</code> <p>a stream of matching name</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>@abstractmethod\ndef scan(self, pattern: Optional[str] = None) -&gt; Iterable[str]:\n    \"\"\"Scan the backend for matching names.\n\n    Args:\n        pattern (str, optional): pattern to limit search to\n\n    Returns:\n        matches_stream (Iterable[str]): a stream of matching name\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>set(name, value, nx=False, ttl=None)</code> <code>abstractmethod</code> <p>Set <code>name</code> to <code>value</code> in the backend.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the item</p> required <code>value</code> <code>Any</code> <p>value to set for <code>name</code></p> required <code>nx</code> <code>bool</code> <p>if <code>True</code> the item must not exist prior to being set</p> <code>False</code> <code>ttl</code> <code>int</code> <p>time to live for the entry in milliseconds</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if <code>nx</code> is <code>True</code> and <code>name</code> already exists</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>@abstractmethod\ndef set(\n    self,\n    name: str,\n    value: Any,\n    nx: bool = False,\n    ttl: Optional[int] = None,\n) -&gt; None:\n    \"\"\"Set ``name`` to ``value`` in the backend.\n\n    Args:\n        name (str): name of the item\n        value (Any): value to set for ``name``\n        nx (bool): if ``True`` the item must not exist prior to being set\n        ttl (int, optional): time to live for the entry in milliseconds\n\n    Returns:\n        None\n\n    Raises:\n        KeyError: if ``nx`` is ``True`` and ``name`` already exists\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <code>short_name(name)</code> <p>Get an item's short name, without the namespace in which it exists.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>the full name of an item</p> required <p>Returns:</p> Name Type Description <code>short_name</code> <code>str</code> <p><code>name</code> without the namespace prefix</p> Notes <ul> <li>If <code>name</code> is already the short name, this method   will collapse to a no-op.</li> </ul> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>def short_name(self, name: str) -&gt; str:\n    \"\"\"Get an item's short name, without the namespace\n    in which it exists.\n\n    Args:\n        name (str): the full name of an item\n\n    Returns:\n        short_name (str): ``name`` without the namespace prefix\n\n    Notes:\n        * If ``name`` is already the short name, this method\n          will collapse to a no-op.\n\n    \"\"\"\n    return re.sub(rf\"^{self.namespace}:\", repl=\"\", string=name)\n</code></pre> <code>sub(channel)</code> <p>Subscribe to a channel.</p> <p>Parameters:</p> Name Type Description Default <code>channel</code> <code>str</code> <p>channel name</p> required <p>Returns:</p> Type Description <code>Iterable[str | dict[str, Any]]</code> <p>Iterable[str | dict[str, Any]]</p> Source code in <code>alsek/storage/backends/abstract.py</code> <pre><code>def sub(self, channel: str) -&gt; Iterable[str | dict[str, Any]]:\n    \"\"\"Subscribe to a channel.\n\n    Args:\n        channel (str): channel name\n\n    Returns:\n        Iterable[str | dict[str, Any]]\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/#alsek.storage.backends.lazy","title":"<code>lazy</code>","text":"<p>Lazy</p>"},{"location":"reference/#alsek.storage.backends.lazy.LazyClient","title":"<code>LazyClient</code>","text":"<p>Lazy client.</p> <p>Wrapper for lazy client initialization.</p> <p>Parameters:</p> Name Type Description Default <code>client_func</code> <code>callable</code> <p>a callable which returns a backend client.</p> required Source code in <code>alsek/storage/backends/lazy.py</code> <pre><code>class LazyClient:\n    \"\"\"Lazy client.\n\n    Wrapper for lazy client initialization.\n\n    Args:\n        client_func (callable): a callable which returns\n            a backend client.\n\n    \"\"\"\n\n    def __init__(self, client_func: Callable[[], Any]) -&gt; None:\n        self.client_func = client_func\n\n    def get(self) -&gt; Any:\n        \"\"\"Execute ``client_func``.\n\n        Returns:\n            client (Any): a backend client\n\n        \"\"\"\n        return self.client_func()\n</code></pre> <code>get()</code> <p>Execute <code>client_func</code>.</p> <p>Returns:</p> Name Type Description <code>client</code> <code>Any</code> <p>a backend client</p> Source code in <code>alsek/storage/backends/lazy.py</code> <pre><code>def get(self) -&gt; Any:\n    \"\"\"Execute ``client_func``.\n\n    Returns:\n        client (Any): a backend client\n\n    \"\"\"\n    return self.client_func()\n</code></pre>"},{"location":"reference/#alsek.storage.backends.redis","title":"<code>redis</code>","text":"<p>Redis</p>"},{"location":"reference/#alsek.storage.backends.redis.asyncio","title":"<code>asyncio</code>","text":"<p>Asynchronous Redis Backend</p> <code>AsyncRedisBackend</code> <p>               Bases: <code>AsyncBackend</code></p> <p>Asynchronous Redis Backend.</p> <p>This backend is powered by Redis and provides asynchronous support for Redis operations.</p> <p>Parameters:</p> Name Type Description Default <code>conn</code> <code>Optional[Union[str, AsyncRedis, LazyClient]]</code> <p>A connection URL, an <code>AsyncRedis</code> instance, or a <code>LazyClient</code>. If <code>None</code>, a default <code>AsyncRedis</code> instance is created.</p> <code>None</code> <code>namespace</code> <code>str</code> <p>prefix to use when inserting names in the backend</p> <code>DEFAULT_NAMESPACE</code> <code>serializer</code> <code>Serializer</code> <p>tool for encoding and decoding values written into the backend.</p> <code>JsonSerializer()</code> Source code in <code>alsek/storage/backends/redis/asyncio.py</code> <pre><code>class AsyncRedisBackend(AsyncBackend):\n    \"\"\"Asynchronous Redis Backend.\n\n    This backend is powered by Redis and provides asynchronous support\n    for Redis operations.\n\n    Args:\n        conn (Optional[Union[str, AsyncRedis, LazyClient]]): A connection URL,\n            an `AsyncRedis` instance, or a `LazyClient`. If `None`, a default\n            `AsyncRedis` instance is created.\n        namespace (str): prefix to use when inserting\n            names in the backend\n        serializer (Serializer): tool for encoding and decoding\n            values written into the backend.\n\n    \"\"\"\n\n    IS_ASYNC: bool = True\n    SUPPORTS_PUBSUB = True\n\n    def __init__(\n        self,\n        conn: Optional[Union[str, RedisAsync, LazyClient]] = None,\n        namespace: str = DEFAULT_NAMESPACE,\n        serializer: Serializer = JsonSerializer(),\n    ) -&gt; None:\n        super().__init__(\n            namespace=namespace,\n            serializer=serializer,\n        )\n        self._conn = self._conn_parse(conn)\n\n    @staticmethod\n    def _conn_parse(\n        conn: Optional[Union[str, RedisAsync, LazyClient]]\n    ) -&gt; Union[RedisAsync, LazyClient]:\n        \"\"\"Parse the connection parameter to obtain an AsyncRedis or LazyClient instance.\n\n        Args:\n            conn (Optional[Union[str, AsyncRedis, LazyClient]]): The connection parameter.\n\n        Returns:\n            Union[AsyncRedis, LazyClient]: An `AsyncRedis` instance or a `LazyClient` wrapping one.\n\n        Raises:\n            ValueError: If the connection parameter is of an unsupported type.\n\n        \"\"\"\n        if isinstance(conn, LazyClient):\n            return conn\n        elif conn is None:\n            return RedisAsync(decode_responses=True)\n        elif isinstance(conn, RedisAsync):\n            return conn\n        elif isinstance(conn, str):\n            return RedisAsync.from_url(conn, decode_responses=True)\n        else:\n            raise ValueError(f\"Unsupported `conn` {conn}\")\n\n    @property\n    def conn(self) -&gt; RedisAsync:\n        \"\"\"Asynchronous Redis connection.\n\n        Returns:\n            AsyncRedis: The asynchronous Redis client instance.\n\n        \"\"\"\n        if isinstance(self._conn, LazyClient):\n            self._conn = self._conn.get()\n        return self._conn\n\n    def __repr__(self) -&gt; str:\n        return auto_repr(\n            self,\n            conn=self.conn,\n            namespace=self.namespace,\n            serializer=self.serializer,\n        )\n\n    def encode(self) -&gt; bytes:\n        data: dict[str, Any] = dict(\n            backend=self.__class__,\n            settings=gather_init_params(self, ignore=(\"conn\",)),\n        )\n        data[\"settings\"][\"conn\"] = dict(\n            connection_class=self.conn.connection_pool.connection_class,\n            max_connections=self.conn.connection_pool.max_connections,\n            connection_kwargs=self.conn.connection_pool.connection_kwargs,\n        )\n        return dill.dumps(data)\n\n    @classmethod\n    def from_settings(cls, settings: dict[str, Any]) -&gt; AsyncRedisBackend:\n        settings[\"conn\"] = RedisAsync(\n            connection_pool=AsyncConnectionPool(\n                connection_class=settings[\"conn\"][\"connection_class\"],\n                max_connections=settings[\"conn\"][\"max_connections\"],\n                **settings[\"conn\"][\"connection_kwargs\"],\n            )\n        )\n        return cls(**settings)\n\n    async def exists(self, name: str) -&gt; bool:\n        \"\"\"Check if a key exists in the Redis backend asynchronously.\n\n        Args:\n            name (str): The name of the key to check.\n\n        Returns:\n            bool: `True` if the key exists, `False` otherwise.\n\n        \"\"\"\n        return await self.conn.exists(self.full_name(name))\n\n    async def set(\n        self,\n        name: str,\n        value: Any,\n        nx: bool = False,\n        ttl: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"Set a value for a key in the Redis backend asynchronously.\n\n        Args:\n            name (str): The name of the key.\n            value (Any): The value to set.\n            nx (bool, optional): If `True`, only set the key if it does not already exist.\n            ttl (Optional[int], optional): Time to live for the key in milliseconds.\n\n        Raises:\n            KeyError: If `nx` is `True` and the key already exists.\n\n        \"\"\"\n        response = await self.conn.set(\n            self.full_name(name),\n            value=self.serializer.forward(value),\n            px=ttl,\n            nx=nx,\n            keepttl=ttl is None,\n        )\n        if nx and not response:\n            raise KeyError(f\"Name '{name}' already exists\")\n\n    async def get(\n        self,\n        name: str,\n        default: Optional[Union[Any, Type[Empty]]] = Empty,\n    ) -&gt; Any:\n        \"\"\"Get the value of a key from the Redis backend asynchronously.\n\n        Args:\n            name (str): The name of the key.\n            default (Optional[Union[Any, Type[Empty]]], optional): Default value if the key does not exist.\n\n        Returns:\n            Any: The value of the key.\n\n        Raises:\n            KeyError: If the key does not exist and no default is provided.\n\n        \"\"\"\n        return await self._get_engine(\n            lambda: self.conn.get(self.full_name(name)),\n            default=default,\n        )\n\n    async def delete(self, name: str, missing_ok: bool = False) -&gt; None:\n        \"\"\"Delete a key from the Redis backend asynchronously.\n\n        Args:\n            name (str): The name of the key to delete.\n            missing_ok (bool, optional): If `True`, do not raise an error if the key does not exist.\n\n        Raises:\n            KeyError: If the key does not exist and `missing_ok` is `False`.\n\n        \"\"\"\n        found = await self.conn.delete(self.full_name(name))\n        if not missing_ok and not found:\n            raise KeyError(f\"No name '{name}' found\")\n\n    async def pub(self, channel: str, value: Any) -&gt; None:\n        \"\"\"Publish a message to a Redis channel asynchronously.\n\n        Args:\n            channel (str): The name of the channel.\n            value (Any): The message to publish.\n\n        Returns:\n            None\n\n        \"\"\"\n        await self.conn.publish(\n            channel=channel,\n            message=self.serializer.forward(value),\n        )\n\n    async def sub(self, channel: str) -&gt; AsyncIterable[dict[str, Any]]:\n        \"\"\"Subscribe to a Redis channel and asynchronously yield messages.\n\n        Args:\n            channel (str): The name of the channel to subscribe to.\n\n        Yields:\n            dict[str, Any]: A dictionary representing the message data.\n\n        \"\"\"\n        pubsub = self.conn.pubsub()\n        await pubsub.subscribe(channel)\n        try:\n            async for message in pubsub.listen():\n                if message.get(\"type\") == \"message\" and message.get(\"data\"):\n                    yield parse_sub_data(message, serializer=self.serializer)\n        finally:\n            await pubsub.unsubscribe(channel)\n            await pubsub.close()\n\n    async def scan(self, pattern: Optional[str] = None) -&gt; AsyncIterable[str]:\n        \"\"\"Asynchronously scan the Redis backend for keys matching a pattern.\n\n        Args:\n            pattern (Optional[str], optional): The pattern to match keys against. Defaults to '*'.\n\n        Yields:\n            str: The names of matching keys without the namespace prefix.\n\n        \"\"\"\n        match = self.full_name(pattern or \"*\")\n        async for key in self.conn.scan_iter(match):\n            yield self.short_name(key)\n\n    async def priority_add(\n        self,\n        key: str,\n        unique_id: str,\n        priority: int | float,\n    ) -&gt; None:\n        \"\"\"Add an item to a priority-sorted set asynchronously.\n\n        Args:\n            key (str): The name of the sorted set.\n            unique_id (str): The item's unique identifier.\n            priority (int | float): The numeric priority score.\n\n        Returns:\n            None\n\n        \"\"\"\n        await self.conn.zadd(\n            self.full_name(key),\n            mapping={unique_id: priority},\n        )\n\n    async def priority_get(self, key: str) -&gt; Optional[str]:\n        \"\"\"Peek the highest-priority item in a sorted set asynchronously.\n\n        Args:\n            key (str): The name of the sorted set.\n\n        Returns:\n            item (str, optional): The ID of the highest-priority item, or None if empty.\n\n        \"\"\"\n        results: list[str] = await self.conn.zrange(\n            self.full_name(key),\n            start=0,\n            end=0,\n        )\n        return results[0] if results else None\n\n    async def priority_iter(self, key: str) -&gt; AsyncIterable[str]:\n        \"\"\"Iterate over all items in a priority-sorted set asynchronously.\n\n        Args:\n            key (str): The name of the sorted set.\n\n        Yields:\n            item (str): Member of the sorted set, in priority order.\n\n        \"\"\"\n        # ToDo: switch to this for better async:\n        #   async for item in self.conn.zscan_iter(self.full_name(key)):\n        #       yield item[0]  # item is a (member, score) tuple\n        for item in await self.conn.zrange(self.full_name(key), 0, -1):\n            yield item\n\n    async def priority_remove(self, key: str, unique_id: str) -&gt; None:\n        \"\"\"Remove an item from a priority-sorted set asynchronously.\n\n        Args:\n            key (str): The name of the sorted set.\n            unique_id (str): The ID of the item to remove.\n\n        Returns:\n            None\n\n        \"\"\"\n        await self.conn.zrem(\n            self.full_name(key),\n            unique_id,\n        )\n</code></pre> <code>conn</code> <code>property</code> <p>Asynchronous Redis connection.</p> <p>Returns:</p> Name Type Description <code>AsyncRedis</code> <code>Redis</code> <p>The asynchronous Redis client instance.</p> <code>delete(name, missing_ok=False)</code> <code>async</code> <p>Delete a key from the Redis backend asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the key to delete.</p> required <code>missing_ok</code> <code>bool</code> <p>If <code>True</code>, do not raise an error if the key does not exist.</p> <code>False</code> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the key does not exist and <code>missing_ok</code> is <code>False</code>.</p> Source code in <code>alsek/storage/backends/redis/asyncio.py</code> <pre><code>async def delete(self, name: str, missing_ok: bool = False) -&gt; None:\n    \"\"\"Delete a key from the Redis backend asynchronously.\n\n    Args:\n        name (str): The name of the key to delete.\n        missing_ok (bool, optional): If `True`, do not raise an error if the key does not exist.\n\n    Raises:\n        KeyError: If the key does not exist and `missing_ok` is `False`.\n\n    \"\"\"\n    found = await self.conn.delete(self.full_name(name))\n    if not missing_ok and not found:\n        raise KeyError(f\"No name '{name}' found\")\n</code></pre> <code>exists(name)</code> <code>async</code> <p>Check if a key exists in the Redis backend asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the key to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the key exists, <code>False</code> otherwise.</p> Source code in <code>alsek/storage/backends/redis/asyncio.py</code> <pre><code>async def exists(self, name: str) -&gt; bool:\n    \"\"\"Check if a key exists in the Redis backend asynchronously.\n\n    Args:\n        name (str): The name of the key to check.\n\n    Returns:\n        bool: `True` if the key exists, `False` otherwise.\n\n    \"\"\"\n    return await self.conn.exists(self.full_name(name))\n</code></pre> <code>get(name, default=Empty)</code> <code>async</code> <p>Get the value of a key from the Redis backend asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the key.</p> required <code>default</code> <code>Optional[Union[Any, Type[Empty]]]</code> <p>Default value if the key does not exist.</p> <code>Empty</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The value of the key.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the key does not exist and no default is provided.</p> Source code in <code>alsek/storage/backends/redis/asyncio.py</code> <pre><code>async def get(\n    self,\n    name: str,\n    default: Optional[Union[Any, Type[Empty]]] = Empty,\n) -&gt; Any:\n    \"\"\"Get the value of a key from the Redis backend asynchronously.\n\n    Args:\n        name (str): The name of the key.\n        default (Optional[Union[Any, Type[Empty]]], optional): Default value if the key does not exist.\n\n    Returns:\n        Any: The value of the key.\n\n    Raises:\n        KeyError: If the key does not exist and no default is provided.\n\n    \"\"\"\n    return await self._get_engine(\n        lambda: self.conn.get(self.full_name(name)),\n        default=default,\n    )\n</code></pre> <code>priority_add(key, unique_id, priority)</code> <code>async</code> <p>Add an item to a priority-sorted set asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the sorted set.</p> required <code>unique_id</code> <code>str</code> <p>The item's unique identifier.</p> required <code>priority</code> <code>int | float</code> <p>The numeric priority score.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/storage/backends/redis/asyncio.py</code> <pre><code>async def priority_add(\n    self,\n    key: str,\n    unique_id: str,\n    priority: int | float,\n) -&gt; None:\n    \"\"\"Add an item to a priority-sorted set asynchronously.\n\n    Args:\n        key (str): The name of the sorted set.\n        unique_id (str): The item's unique identifier.\n        priority (int | float): The numeric priority score.\n\n    Returns:\n        None\n\n    \"\"\"\n    await self.conn.zadd(\n        self.full_name(key),\n        mapping={unique_id: priority},\n    )\n</code></pre> <code>priority_get(key)</code> <code>async</code> <p>Peek the highest-priority item in a sorted set asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the sorted set.</p> required <p>Returns:</p> Name Type Description <code>item</code> <code>(str, optional)</code> <p>The ID of the highest-priority item, or None if empty.</p> Source code in <code>alsek/storage/backends/redis/asyncio.py</code> <pre><code>async def priority_get(self, key: str) -&gt; Optional[str]:\n    \"\"\"Peek the highest-priority item in a sorted set asynchronously.\n\n    Args:\n        key (str): The name of the sorted set.\n\n    Returns:\n        item (str, optional): The ID of the highest-priority item, or None if empty.\n\n    \"\"\"\n    results: list[str] = await self.conn.zrange(\n        self.full_name(key),\n        start=0,\n        end=0,\n    )\n    return results[0] if results else None\n</code></pre> <code>priority_iter(key)</code> <code>async</code> <p>Iterate over all items in a priority-sorted set asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the sorted set.</p> required <p>Yields:</p> Name Type Description <code>item</code> <code>str</code> <p>Member of the sorted set, in priority order.</p> Source code in <code>alsek/storage/backends/redis/asyncio.py</code> <pre><code>async def priority_iter(self, key: str) -&gt; AsyncIterable[str]:\n    \"\"\"Iterate over all items in a priority-sorted set asynchronously.\n\n    Args:\n        key (str): The name of the sorted set.\n\n    Yields:\n        item (str): Member of the sorted set, in priority order.\n\n    \"\"\"\n    # ToDo: switch to this for better async:\n    #   async for item in self.conn.zscan_iter(self.full_name(key)):\n    #       yield item[0]  # item is a (member, score) tuple\n    for item in await self.conn.zrange(self.full_name(key), 0, -1):\n        yield item\n</code></pre> <code>priority_remove(key, unique_id)</code> <code>async</code> <p>Remove an item from a priority-sorted set asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the sorted set.</p> required <code>unique_id</code> <code>str</code> <p>The ID of the item to remove.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/storage/backends/redis/asyncio.py</code> <pre><code>async def priority_remove(self, key: str, unique_id: str) -&gt; None:\n    \"\"\"Remove an item from a priority-sorted set asynchronously.\n\n    Args:\n        key (str): The name of the sorted set.\n        unique_id (str): The ID of the item to remove.\n\n    Returns:\n        None\n\n    \"\"\"\n    await self.conn.zrem(\n        self.full_name(key),\n        unique_id,\n    )\n</code></pre> <code>pub(channel, value)</code> <code>async</code> <p>Publish a message to a Redis channel asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>channel</code> <code>str</code> <p>The name of the channel.</p> required <code>value</code> <code>Any</code> <p>The message to publish.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/storage/backends/redis/asyncio.py</code> <pre><code>async def pub(self, channel: str, value: Any) -&gt; None:\n    \"\"\"Publish a message to a Redis channel asynchronously.\n\n    Args:\n        channel (str): The name of the channel.\n        value (Any): The message to publish.\n\n    Returns:\n        None\n\n    \"\"\"\n    await self.conn.publish(\n        channel=channel,\n        message=self.serializer.forward(value),\n    )\n</code></pre> <code>scan(pattern=None)</code> <code>async</code> <p>Asynchronously scan the Redis backend for keys matching a pattern.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>Optional[str]</code> <p>The pattern to match keys against. Defaults to '*'.</p> <code>None</code> <p>Yields:</p> Name Type Description <code>str</code> <code>AsyncIterable[str]</code> <p>The names of matching keys without the namespace prefix.</p> Source code in <code>alsek/storage/backends/redis/asyncio.py</code> <pre><code>async def scan(self, pattern: Optional[str] = None) -&gt; AsyncIterable[str]:\n    \"\"\"Asynchronously scan the Redis backend for keys matching a pattern.\n\n    Args:\n        pattern (Optional[str], optional): The pattern to match keys against. Defaults to '*'.\n\n    Yields:\n        str: The names of matching keys without the namespace prefix.\n\n    \"\"\"\n    match = self.full_name(pattern or \"*\")\n    async for key in self.conn.scan_iter(match):\n        yield self.short_name(key)\n</code></pre> <code>set(name, value, nx=False, ttl=None)</code> <code>async</code> <p>Set a value for a key in the Redis backend asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the key.</p> required <code>value</code> <code>Any</code> <p>The value to set.</p> required <code>nx</code> <code>bool</code> <p>If <code>True</code>, only set the key if it does not already exist.</p> <code>False</code> <code>ttl</code> <code>Optional[int]</code> <p>Time to live for the key in milliseconds.</p> <code>None</code> <p>Raises:</p> Type Description <code>KeyError</code> <p>If <code>nx</code> is <code>True</code> and the key already exists.</p> Source code in <code>alsek/storage/backends/redis/asyncio.py</code> <pre><code>async def set(\n    self,\n    name: str,\n    value: Any,\n    nx: bool = False,\n    ttl: Optional[int] = None,\n) -&gt; None:\n    \"\"\"Set a value for a key in the Redis backend asynchronously.\n\n    Args:\n        name (str): The name of the key.\n        value (Any): The value to set.\n        nx (bool, optional): If `True`, only set the key if it does not already exist.\n        ttl (Optional[int], optional): Time to live for the key in milliseconds.\n\n    Raises:\n        KeyError: If `nx` is `True` and the key already exists.\n\n    \"\"\"\n    response = await self.conn.set(\n        self.full_name(name),\n        value=self.serializer.forward(value),\n        px=ttl,\n        nx=nx,\n        keepttl=ttl is None,\n    )\n    if nx and not response:\n        raise KeyError(f\"Name '{name}' already exists\")\n</code></pre> <code>sub(channel)</code> <code>async</code> <p>Subscribe to a Redis channel and asynchronously yield messages.</p> <p>Parameters:</p> Name Type Description Default <code>channel</code> <code>str</code> <p>The name of the channel to subscribe to.</p> required <p>Yields:</p> Type Description <code>AsyncIterable[dict[str, Any]]</code> <p>dict[str, Any]: A dictionary representing the message data.</p> Source code in <code>alsek/storage/backends/redis/asyncio.py</code> <pre><code>async def sub(self, channel: str) -&gt; AsyncIterable[dict[str, Any]]:\n    \"\"\"Subscribe to a Redis channel and asynchronously yield messages.\n\n    Args:\n        channel (str): The name of the channel to subscribe to.\n\n    Yields:\n        dict[str, Any]: A dictionary representing the message data.\n\n    \"\"\"\n    pubsub = self.conn.pubsub()\n    await pubsub.subscribe(channel)\n    try:\n        async for message in pubsub.listen():\n            if message.get(\"type\") == \"message\" and message.get(\"data\"):\n                yield parse_sub_data(message, serializer=self.serializer)\n    finally:\n        await pubsub.unsubscribe(channel)\n        await pubsub.close()\n</code></pre>"},{"location":"reference/#alsek.storage.backends.redis.standard","title":"<code>standard</code>","text":"<p>Redis Backend</p> <code>RedisBackend</code> <p>               Bases: <code>Backend</code></p> <p>Redis Backend.</p> <p>Backend powered by Redis.</p> <p>Parameters:</p> Name Type Description Default <code>conn</code> <code>(str, Redis, LazyClient)</code> <p>a connection url, <code>Redis()</code> object or <code>LazyClient</code>.</p> <code>None</code> <code>namespace</code> <code>str</code> <p>prefix to use when inserting names in the backend</p> <code>DEFAULT_NAMESPACE</code> <code>serializer</code> <code>Serializer</code> <p>tool for encoding and decoding values written into the backend.</p> <code>JsonSerializer()</code> Warning <ul> <li>If <code>conn</code> is a <code>Redis()</code> object, <code>decode_responses</code>   is expected to be set to <code>True</code>.</li> </ul> Source code in <code>alsek/storage/backends/redis/standard.py</code> <pre><code>class RedisBackend(Backend):\n    \"\"\"Redis Backend.\n\n    Backend powered by Redis.\n\n    Args:\n        conn (str, Redis, LazyClient, optional): a connection url, ``Redis()`` object\n            or ``LazyClient``.\n        namespace (str): prefix to use when inserting\n            names in the backend\n        serializer (Serializer): tool for encoding and decoding\n            values written into the backend.\n\n    Warning:\n        * If ``conn`` is a ``Redis()`` object, ``decode_responses``\n          is expected to be set to ``True``.\n\n    \"\"\"\n\n    SUPPORTS_PUBSUB: bool = True\n\n    def __init__(\n        self,\n        conn: Optional[Union[str, Redis, LazyClient]] = None,\n        namespace: str = DEFAULT_NAMESPACE,\n        serializer: Serializer = JsonSerializer(),\n    ) -&gt; None:\n        super().__init__(namespace, serializer=serializer)\n        self._conn = self._conn_parse(conn)\n\n    @staticmethod\n    def _conn_parse(\n        conn: Optional[Union[str, Redis, LazyClient]]\n    ) -&gt; Union[Redis, LazyClient]:\n        if isinstance(conn, LazyClient):\n            return conn\n\n        if conn is None:\n            return Redis(decode_responses=True)\n        elif isinstance(conn, Redis):\n            return conn\n        elif isinstance(conn, str):\n            return Redis.from_url(conn, decode_responses=True)\n        else:\n            raise ValueError(f\"Unsupported `conn` {conn}\")\n\n    @property\n    def conn(self) -&gt; Redis:\n        \"\"\"Connection to the backend.\"\"\"\n        if isinstance(self._conn, LazyClient):\n            self._conn = self._conn.get()\n        return cast(Redis, self._conn)\n\n    def __repr__(self) -&gt; str:\n        return auto_repr(\n            self,\n            conn=self.conn,\n            namespace=self.namespace,\n            serializer=self.serializer,\n        )\n\n    def encode(self) -&gt; bytes:\n        data: dict[str, Any] = dict(\n            backend=self.__class__,\n            settings=gather_init_params(self, ignore=(\"conn\",)),\n        )\n        data[\"settings\"][\"conn\"] = dict(\n            connection_class=self.conn.connection_pool.connection_class,\n            max_connections=self.conn.connection_pool.max_connections,\n            connection_kwargs=self.conn.connection_pool.connection_kwargs,\n        )\n        return cast(bytes, dill.dumps(data))\n\n    @classmethod\n    def from_settings(cls, settings: dict[str, Any]) -&gt; RedisBackend:\n        settings[\"conn\"] = Redis(\n            connection_pool=ConnectionPool(\n                connection_class=settings[\"conn\"][\"connection_class\"],\n                max_connections=settings[\"conn\"][\"max_connections\"],\n                **settings[\"conn\"][\"connection_kwargs\"],\n            )\n        )\n        return cls(**settings)\n\n    def exists(self, name: str) -&gt; bool:\n        \"\"\"Check if ``name`` exists in the Redis backend.\n\n        Args:\n            name (str): name of the item\n\n        Returns:\n            bool\n\n        \"\"\"\n        return bool(self.conn.exists(self.full_name(name)))\n\n    def set(\n        self,\n        name: str,\n        value: Any,\n        nx: bool = False,\n        ttl: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"Set ``name`` to ``value`` in the Redis backend.\n\n        Args:\n            name (str): name of the item\n            value (Any): value to set for ``name``\n            nx (bool): if ``True`` the item must not exist prior to being set\n            ttl (int, optional): time to live for the entry in milliseconds\n\n        Returns:\n            None\n\n        Raises:\n            KeyError: if ``nx`` is ``True`` and ``name`` already exists\n\n        \"\"\"\n        response = self.conn.set(\n            self.full_name(name),\n            value=self.serializer.forward(value),\n            px=ttl,\n            nx=nx,\n            keepttl=ttl is None,  # type: ignore\n        )\n        if nx and response is None:\n            raise KeyError(f\"Name '{name}' already exists\")\n\n    def get(self, name: str, default: Optional[Union[Any, Type[Empty]]] = None) -&gt; Any:\n        \"\"\"Get ``name`` from the Redis backend.\n\n        Args:\n            name (str): name of the item\n            default (Any, Type[Empty], optional): default value for ``name``\n\n        Returns:\n            Any\n\n        \"\"\"\n        return self._get_engine(\n            lambda: self.conn.__getitem__(self.full_name(name)),\n            default=default,\n        )\n\n    def delete(self, name: str, missing_ok: bool = False) -&gt; None:\n        \"\"\"Delete a ``name`` from the Redis backend.\n\n        Args:\n            name (str): name of the item\n            missing_ok (bool): if ``True``, do not raise for missing\n\n        Returns:\n            None\n\n        Raises:\n            KeyError: if ``missing_ok`` is ``False`` and ``name`` is not found.\n\n        \"\"\"\n        found = self.conn.delete(self.full_name(name))\n        if not missing_ok and not found:\n            raise KeyError(f\"No name '{name}' found\")\n\n    def priority_add(self, key: str, unique_id: str, priority: int | float) -&gt; None:\n        \"\"\"Add an item to a priority-sorted set.\n\n        Args:\n            key (str): The name of the sorted set.\n            unique_id (str): The item's (Message's) unique identifier\n            priority (float): The numeric priority score (decide if lower or higher means higher priority).\n\n        Returns:\n            None\n\n        \"\"\"\n        self.conn.zadd(\n            self.full_name(key),\n            mapping={unique_id: priority},\n        )\n\n    def priority_get(self, key: str) -&gt; Optional[str]:\n        \"\"\"Get (peek) the highest-priority item without removing it.\n\n        Args:\n            key (str): The name of the sorted set.\n\n        Returns:\n            item (str, optional): The member with the highest priority, or None if empty.\n\n        \"\"\"\n        results: list[str] = self.conn.zrange(\n            self.full_name(key),\n            start=0,\n            end=0,\n        )\n        return results[0] if results else None\n\n    def priority_iter(self, key: str) -&gt; Iterable[str]:\n        \"\"\"Iterate over the items in a priority-sorted set.\n\n        Args:\n            key (str): The name of the sorted set.\n\n        Returns:\n            priority (Iterable[str]): An iterable of members in the sorted set, sorted by priority.\n\n        \"\"\"\n        yield from self.conn.zrange(self.full_name(key), 0, -1)\n\n    def priority_remove(self, key: str, unique_id: str) -&gt; None:\n        \"\"\"Remove an item from a priority-sorted set.\n\n        Args:\n            key (str): The name of the sorted set.\n            unique_id (str): The item's (Message's) unique identifier\n\n        Returns:\n            None\n\n        \"\"\"\n        self.conn.zrem(\n            self.full_name(key),\n            unique_id,\n        )\n\n    def pub(self, channel: str, value: Any) -&gt; None:\n        self.conn.publish(\n            channel=channel,\n            message=self.serializer.forward(value),\n        )\n\n    def sub(self, channel: str) -&gt; Iterable[str | dict[str, Any]]:\n        pubsub = self.conn.pubsub()\n        pubsub.subscribe(channel)\n        try:\n            for message in pubsub.listen():\n                if message.get(\"type\") == \"message\" and message.get(\"data\"):\n                    yield parse_sub_data(message, serializer=self.serializer)\n        finally:\n            pubsub.unsubscribe(channel)\n            pubsub.close()\n\n    def scan(self, pattern: Optional[str] = None) -&gt; Iterable[str]:\n        \"\"\"Scan the backend for matching names.\n\n        Args:\n            pattern (str): pattern to match against\n\n        Returns:\n            names_stream (Iterable[str]): a stream of matching name\n\n        \"\"\"\n        match = self.full_name(pattern or \"*\")\n        yield from map(self.short_name, self.conn.scan_iter(match))\n</code></pre> <code>conn</code> <code>property</code> <p>Connection to the backend.</p> <code>delete(name, missing_ok=False)</code> <p>Delete a <code>name</code> from the Redis backend.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the item</p> required <code>missing_ok</code> <code>bool</code> <p>if <code>True</code>, do not raise for missing</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if <code>missing_ok</code> is <code>False</code> and <code>name</code> is not found.</p> Source code in <code>alsek/storage/backends/redis/standard.py</code> <pre><code>def delete(self, name: str, missing_ok: bool = False) -&gt; None:\n    \"\"\"Delete a ``name`` from the Redis backend.\n\n    Args:\n        name (str): name of the item\n        missing_ok (bool): if ``True``, do not raise for missing\n\n    Returns:\n        None\n\n    Raises:\n        KeyError: if ``missing_ok`` is ``False`` and ``name`` is not found.\n\n    \"\"\"\n    found = self.conn.delete(self.full_name(name))\n    if not missing_ok and not found:\n        raise KeyError(f\"No name '{name}' found\")\n</code></pre> <code>exists(name)</code> <p>Check if <code>name</code> exists in the Redis backend.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the item</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>alsek/storage/backends/redis/standard.py</code> <pre><code>def exists(self, name: str) -&gt; bool:\n    \"\"\"Check if ``name`` exists in the Redis backend.\n\n    Args:\n        name (str): name of the item\n\n    Returns:\n        bool\n\n    \"\"\"\n    return bool(self.conn.exists(self.full_name(name)))\n</code></pre> <code>get(name, default=None)</code> <p>Get <code>name</code> from the Redis backend.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the item</p> required <code>default</code> <code>(Any, Type[Empty])</code> <p>default value for <code>name</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Any</p> Source code in <code>alsek/storage/backends/redis/standard.py</code> <pre><code>def get(self, name: str, default: Optional[Union[Any, Type[Empty]]] = None) -&gt; Any:\n    \"\"\"Get ``name`` from the Redis backend.\n\n    Args:\n        name (str): name of the item\n        default (Any, Type[Empty], optional): default value for ``name``\n\n    Returns:\n        Any\n\n    \"\"\"\n    return self._get_engine(\n        lambda: self.conn.__getitem__(self.full_name(name)),\n        default=default,\n    )\n</code></pre> <code>priority_add(key, unique_id, priority)</code> <p>Add an item to a priority-sorted set.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the sorted set.</p> required <code>unique_id</code> <code>str</code> <p>The item's (Message's) unique identifier</p> required <code>priority</code> <code>float</code> <p>The numeric priority score (decide if lower or higher means higher priority).</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/storage/backends/redis/standard.py</code> <pre><code>def priority_add(self, key: str, unique_id: str, priority: int | float) -&gt; None:\n    \"\"\"Add an item to a priority-sorted set.\n\n    Args:\n        key (str): The name of the sorted set.\n        unique_id (str): The item's (Message's) unique identifier\n        priority (float): The numeric priority score (decide if lower or higher means higher priority).\n\n    Returns:\n        None\n\n    \"\"\"\n    self.conn.zadd(\n        self.full_name(key),\n        mapping={unique_id: priority},\n    )\n</code></pre> <code>priority_get(key)</code> <p>Get (peek) the highest-priority item without removing it.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the sorted set.</p> required <p>Returns:</p> Name Type Description <code>item</code> <code>(str, optional)</code> <p>The member with the highest priority, or None if empty.</p> Source code in <code>alsek/storage/backends/redis/standard.py</code> <pre><code>def priority_get(self, key: str) -&gt; Optional[str]:\n    \"\"\"Get (peek) the highest-priority item without removing it.\n\n    Args:\n        key (str): The name of the sorted set.\n\n    Returns:\n        item (str, optional): The member with the highest priority, or None if empty.\n\n    \"\"\"\n    results: list[str] = self.conn.zrange(\n        self.full_name(key),\n        start=0,\n        end=0,\n    )\n    return results[0] if results else None\n</code></pre> <code>priority_iter(key)</code> <p>Iterate over the items in a priority-sorted set.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the sorted set.</p> required <p>Returns:</p> Name Type Description <code>priority</code> <code>Iterable[str]</code> <p>An iterable of members in the sorted set, sorted by priority.</p> Source code in <code>alsek/storage/backends/redis/standard.py</code> <pre><code>def priority_iter(self, key: str) -&gt; Iterable[str]:\n    \"\"\"Iterate over the items in a priority-sorted set.\n\n    Args:\n        key (str): The name of the sorted set.\n\n    Returns:\n        priority (Iterable[str]): An iterable of members in the sorted set, sorted by priority.\n\n    \"\"\"\n    yield from self.conn.zrange(self.full_name(key), 0, -1)\n</code></pre> <code>priority_remove(key, unique_id)</code> <p>Remove an item from a priority-sorted set.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the sorted set.</p> required <code>unique_id</code> <code>str</code> <p>The item's (Message's) unique identifier</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/storage/backends/redis/standard.py</code> <pre><code>def priority_remove(self, key: str, unique_id: str) -&gt; None:\n    \"\"\"Remove an item from a priority-sorted set.\n\n    Args:\n        key (str): The name of the sorted set.\n        unique_id (str): The item's (Message's) unique identifier\n\n    Returns:\n        None\n\n    \"\"\"\n    self.conn.zrem(\n        self.full_name(key),\n        unique_id,\n    )\n</code></pre> <code>scan(pattern=None)</code> <p>Scan the backend for matching names.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>pattern to match against</p> <code>None</code> <p>Returns:</p> Name Type Description <code>names_stream</code> <code>Iterable[str]</code> <p>a stream of matching name</p> Source code in <code>alsek/storage/backends/redis/standard.py</code> <pre><code>def scan(self, pattern: Optional[str] = None) -&gt; Iterable[str]:\n    \"\"\"Scan the backend for matching names.\n\n    Args:\n        pattern (str): pattern to match against\n\n    Returns:\n        names_stream (Iterable[str]): a stream of matching name\n\n    \"\"\"\n    match = self.full_name(pattern or \"*\")\n    yield from map(self.short_name, self.conn.scan_iter(match))\n</code></pre> <code>set(name, value, nx=False, ttl=None)</code> <p>Set <code>name</code> to <code>value</code> in the Redis backend.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the item</p> required <code>value</code> <code>Any</code> <p>value to set for <code>name</code></p> required <code>nx</code> <code>bool</code> <p>if <code>True</code> the item must not exist prior to being set</p> <code>False</code> <code>ttl</code> <code>int</code> <p>time to live for the entry in milliseconds</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if <code>nx</code> is <code>True</code> and <code>name</code> already exists</p> Source code in <code>alsek/storage/backends/redis/standard.py</code> <pre><code>def set(\n    self,\n    name: str,\n    value: Any,\n    nx: bool = False,\n    ttl: Optional[int] = None,\n) -&gt; None:\n    \"\"\"Set ``name`` to ``value`` in the Redis backend.\n\n    Args:\n        name (str): name of the item\n        value (Any): value to set for ``name``\n        nx (bool): if ``True`` the item must not exist prior to being set\n        ttl (int, optional): time to live for the entry in milliseconds\n\n    Returns:\n        None\n\n    Raises:\n        KeyError: if ``nx`` is ``True`` and ``name`` already exists\n\n    \"\"\"\n    response = self.conn.set(\n        self.full_name(name),\n        value=self.serializer.forward(value),\n        px=ttl,\n        nx=nx,\n        keepttl=ttl is None,  # type: ignore\n    )\n    if nx and response is None:\n        raise KeyError(f\"Name '{name}' already exists\")\n</code></pre>"},{"location":"reference/#alsek.storage.result","title":"<code>result</code>","text":"<p>Result Storage</p>"},{"location":"reference/#alsek.storage.result.ResultStore","title":"<code>ResultStore</code>","text":"<p>Alsek Result Store.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>Backend</code> <p>backend for data storage</p> required Warning <ul> <li>In order for a result to be stored, it must be   serializable by the <code>serializer</code> used by <code>backend</code>.</li> </ul> Source code in <code>alsek/storage/result.py</code> <pre><code>class ResultStore:\n    \"\"\"Alsek Result Store.\n\n    Args:\n        backend (Backend): backend for data storage\n\n    Warning:\n        * In order for a result to be stored, it must be\n          serializable by the ``serializer`` used by ``backend``.\n\n    \"\"\"\n\n    def __init__(self, backend: Backend) -&gt; None:\n        self.backend = backend\n\n    def serialize(self) -&gt; dict[str, Any]:\n        return {\n            \"backend\": self.backend.encode(),\n        }\n\n    @classmethod\n    def deserialize(cls, data: dict[str, Any]) -&gt; ResultStore:\n        backend_data = dill.loads(data[\"backend\"])\n        backend = backend_data[\"backend\"].from_settings(backend_data[\"settings\"])\n        return cls(\n            backend=backend,\n        )\n\n    @staticmethod\n    def _get_stable_prefix(message: Message) -&gt; str:\n        \"\"\"Get a prefix that does not change based on\n        whether the message has a progenitor.\"\"\"\n        return f\"results:{message.progenitor_uuid if message.progenitor_uuid else message.uuid}\"\n\n    @staticmethod\n    def get_storage_name(message: Message) -&gt; str:\n        \"\"\"Get the name for ``message`` in the backend.\n\n        Args:\n            message (Message): an Alsek message\n\n        Returns:\n            name (str): message-specific name\n\n        \"\"\"\n        if message.uuid is None:\n            raise ValueError(\"Message does not have a uuid\")\n\n        if message.progenitor_uuid:\n            return f\"results:{message.progenitor_uuid}:descendants:{message.uuid}\"\n        else:\n            return f\"results:{message.uuid}\"\n\n    def _get_all_storage_names(self, message: Message, descendants: bool) -&gt; list[str]:\n        if descendants:\n            if message.descendant_uuids:\n                descendant_names = [\n                    self.get_storage_name(\n                        Message(message.task_name, uuid=u, progenitor_uuid=message.uuid)\n                    )\n                    for u in message.descendant_uuids\n                ]\n                return [*descendant_names, self.get_storage_name(message)]\n            else:\n                return sorted(\n                    self.backend.scan(f\"{self._get_stable_prefix(message)}*\"),\n                    key=lambda i: 1 if i == message.uuid else 0,\n                )\n        else:\n            return [self.get_storage_name(message)]\n\n    @staticmethod\n    def _extract_uuid(storage_name: str) -&gt; str:\n        return storage_name.rsplit(\":\", 1)[-1]\n\n    def exists(self, message: Message, descendants: bool = False) -&gt; bool:\n        \"\"\"Whether data for ``message`` exists in the store.\n\n        Args:\n            message (Message): an Alsek message\n            descendants (bool): if ``True``, this method will return ``True``\n                iff all of the descendants of ``message`` also exist.\n\n        Returns:\n            bool\n\n        \"\"\"\n        names = self._get_all_storage_names(message, descendants=descendants)\n        return all(self.backend.exists(n) for n in names)\n\n    def set(self, message: Message, result: Any, nx: bool = True) -&gt; None:\n        \"\"\"Store a ``result`` for ``message``.\n\n        Args:\n            message (Message): an Alsek message.\n            result (Any): the result to persist\n            nx (bool): if ``True`` the item must not exist prior to being set\n\n        Returns:\n            None\n\n        \"\"\"\n        self.backend.set(\n            self.get_storage_name(message),\n            value={\"result\": result, \"timestamp\": utcnow_timestamp_ms()},\n            nx=nx,\n            ttl=message.result_ttl,\n        )\n\n    def _get_engine(self, names: Iterable[str], with_metadata: bool) -&gt; list[Any]:\n        def bundle_data(n: str) -&gt; dict[str, Any]:\n            data: dict[str, Any] = self.backend.get(n)\n            if with_metadata:\n                data[\"uuid\"] = self._extract_uuid(n)\n            return data\n\n        results = sorted(\n            [bundle_data(n) for n in names],\n            key=lambda d: d[\"timestamp\"],  # type: ignore\n        )\n        return results if with_metadata else [r[\"result\"] for r in results]\n\n    def get(\n        self,\n        message: Message,\n        timeout: int = 0,\n        keep: bool = False,\n        with_metadata: bool = False,\n        descendants: bool = False,\n    ) -&gt; Union[Any, list[Any]]:\n        \"\"\"Get the result for ``message``.\n\n        Args:\n            message (Message): an Alsek message.\n            timeout (int): amount of time (in milliseconds) to wait\n                for the result to become available\n            keep (bool): whether to keep the result after fetching it.\n                Defaults to ``False`` to conserve storage space.\n            with_metadata (bool): if ``True`` return results of the form\n                ``{\"result\": &lt;result&gt;, \"uuid\": str, \"timestamp\": int}``, where\n                \"result\" is the result persisted to the backend, \"uuid\" if the uuid\n                 of the message associated with the result and \"timestamp\" is the\n                time at which the result was written to the backend.\n            descendants (bool): if ``True`` also fetch results for descendants.\n\n        Returns:\n            result (Any, list[Any]): the stored result. If ``descendants``\n                is ``True`` a list of results will be returned.\n\n        Raises:\n            KeyError: if results are not available for ``message``\n            TimeoutError: if results are not available for ``message``\n                following ``timeout``.\n\n        Notes:\n            * The order of results when ``descendants=True`` is determined\n              by the time at which the data was written to the backend.\n\n        Warning:\n            * If a message has a projenitor, the ``projenitor_uuid`` field in the\n              ``message`` must be set.\n\n        Examples:\n            &gt;&gt;&gt; from alsek import Message\n            &gt;&gt;&gt; from alsek.storage.backends.redis.standard import RedisBackend\n            &gt;&gt;&gt; from alsek.storage.result import ResultStore\n\n            &gt;&gt;&gt; backend = RedisBackend()\n            &gt;&gt;&gt; result_store = ResultStore(backend)\n\n            &gt;&gt;&gt; result_store.get(Message(uuid=\"...\"))\n\n        \"\"\"\n        if not self.exists(message, descendants=descendants):\n            if timeout:\n                waiter(\n                    lambda: self.exists(message, descendants=descendants),\n                    timeout=timeout,\n                    timeout_msg=f\"Timeout waiting on result for {message.summary}\",\n                    sleep_interval=_GET_RESULT_WAIT_SLEEP_INTERVAL,\n                )\n            else:\n                raise KeyError(f\"No results for {message.uuid}\")\n\n        names = self._get_all_storage_names(message, descendants=descendants)\n        results = self._get_engine(names, with_metadata=with_metadata)\n        if not keep:\n            for n in names:\n                self.backend.delete(n)\n\n        return results if descendants else results[0]\n\n    def delete(\n        self,\n        message: Message,\n        descendants: bool = True,\n        missing_ok: bool = False,\n    ) -&gt; int:\n        \"\"\"Delete any data for ``message`` from the backend.\n\n        Args:\n            message (Message): an Alsek message.\n            descendants (bool): if ``True`` also delete results for descendants.\n            missing_ok (bool): if ``True``, do not raise for missing\n\n        Returns:\n            count (int): number of results deleted\n\n        \"\"\"\n        count: int = 0\n        for name in self._get_all_storage_names(message, descendants=descendants):\n            self.backend.delete(name, missing_ok=missing_ok)\n            count += 1\n        return count\n</code></pre>"},{"location":"reference/#alsek.storage.result.ResultStore.delete","title":"<code>delete(message, descendants=True, missing_ok=False)</code>","text":"<p>Delete any data for <code>message</code> from the backend.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message.</p> required <code>descendants</code> <code>bool</code> <p>if <code>True</code> also delete results for descendants.</p> <code>True</code> <code>missing_ok</code> <code>bool</code> <p>if <code>True</code>, do not raise for missing</p> <code>False</code> <p>Returns:</p> Name Type Description <code>count</code> <code>int</code> <p>number of results deleted</p> Source code in <code>alsek/storage/result.py</code> <pre><code>def delete(\n    self,\n    message: Message,\n    descendants: bool = True,\n    missing_ok: bool = False,\n) -&gt; int:\n    \"\"\"Delete any data for ``message`` from the backend.\n\n    Args:\n        message (Message): an Alsek message.\n        descendants (bool): if ``True`` also delete results for descendants.\n        missing_ok (bool): if ``True``, do not raise for missing\n\n    Returns:\n        count (int): number of results deleted\n\n    \"\"\"\n    count: int = 0\n    for name in self._get_all_storage_names(message, descendants=descendants):\n        self.backend.delete(name, missing_ok=missing_ok)\n        count += 1\n    return count\n</code></pre>"},{"location":"reference/#alsek.storage.result.ResultStore.exists","title":"<code>exists(message, descendants=False)</code>","text":"<p>Whether data for <code>message</code> exists in the store.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <code>descendants</code> <code>bool</code> <p>if <code>True</code>, this method will return <code>True</code> iff all of the descendants of <code>message</code> also exist.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>alsek/storage/result.py</code> <pre><code>def exists(self, message: Message, descendants: bool = False) -&gt; bool:\n    \"\"\"Whether data for ``message`` exists in the store.\n\n    Args:\n        message (Message): an Alsek message\n        descendants (bool): if ``True``, this method will return ``True``\n            iff all of the descendants of ``message`` also exist.\n\n    Returns:\n        bool\n\n    \"\"\"\n    names = self._get_all_storage_names(message, descendants=descendants)\n    return all(self.backend.exists(n) for n in names)\n</code></pre>"},{"location":"reference/#alsek.storage.result.ResultStore.get","title":"<code>get(message, timeout=0, keep=False, with_metadata=False, descendants=False)</code>","text":"<p>Get the result for <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message.</p> required <code>timeout</code> <code>int</code> <p>amount of time (in milliseconds) to wait for the result to become available</p> <code>0</code> <code>keep</code> <code>bool</code> <p>whether to keep the result after fetching it. Defaults to <code>False</code> to conserve storage space.</p> <code>False</code> <code>with_metadata</code> <code>bool</code> <p>if <code>True</code> return results of the form <code>{\"result\": &lt;result&gt;, \"uuid\": str, \"timestamp\": int}</code>, where \"result\" is the result persisted to the backend, \"uuid\" if the uuid  of the message associated with the result and \"timestamp\" is the time at which the result was written to the backend.</p> <code>False</code> <code>descendants</code> <code>bool</code> <p>if <code>True</code> also fetch results for descendants.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>result</code> <code>(Any, list[Any])</code> <p>the stored result. If <code>descendants</code> is <code>True</code> a list of results will be returned.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if results are not available for <code>message</code></p> <code>TimeoutError</code> <p>if results are not available for <code>message</code> following <code>timeout</code>.</p> Notes <ul> <li>The order of results when <code>descendants=True</code> is determined   by the time at which the data was written to the backend.</li> </ul> Warning <ul> <li>If a message has a projenitor, the <code>projenitor_uuid</code> field in the   <code>message</code> must be set.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from alsek import Message\n&gt;&gt;&gt; from alsek.storage.backends.redis.standard import RedisBackend\n&gt;&gt;&gt; from alsek.storage.result import ResultStore\n</code></pre> <pre><code>&gt;&gt;&gt; backend = RedisBackend()\n&gt;&gt;&gt; result_store = ResultStore(backend)\n</code></pre> <pre><code>&gt;&gt;&gt; result_store.get(Message(uuid=\"...\"))\n</code></pre> Source code in <code>alsek/storage/result.py</code> <pre><code>def get(\n    self,\n    message: Message,\n    timeout: int = 0,\n    keep: bool = False,\n    with_metadata: bool = False,\n    descendants: bool = False,\n) -&gt; Union[Any, list[Any]]:\n    \"\"\"Get the result for ``message``.\n\n    Args:\n        message (Message): an Alsek message.\n        timeout (int): amount of time (in milliseconds) to wait\n            for the result to become available\n        keep (bool): whether to keep the result after fetching it.\n            Defaults to ``False`` to conserve storage space.\n        with_metadata (bool): if ``True`` return results of the form\n            ``{\"result\": &lt;result&gt;, \"uuid\": str, \"timestamp\": int}``, where\n            \"result\" is the result persisted to the backend, \"uuid\" if the uuid\n             of the message associated with the result and \"timestamp\" is the\n            time at which the result was written to the backend.\n        descendants (bool): if ``True`` also fetch results for descendants.\n\n    Returns:\n        result (Any, list[Any]): the stored result. If ``descendants``\n            is ``True`` a list of results will be returned.\n\n    Raises:\n        KeyError: if results are not available for ``message``\n        TimeoutError: if results are not available for ``message``\n            following ``timeout``.\n\n    Notes:\n        * The order of results when ``descendants=True`` is determined\n          by the time at which the data was written to the backend.\n\n    Warning:\n        * If a message has a projenitor, the ``projenitor_uuid`` field in the\n          ``message`` must be set.\n\n    Examples:\n        &gt;&gt;&gt; from alsek import Message\n        &gt;&gt;&gt; from alsek.storage.backends.redis.standard import RedisBackend\n        &gt;&gt;&gt; from alsek.storage.result import ResultStore\n\n        &gt;&gt;&gt; backend = RedisBackend()\n        &gt;&gt;&gt; result_store = ResultStore(backend)\n\n        &gt;&gt;&gt; result_store.get(Message(uuid=\"...\"))\n\n    \"\"\"\n    if not self.exists(message, descendants=descendants):\n        if timeout:\n            waiter(\n                lambda: self.exists(message, descendants=descendants),\n                timeout=timeout,\n                timeout_msg=f\"Timeout waiting on result for {message.summary}\",\n                sleep_interval=_GET_RESULT_WAIT_SLEEP_INTERVAL,\n            )\n        else:\n            raise KeyError(f\"No results for {message.uuid}\")\n\n    names = self._get_all_storage_names(message, descendants=descendants)\n    results = self._get_engine(names, with_metadata=with_metadata)\n    if not keep:\n        for n in names:\n            self.backend.delete(n)\n\n    return results if descendants else results[0]\n</code></pre>"},{"location":"reference/#alsek.storage.result.ResultStore.get_storage_name","title":"<code>get_storage_name(message)</code>  <code>staticmethod</code>","text":"<p>Get the name for <code>message</code> in the backend.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>name</code> <code>str</code> <p>message-specific name</p> Source code in <code>alsek/storage/result.py</code> <pre><code>@staticmethod\ndef get_storage_name(message: Message) -&gt; str:\n    \"\"\"Get the name for ``message`` in the backend.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        name (str): message-specific name\n\n    \"\"\"\n    if message.uuid is None:\n        raise ValueError(\"Message does not have a uuid\")\n\n    if message.progenitor_uuid:\n        return f\"results:{message.progenitor_uuid}:descendants:{message.uuid}\"\n    else:\n        return f\"results:{message.uuid}\"\n</code></pre>"},{"location":"reference/#alsek.storage.result.ResultStore.set","title":"<code>set(message, result, nx=True)</code>","text":"<p>Store a <code>result</code> for <code>message</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message.</p> required <code>result</code> <code>Any</code> <p>the result to persist</p> required <code>nx</code> <code>bool</code> <p>if <code>True</code> the item must not exist prior to being set</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/storage/result.py</code> <pre><code>def set(self, message: Message, result: Any, nx: bool = True) -&gt; None:\n    \"\"\"Store a ``result`` for ``message``.\n\n    Args:\n        message (Message): an Alsek message.\n        result (Any): the result to persist\n        nx (bool): if ``True`` the item must not exist prior to being set\n\n    Returns:\n        None\n\n    \"\"\"\n    self.backend.set(\n        self.get_storage_name(message),\n        value={\"result\": result, \"timestamp\": utcnow_timestamp_ms()},\n        nx=nx,\n        ttl=message.result_ttl,\n    )\n</code></pre>"},{"location":"reference/#alsek.storage.serialization","title":"<code>serialization</code>","text":"<p>Serialization</p>"},{"location":"reference/#alsek.storage.serialization.BinarySerializer","title":"<code>BinarySerializer</code>","text":"<p>               Bases: <code>Serializer</code></p> <p>Binary serialization.</p> Source code in <code>alsek/storage/serialization.py</code> <pre><code>class BinarySerializer(Serializer):\n    \"\"\"Binary serialization.\"\"\"\n\n    @staticmethod\n    def forward(obj: Any) -&gt; Any:\n        \"\"\"Encode an object.\n\n        Args:\n            obj (Any): an object to encode\n\n        Returns:\n            encoded (Any): base64 encoded ``dill``-serialized object\n\n        \"\"\"\n        dill_bytes = dill.dumps(obj)\n        return b64encode(dill_bytes).decode(\"utf-8\")\n\n    @staticmethod\n    def reverse(obj: Any) -&gt; Any:\n        \"\"\"Decode an object.\n\n        Args:\n            obj (Any): an object to decode\n\n        Returns:\n            decoded (Any): ``dill``-deserialized object from base64 encoded string\n\n        \"\"\"\n        if obj is None:\n            return None\n        base64_bytes = obj.encode(\"utf-8\")\n        return dill.loads(b64decode(base64_bytes))\n</code></pre>"},{"location":"reference/#alsek.storage.serialization.BinarySerializer.forward","title":"<code>forward(obj)</code>  <code>staticmethod</code>","text":"<p>Encode an object.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>an object to encode</p> required <p>Returns:</p> Name Type Description <code>encoded</code> <code>Any</code> <p>base64 encoded <code>dill</code>-serialized object</p> Source code in <code>alsek/storage/serialization.py</code> <pre><code>@staticmethod\ndef forward(obj: Any) -&gt; Any:\n    \"\"\"Encode an object.\n\n    Args:\n        obj (Any): an object to encode\n\n    Returns:\n        encoded (Any): base64 encoded ``dill``-serialized object\n\n    \"\"\"\n    dill_bytes = dill.dumps(obj)\n    return b64encode(dill_bytes).decode(\"utf-8\")\n</code></pre>"},{"location":"reference/#alsek.storage.serialization.BinarySerializer.reverse","title":"<code>reverse(obj)</code>  <code>staticmethod</code>","text":"<p>Decode an object.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>an object to decode</p> required <p>Returns:</p> Name Type Description <code>decoded</code> <code>Any</code> <p><code>dill</code>-deserialized object from base64 encoded string</p> Source code in <code>alsek/storage/serialization.py</code> <pre><code>@staticmethod\ndef reverse(obj: Any) -&gt; Any:\n    \"\"\"Decode an object.\n\n    Args:\n        obj (Any): an object to decode\n\n    Returns:\n        decoded (Any): ``dill``-deserialized object from base64 encoded string\n\n    \"\"\"\n    if obj is None:\n        return None\n    base64_bytes = obj.encode(\"utf-8\")\n    return dill.loads(b64decode(base64_bytes))\n</code></pre>"},{"location":"reference/#alsek.storage.serialization.JsonSerializer","title":"<code>JsonSerializer</code>","text":"<p>               Bases: <code>Serializer</code></p> <p>JSON serialization.</p> Source code in <code>alsek/storage/serialization.py</code> <pre><code>class JsonSerializer(Serializer):\n    \"\"\"JSON serialization.\"\"\"\n\n    @staticmethod\n    def forward(obj: Any) -&gt; Any:\n        \"\"\"Encode an object.\n\n        Args:\n            obj (Any): an object to encode\n\n        Returns:\n            encoded (Any): JSON encoded object\n\n        \"\"\"\n        return json.dumps(obj)\n\n    @staticmethod\n    def reverse(obj: Any) -&gt; Any:\n        \"\"\"Decode an object.\n\n        Args:\n            obj (Any): an object to decode\n\n        Returns:\n            decoded (Any): JSON decoded object\n\n        \"\"\"\n        if obj is None:\n            return None\n        return json.loads(obj)\n</code></pre>"},{"location":"reference/#alsek.storage.serialization.JsonSerializer.forward","title":"<code>forward(obj)</code>  <code>staticmethod</code>","text":"<p>Encode an object.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>an object to encode</p> required <p>Returns:</p> Name Type Description <code>encoded</code> <code>Any</code> <p>JSON encoded object</p> Source code in <code>alsek/storage/serialization.py</code> <pre><code>@staticmethod\ndef forward(obj: Any) -&gt; Any:\n    \"\"\"Encode an object.\n\n    Args:\n        obj (Any): an object to encode\n\n    Returns:\n        encoded (Any): JSON encoded object\n\n    \"\"\"\n    return json.dumps(obj)\n</code></pre>"},{"location":"reference/#alsek.storage.serialization.JsonSerializer.reverse","title":"<code>reverse(obj)</code>  <code>staticmethod</code>","text":"<p>Decode an object.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>an object to decode</p> required <p>Returns:</p> Name Type Description <code>decoded</code> <code>Any</code> <p>JSON decoded object</p> Source code in <code>alsek/storage/serialization.py</code> <pre><code>@staticmethod\ndef reverse(obj: Any) -&gt; Any:\n    \"\"\"Decode an object.\n\n    Args:\n        obj (Any): an object to decode\n\n    Returns:\n        decoded (Any): JSON decoded object\n\n    \"\"\"\n    if obj is None:\n        return None\n    return json.loads(obj)\n</code></pre>"},{"location":"reference/#alsek.storage.serialization.Serializer","title":"<code>Serializer</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base Serializer Class.</p> Source code in <code>alsek/storage/serialization.py</code> <pre><code>class Serializer(ABC):\n    \"\"\"Base Serializer Class.\"\"\"\n\n    def __repr__(self) -&gt; str:\n        return auto_repr(self)\n\n    @staticmethod\n    @abstractmethod\n    def forward(obj: Any) -&gt; Any:\n        \"\"\"Encode an object for backend serialization.\n\n        Args:\n            obj (Any): an object to encode\n\n        Returns:\n            encoded (Any): encoded object\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @staticmethod\n    @abstractmethod\n    def reverse(obj: Any) -&gt; Any:\n        \"\"\"Decode an object.\n\n        Args:\n            obj (Any): an object to decode\n\n        Returns:\n            decoded (Any): decoded object\n\n        \"\"\"\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/#alsek.storage.serialization.Serializer.forward","title":"<code>forward(obj)</code>  <code>abstractmethod</code> <code>staticmethod</code>","text":"<p>Encode an object for backend serialization.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>an object to encode</p> required <p>Returns:</p> Name Type Description <code>encoded</code> <code>Any</code> <p>encoded object</p> Source code in <code>alsek/storage/serialization.py</code> <pre><code>@staticmethod\n@abstractmethod\ndef forward(obj: Any) -&gt; Any:\n    \"\"\"Encode an object for backend serialization.\n\n    Args:\n        obj (Any): an object to encode\n\n    Returns:\n        encoded (Any): encoded object\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/#alsek.storage.serialization.Serializer.reverse","title":"<code>reverse(obj)</code>  <code>abstractmethod</code> <code>staticmethod</code>","text":"<p>Decode an object.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>an object to decode</p> required <p>Returns:</p> Name Type Description <code>decoded</code> <code>Any</code> <p>decoded object</p> Source code in <code>alsek/storage/serialization.py</code> <pre><code>@staticmethod\n@abstractmethod\ndef reverse(obj: Any) -&gt; Any:\n    \"\"\"Decode an object.\n\n    Args:\n        obj (Any): an object to decode\n\n    Returns:\n        decoded (Any): decoded object\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/#alsek.tools","title":"<code>tools</code>","text":"<p>Tools</p>"},{"location":"reference/#alsek.tools.iteration","title":"<code>iteration</code>","text":"<p>Result Iteration</p>"},{"location":"reference/#alsek.tools.iteration.ResultPool","title":"<code>ResultPool</code>","text":"<p>Tooling for iterating over task results.</p> <p>Parameters:</p> Name Type Description Default <code>result_store</code> <code>ResultStore</code> <p>store where task results are persisted</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from alsek.storage.result import ResultStore\n&gt;&gt;&gt; from alsek.tools.iteration import ResultPool\n...\n&gt;&gt;&gt; result_store = ResultStore(...)\n&gt;&gt;&gt; pool = ResultPool(result_store)\n...\n&gt;&gt;&gt; messages = [...]\n&gt;&gt;&gt; for uuid, result in pool.istream(*messages):\n...     pass\n</code></pre> Source code in <code>alsek/tools/iteration.py</code> <pre><code>class ResultPool:\n    \"\"\"Tooling for iterating over task results.\n\n    Args:\n        result_store (ResultStore): store where task results are persisted\n\n    Examples:\n        &gt;&gt;&gt; from alsek.storage.result import ResultStore\n        &gt;&gt;&gt; from alsek.tools.iteration import ResultPool\n        ...\n        &gt;&gt;&gt; result_store = ResultStore(...)\n        &gt;&gt;&gt; pool = ResultPool(result_store)\n        ...\n        &gt;&gt;&gt; messages = [...]\n        &gt;&gt;&gt; for uuid, result in pool.istream(*messages):\n        ...     pass\n\n    \"\"\"\n\n    def __init__(self, result_store: ResultStore) -&gt; None:\n        self.result_store = result_store\n\n        self.stop_signal = StopSignalListener(exit_override=False)\n\n    @staticmethod\n    def _validate(messages: tuple[Message, ...]) -&gt; None:\n        if has_duplicates([m.uuid for m in messages]):\n            raise ValidationError(\"Duplicate messages detected\")\n\n    def _engine(\n        self,\n        messages: tuple[Message, ...],\n        wait: int,\n        break_on_error: bool,\n        **kwargs: Any,\n    ) -&gt; Iterable[tuple[Message, Any]]:\n        self._validate(messages)\n\n        outstanding = list(range(len(messages)))\n        while outstanding and not self.stop_signal.received:\n            to_drop = set()\n            for i in outstanding:\n                try:\n                    yield messages[i], self.result_store.get(messages[i], **kwargs)\n                    to_drop.add(i)\n                except (KeyError, TimeoutError):\n                    if break_on_error:\n                        break\n\n            outstanding = _idx_drop(outstanding, indexes=to_drop)\n            self.stop_signal.wait(wait if outstanding else 0)\n\n    def istream(\n        self,\n        *messages: Message,\n        wait: int = 5 * 1000,\n        descendants: bool = False,\n        **kwargs: Any,\n    ) -&gt; Iterable[tuple[Message, Any]]:\n        \"\"\"Stream the results of one or more messages. Results are yielded\n        in the order in which they become available. (This may differ from\n        the order in which messages are provided.)\n\n        Args:\n            *messages (Message): one or more messages to iterate over\n            wait (int): time to wait (in milliseconds) between checks for\n                available results\n            descendants (bool): if ``True``, wait for and return\n                the results of all descendant (callback) messages.\n            **kwargs (Keyword Args): keyword arguments to pass to\n                ``result_store.get()``.\n\n        results (iterable): an iterable of results of the form\n            ``(Message, result)``.\n\n        Warning:\n            * By default, ``result_store`` does not keep messages once\n              they have been collected. As a result, providing messages\n              for which the corresponding results have already been collected\n              (and deleted) will cause this method to loop indefinitely.\n              In order to loop over messages multiple times set ``keep=True``.\n\n        \"\"\"\n        yield from self._engine(\n            messages,\n            wait=wait,\n            break_on_error=False,\n            descendants=descendants,\n            **kwargs,\n        )\n\n    def stream(\n        self,\n        *messages: Message,\n        wait: int = 5 * 1000,\n        descendants: bool = False,\n        **kwargs: Any,\n    ) -&gt; Iterable[tuple[Message, Any]]:\n        \"\"\"Stream the results of one or more messages. The order of the\n        results are guaranteed to match the order of ``messages``.\n\n        Args:\n            *messages (Message): one or more messages to iterate over\n            wait (int): time to wait (in milliseconds) between checks for\n                available results\n            descendants (bool): if ``True``, wait for and return\n                the results of all descendant (callback) messages.\n            **kwargs (Keyword Args): keyword arguments to pass to\n                ``result_store.get()``.\n\n        Returns:\n            results (iterable): an iterable of results of the form\n                ``(Message, result)``.\n\n        Warning:\n            * By default, ``result_store`` does not keep messages once\n              they have been collected. As a result, providing messages\n              for which the corresponding results have already been collected\n              (and deleted) will cause this method to loop indefinitely.\n              In order to loop over messages multiple times set ``keep=True``.\n\n        \"\"\"\n        yield from self._engine(\n            messages,\n            wait=wait,\n            break_on_error=True,\n            descendants=descendants,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/#alsek.tools.iteration.ResultPool.istream","title":"<code>istream(*messages, wait=5 * 1000, descendants=False, **kwargs)</code>","text":"<p>Stream the results of one or more messages. Results are yielded in the order in which they become available. (This may differ from the order in which messages are provided.)</p> <p>Parameters:</p> Name Type Description Default <code>*messages</code> <code>Message</code> <p>one or more messages to iterate over</p> <code>()</code> <code>wait</code> <code>int</code> <p>time to wait (in milliseconds) between checks for available results</p> <code>5 * 1000</code> <code>descendants</code> <code>bool</code> <p>if <code>True</code>, wait for and return the results of all descendant (callback) messages.</p> <code>False</code> <code>**kwargs</code> <code>Keyword Args</code> <p>keyword arguments to pass to <code>result_store.get()</code>.</p> <code>{}</code> <p>results (iterable): an iterable of results of the form     <code>(Message, result)</code>.</p> Warning <ul> <li>By default, <code>result_store</code> does not keep messages once   they have been collected. As a result, providing messages   for which the corresponding results have already been collected   (and deleted) will cause this method to loop indefinitely.   In order to loop over messages multiple times set <code>keep=True</code>.</li> </ul> Source code in <code>alsek/tools/iteration.py</code> <pre><code>def istream(\n    self,\n    *messages: Message,\n    wait: int = 5 * 1000,\n    descendants: bool = False,\n    **kwargs: Any,\n) -&gt; Iterable[tuple[Message, Any]]:\n    \"\"\"Stream the results of one or more messages. Results are yielded\n    in the order in which they become available. (This may differ from\n    the order in which messages are provided.)\n\n    Args:\n        *messages (Message): one or more messages to iterate over\n        wait (int): time to wait (in milliseconds) between checks for\n            available results\n        descendants (bool): if ``True``, wait for and return\n            the results of all descendant (callback) messages.\n        **kwargs (Keyword Args): keyword arguments to pass to\n            ``result_store.get()``.\n\n    results (iterable): an iterable of results of the form\n        ``(Message, result)``.\n\n    Warning:\n        * By default, ``result_store`` does not keep messages once\n          they have been collected. As a result, providing messages\n          for which the corresponding results have already been collected\n          (and deleted) will cause this method to loop indefinitely.\n          In order to loop over messages multiple times set ``keep=True``.\n\n    \"\"\"\n    yield from self._engine(\n        messages,\n        wait=wait,\n        break_on_error=False,\n        descendants=descendants,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/#alsek.tools.iteration.ResultPool.stream","title":"<code>stream(*messages, wait=5 * 1000, descendants=False, **kwargs)</code>","text":"<p>Stream the results of one or more messages. The order of the results are guaranteed to match the order of <code>messages</code>.</p> <p>Parameters:</p> Name Type Description Default <code>*messages</code> <code>Message</code> <p>one or more messages to iterate over</p> <code>()</code> <code>wait</code> <code>int</code> <p>time to wait (in milliseconds) between checks for available results</p> <code>5 * 1000</code> <code>descendants</code> <code>bool</code> <p>if <code>True</code>, wait for and return the results of all descendant (callback) messages.</p> <code>False</code> <code>**kwargs</code> <code>Keyword Args</code> <p>keyword arguments to pass to <code>result_store.get()</code>.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>results</code> <code>iterable</code> <p>an iterable of results of the form <code>(Message, result)</code>.</p> Warning <ul> <li>By default, <code>result_store</code> does not keep messages once   they have been collected. As a result, providing messages   for which the corresponding results have already been collected   (and deleted) will cause this method to loop indefinitely.   In order to loop over messages multiple times set <code>keep=True</code>.</li> </ul> Source code in <code>alsek/tools/iteration.py</code> <pre><code>def stream(\n    self,\n    *messages: Message,\n    wait: int = 5 * 1000,\n    descendants: bool = False,\n    **kwargs: Any,\n) -&gt; Iterable[tuple[Message, Any]]:\n    \"\"\"Stream the results of one or more messages. The order of the\n    results are guaranteed to match the order of ``messages``.\n\n    Args:\n        *messages (Message): one or more messages to iterate over\n        wait (int): time to wait (in milliseconds) between checks for\n            available results\n        descendants (bool): if ``True``, wait for and return\n            the results of all descendant (callback) messages.\n        **kwargs (Keyword Args): keyword arguments to pass to\n            ``result_store.get()``.\n\n    Returns:\n        results (iterable): an iterable of results of the form\n            ``(Message, result)``.\n\n    Warning:\n        * By default, ``result_store`` does not keep messages once\n          they have been collected. As a result, providing messages\n          for which the corresponding results have already been collected\n          (and deleted) will cause this method to loop indefinitely.\n          In order to loop over messages multiple times set ``keep=True``.\n\n    \"\"\"\n    yield from self._engine(\n        messages,\n        wait=wait,\n        break_on_error=True,\n        descendants=descendants,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/#alsek.types","title":"<code>types</code>","text":"<p>Types</p>"},{"location":"reference/#alsek.types.Empty","title":"<code>Empty</code>","text":"<p>Empty sentinel.</p> Source code in <code>alsek/types.py</code> <pre><code>class Empty:\n    \"\"\"Empty sentinel.\"\"\"\n</code></pre>"},{"location":"reference/#alsek.utils","title":"<code>utils</code>","text":""},{"location":"reference/#alsek.utils.aggregation","title":"<code>aggregation</code>","text":"<p>Aggregation Utils</p>"},{"location":"reference/#alsek.utils.aggregation.gather_init_params","title":"<code>gather_init_params(obj, ignore=None)</code>","text":"<p>Extract the parameters passed to an object's <code>__init__()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> required <code>ignore</code> <code>tuple</code> <p>parameters in <code>__init__()</code> to ignore</p> <code>None</code> <p>Returns:</p> Name Type Description <code>params</code> <code>dict</code> <p>parameters from <code>__init__()</code>.</p> Source code in <code>alsek/utils/aggregation.py</code> <pre><code>def gather_init_params(\n    obj: Any,\n    ignore: Optional[tuple[str, ...]] = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Extract the parameters passed to an object's ``__init__()``.\n\n    Args:\n        obj (object):\n        ignore (tuple, optional): parameters in ``__init__()`` to ignore\n\n    Returns:\n        params (dict): parameters from ``__init__()``.\n\n    \"\"\"\n    params = dict()\n    for k in inspect.signature(obj.__init__).parameters:\n        if ignore and k in ignore:\n            continue\n        params[k] = getattr(obj, k)\n    return params\n</code></pre>"},{"location":"reference/#alsek.utils.checks","title":"<code>checks</code>","text":"<p>Check Utils</p>"},{"location":"reference/#alsek.utils.checks.has_duplicates","title":"<code>has_duplicates(itera)</code>","text":"<p>Determine if <code>itera</code> contains duplicates.</p> <p>Parameters:</p> Name Type Description Default <code>itera</code> <code>Collection</code> <p>a sized iterable</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>alsek/utils/checks.py</code> <pre><code>def has_duplicates(itera: Collection[Any]) -&gt; bool:\n    \"\"\"Determine if ``itera`` contains duplicates.\n\n    Args:\n        itera (Collection): a sized iterable\n\n    Returns:\n        bool\n\n    \"\"\"\n    seen = set()\n    for i in itera:\n        if i in seen:\n            return True\n        seen.add(i)\n    return False\n</code></pre>"},{"location":"reference/#alsek.utils.decorators","title":"<code>decorators</code>","text":"<p>Decorators</p>"},{"location":"reference/#alsek.utils.environment","title":"<code>environment</code>","text":"<p>Environment</p>"},{"location":"reference/#alsek.utils.helpers","title":"<code>helpers</code>","text":"<p>Helpers</p>"},{"location":"reference/#alsek.utils.logging","title":"<code>logging</code>","text":"<p>Logging</p>"},{"location":"reference/#alsek.utils.logging.get_logger","title":"<code>get_logger()</code>","text":"<p>Get the Alsek logger.</p> <p>Returns:</p> Name Type Description <code>logger</code> <code>Logger</code> <p>Alsek logger</p> Source code in <code>alsek/utils/logging.py</code> <pre><code>def get_logger() -&gt; logging.Logger:\n    \"\"\"Get the Alsek logger.\n\n    Returns:\n        logger (logging.Logger): Alsek logger\n\n    \"\"\"\n    return logging.getLogger(\"alsek\")\n</code></pre>"},{"location":"reference/#alsek.utils.logging.magic_logger","title":"<code>magic_logger(before=lambda: None, after=lambda: None)</code>","text":"<p>Logging decorator.</p> <p>Parameters:</p> Name Type Description Default <code>before</code> <code>callable</code> <p>function to log a message before function execution. This callable will be passed only those parameters     which it shares with the deocrated function.</p> <code>lambda: None</code> <code>after</code> <code>callable</code> <p>function to log a message after function execution. This callable will be passed:     * <code>input_</code>: a dictionary where the key is a parameter accepted       by the wrapped function and the value is the value passed. If not       present in the signature of <code>after</code> this data will not be provided.     * <code>output</code>: the output of the function. If not present in the signature       of <code>after</code> this data will not be provided.</p> <code>lambda: None</code> <p>Returns:</p> Name Type Description <code>wrapper</code> <code>callable</code> <p>wrapped <code>function</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import logging\n&gt;&gt;&gt; from alsek.utils.logging import magic_logger\n</code></pre> <pre><code>&gt;&gt;&gt; log = logging.getLogger(__name__)\n</code></pre> <pre><code>&gt;&gt;&gt; @magic_logger(\n&gt;&gt;&gt;    before=lambda a: log.debug(a),\n&gt;&gt;&gt;    after=lambda input_, output: log.info(output)\n&gt;&gt;&gt; )\n&gt;&gt;&gt; def add99(a: int) -&gt; int:\n&gt;&gt;&gt;    return a + 99\n</code></pre> Source code in <code>alsek/utils/logging.py</code> <pre><code>def magic_logger(\n    before: Callable[..., Any] = lambda: None,\n    after: Callable[..., Any] = lambda: None,\n) -&gt; Callable[..., Any]:\n    \"\"\"Logging decorator.\n\n    Args:\n        before (callable): function to log a message before function\n            execution. This callable will be passed only those parameters\n                which it shares with the deocrated function.\n        after (callable): function to log a message after function\n            execution. This callable will be passed:\n                * ``input_``: a dictionary where the key is a parameter accepted\n                  by the wrapped function and the value is the value passed. If not\n                  present in the signature of ``after`` this data will not be provided.\n                * ``output``: the output of the function. If not present in the signature\n                  of ``after`` this data will not be provided.\n\n    Returns:\n        wrapper (callable): wrapped ``function``\n\n    Examples:\n        &gt;&gt;&gt; import logging\n        &gt;&gt;&gt; from alsek.utils.logging import magic_logger\n\n        &gt;&gt;&gt; log = logging.getLogger(__name__)\n\n        &gt;&gt;&gt; @magic_logger(\n        &gt;&gt;&gt;    before=lambda a: log.debug(a),\n        &gt;&gt;&gt;    after=lambda input_, output: log.info(output)\n        &gt;&gt;&gt; )\n        &gt;&gt;&gt; def add99(a: int) -&gt; int:\n        &gt;&gt;&gt;    return a + 99\n\n    \"\"\"\n\n    def wrapper(function_raw: Callable[..., Any]) -&gt; Callable[..., Any]:\n        @wraps(function_raw)\n        def inner(*args_raw: Any, **kwargs_raw: Any) -&gt; Any:\n            function, args, kwargs = _magic_parser(\n                function_raw,\n                args_raw=args_raw,\n                kwargs_raw=kwargs_raw,\n            )\n            full_kwargs = _merge_args_kwargs(function, args=args, kwargs=kwargs)\n            _run_func(before, **full_kwargs)\n            output = function(*args, **kwargs)\n            _run_func(after, input_=full_kwargs, output=output)\n            return output\n\n        return inner\n\n    return wrapper\n</code></pre>"},{"location":"reference/#alsek.utils.logging.setup_logging","title":"<code>setup_logging(level)</code>","text":"<p>Setup Alsek-style logging.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>int</code> <p>logging level to use</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/utils/logging.py</code> <pre><code>def setup_logging(level: int) -&gt; None:\n    \"\"\"Setup Alsek-style logging.\n\n    Args:\n        level (int): logging level to use\n\n    Returns:\n        None\n\n    \"\"\"\n    logger = get_logger()\n    handler = logging.StreamHandler()\n    formatter = logging.Formatter(fmt=LOGGING_FORMAT, datefmt=LOGGING_DATEFMT)\n    handler.setFormatter(formatter)\n    logger.handlers = [handler]\n    logger.setLevel(level)\n    logger.propagate = False  # &lt;-- super important!\n</code></pre>"},{"location":"reference/#alsek.utils.namespacing","title":"<code>namespacing</code>","text":"<p>Namespacing</p>"},{"location":"reference/#alsek.utils.namespacing.get_dlq_message_name","title":"<code>get_dlq_message_name(message)</code>","text":"<p>Get the name for <code>message</code> in the backend's dead letter queue (DLQ).</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>dlq_name</code> <code>str</code> <p>message-specific name in the DLQ</p> Source code in <code>alsek/utils/namespacing.py</code> <pre><code>def get_dlq_message_name(message: Message) -&gt; str:\n    \"\"\"Get the name for ``message`` in the backend's dead letter queue (DLQ).\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        dlq_name (str): message-specific name in the DLQ\n\n    \"\"\"\n    return f\"{DLQ_NAMESPACE_KEY}:{get_message_name(message)}\"\n</code></pre>"},{"location":"reference/#alsek.utils.namespacing.get_message_name","title":"<code>get_message_name(message)</code>","text":"<p>Get the name for <code>message</code> in the backend.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>name</code> <code>str</code> <p>message-specific name</p> Source code in <code>alsek/utils/namespacing.py</code> <pre><code>def get_message_name(message: Message) -&gt; str:\n    \"\"\"Get the name for ``message`` in the backend.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        name (str): message-specific name\n\n    \"\"\"\n    subnamespace = get_messages_namespace(message)\n    return f\"{subnamespace}:{message.uuid}\"\n</code></pre>"},{"location":"reference/#alsek.utils.namespacing.get_message_signature","title":"<code>get_message_signature(message)</code>","text":"<p>Get the signature for <code>message</code> in the backend.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>signature</code> <code>str</code> <p>message-specific signature.</p> Source code in <code>alsek/utils/namespacing.py</code> <pre><code>def get_message_signature(message: Message) -&gt; str:\n    \"\"\"Get the signature for ``message`` in the backend.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        signature (str): message-specific signature.\n\n    \"\"\"\n    return f\"{get_message_name(message)}:retry:{message.retries}\"\n</code></pre>"},{"location":"reference/#alsek.utils.namespacing.get_messages_namespace","title":"<code>get_messages_namespace(message)</code>","text":"<p>Get the namespace for a message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>namespace</code> <code>str</code> <p>the namespace for the message</p> Source code in <code>alsek/utils/namespacing.py</code> <pre><code>def get_messages_namespace(message: Message) -&gt; str:\n    \"\"\"Get the namespace for a message.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        namespace (str): the namespace for the message\n\n    \"\"\"\n    subnamespace = get_subnamespace(message.queue, message.task_name)\n    return f\"{subnamespace}:{MESSAGES_NAMESPACE_KEY}\"\n</code></pre>"},{"location":"reference/#alsek.utils.namespacing.get_priority_namespace","title":"<code>get_priority_namespace(subnamespace)</code>","text":"<p>Get the namespace for a message's priority information.</p> <p>Parameters:</p> Name Type Description Default <code>subnamespace</code> <code>str</code> <p>the namespace for the message</p> required <p>Returns:</p> Name Type Description <code>priority_namespace</code> <code>str</code> <p>the namespace for priority information</p> Source code in <code>alsek/utils/namespacing.py</code> <pre><code>def get_priority_namespace(subnamespace: str) -&gt; str:\n    \"\"\"Get the namespace for a message's priority information.\n\n    Args:\n        subnamespace (str): the namespace for the message\n\n    Returns:\n        priority_namespace (str): the namespace for priority information\n\n    \"\"\"\n    return f\"{PRIORITY_NAMESPACE_KEY}:{subnamespace}\"\n</code></pre>"},{"location":"reference/#alsek.utils.namespacing.get_priority_namespace_from_message","title":"<code>get_priority_namespace_from_message(message)</code>","text":"<p>Get the namespace for message's priority information.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>an Alsek message</p> required <p>Returns:</p> Name Type Description <code>namespace</code> <code>str</code> <p>the fully-qualified priority queue name</p> Source code in <code>alsek/utils/namespacing.py</code> <pre><code>def get_priority_namespace_from_message(message: Message) -&gt; str:\n    \"\"\"Get the namespace for message's priority information.\n\n    Args:\n        message (Message): an Alsek message\n\n    Returns:\n        namespace (str): the fully-qualified priority queue name\n\n    \"\"\"\n    subnamespace = get_subnamespace(message.queue, message.task_name)\n    return get_priority_namespace(subnamespace)\n</code></pre>"},{"location":"reference/#alsek.utils.namespacing.get_subnamespace","title":"<code>get_subnamespace(queue=None, task_name=None)</code>","text":"<p>Get the subnamespace for a given <code>queue</code> and (optionally) <code>task_name</code>.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>str</code> <p>the name of the queue</p> <code>None</code> <code>task_name</code> <code>str</code> <p>name of the task</p> <code>None</code> <p>Returns:</p> Name Type Description <code>subnamespace</code> <code>str</code> <p>queue-specific namespace</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>task_name</code> is provided and <code>queue</code> is not.</p> Source code in <code>alsek/utils/namespacing.py</code> <pre><code>def get_subnamespace(\n    queue: Optional[str] = None,\n    task_name: Optional[str] = None,\n) -&gt; str:\n    \"\"\"Get the subnamespace for a given ``queue``\n    and (optionally) ``task_name``.\n\n    Args:\n        queue (str, optional): the name of the queue\n        task_name (str): name of the task\n\n    Returns:\n        subnamespace (str): queue-specific namespace\n\n    Raises:\n        ValueError: if ``task_name`` is provided and ``queue`` is not.\n\n    \"\"\"\n    if queue is None and task_name is not None:\n        raise ValueError(\"`queue` must be provided if `task_name` is not None\")\n\n    if queue and task_name:\n        return f\"{QUEUES_NAMESPACE_KEY}:{queue}:{TASK_NAMESPACE_KEY}:{task_name}\"\n    elif queue:\n        return f\"{QUEUES_NAMESPACE_KEY}:{queue}\"\n    else:\n        return f\"{QUEUES_NAMESPACE_KEY}\"\n</code></pre>"},{"location":"reference/#alsek.utils.parsing","title":"<code>parsing</code>","text":"<p>Parsing</p>"},{"location":"reference/#alsek.utils.parsing.ExceptionDetails","title":"<code>ExceptionDetails</code>","text":"<p>               Bases: <code>NamedTuple</code></p> Source code in <code>alsek/utils/parsing.py</code> <pre><code>class ExceptionDetails(NamedTuple):\n    name: str\n    text: Optional[str] = None\n    traceback: Optional[str] = None\n\n    def as_dict(self) -&gt; dict[str, str]:\n        \"\"\"Convert the NamedTuple to a dictionary\n\n        Returns:\n            dict\n\n        \"\"\"\n        return self._asdict()\n\n    def as_exception(self, strict: bool = True) -&gt; BaseException:\n        \"\"\"Return parsed exception information as a Python exception.\n\n        Args:\n            strict (bool): if ``True`` do not coerce failures to\n                import the correct error\n\n        Returns:\n            BaseException\n\n        Warnings:\n            This will not include the original traceback.\n\n        \"\"\"\n        try:\n            exc, text = _get_exception_class(self.name), self.text\n            output = exc(text)\n        except (ImportError, AttributeError, TypeError) as error:\n            if strict:\n                raise error\n            else:\n                exc, text = Exception, f\"{self.name}: {self.text}\"\n            output = exc(text)\n        return output\n</code></pre>"},{"location":"reference/#alsek.utils.parsing.ExceptionDetails.as_dict","title":"<code>as_dict()</code>","text":"<p>Convert the NamedTuple to a dictionary</p> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>dict</p> Source code in <code>alsek/utils/parsing.py</code> <pre><code>def as_dict(self) -&gt; dict[str, str]:\n    \"\"\"Convert the NamedTuple to a dictionary\n\n    Returns:\n        dict\n\n    \"\"\"\n    return self._asdict()\n</code></pre>"},{"location":"reference/#alsek.utils.parsing.ExceptionDetails.as_exception","title":"<code>as_exception(strict=True)</code>","text":"<p>Return parsed exception information as a Python exception.</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool</code> <p>if <code>True</code> do not coerce failures to import the correct error</p> <code>True</code> <p>Returns:</p> Type Description <code>BaseException</code> <p>BaseException</p> Source code in <code>alsek/utils/parsing.py</code> <pre><code>def as_exception(self, strict: bool = True) -&gt; BaseException:\n    \"\"\"Return parsed exception information as a Python exception.\n\n    Args:\n        strict (bool): if ``True`` do not coerce failures to\n            import the correct error\n\n    Returns:\n        BaseException\n\n    Warnings:\n        This will not include the original traceback.\n\n    \"\"\"\n    try:\n        exc, text = _get_exception_class(self.name), self.text\n        output = exc(text)\n    except (ImportError, AttributeError, TypeError) as error:\n        if strict:\n            raise error\n        else:\n            exc, text = Exception, f\"{self.name}: {self.text}\"\n        output = exc(text)\n    return output\n</code></pre>"},{"location":"reference/#alsek.utils.parsing.get_exception_name","title":"<code>get_exception_name(exception)</code>","text":"<p>Get the name of an exception as a string.</p> <p>Parameters:</p> Name Type Description Default <code>exception</code> <code>(BaseException, Type[BaseException])</code> <p>Exception class</p> required <p>Returns:</p> Name Type Description <code>name</code> <code>str</code> <p>the exception name</p> Source code in <code>alsek/utils/parsing.py</code> <pre><code>def get_exception_name(exception: Union[BaseException, Type[BaseException]]) -&gt; str:\n    \"\"\"Get the name of an exception as a string.\n\n    Args:\n        exception (BaseException, Type[BaseException]): Exception class\n\n    Returns:\n        name (str): the exception name\n\n    \"\"\"\n    exception_type = exception if isinstance(exception, type) else type(exception)\n    module, qualname = exception_type.__module__, exception_type.__qualname__\n    return qualname if module == \"builtins\" else f\"{module}.{qualname}\"\n</code></pre>"},{"location":"reference/#alsek.utils.parsing.parse_exception","title":"<code>parse_exception(error)</code>","text":"<p>Extracts the exception type, exception message, and exception traceback from an error.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>BaseException</code> <p>The exception to extract details from.</p> required <p>Returns:</p> Name Type Description <code>details</code> <code>ExceptionDetails</code> <p>A named tuple containing the exception information</p> Source code in <code>alsek/utils/parsing.py</code> <pre><code>def parse_exception(error: BaseException) -&gt; ExceptionDetails:\n    \"\"\"Extracts the exception type, exception message, and exception\n    traceback from an error.\n\n    Args:\n        error (BaseException): The exception to extract details from.\n\n    Returns:\n        details (ExceptionDetails): A named tuple containing the exception information\n\n    \"\"\"\n    return ExceptionDetails(\n        name=get_exception_name(error),\n        text=str(error),\n        traceback=\"\".join(\n            traceback.format_exception(\n                type(error),\n                value=error,\n                tb=error.__traceback__,\n            )\n        ),\n    )\n</code></pre>"},{"location":"reference/#alsek.utils.printing","title":"<code>printing</code>","text":"<p>Printing Utils</p>"},{"location":"reference/#alsek.utils.printing.auto_repr","title":"<code>auto_repr(obj, new_line_threshold=5, **params)</code>","text":"<p>Autogenerate a class repr string.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>an object to generate a repr for</p> required <code>new_line_threshold</code> <code>int</code> <p>number of <code>params</code> required to split the parameters over multiple lines.</p> <code>5</code> <code>**params</code> <code>Keyword Args</code> <p>parameters to include in the repr string</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>repr</code> <code>str</code> <p>repr string</p> Source code in <code>alsek/utils/printing.py</code> <pre><code>def auto_repr(obj: object, new_line_threshold: Optional[int] = 5, **params: Any) -&gt; str:\n    \"\"\"Autogenerate a class repr string.\n\n    Args:\n        obj (object): an object to generate a repr for\n        new_line_threshold (int, optional): number of ``params``\n            required to split the parameters over multiple lines.\n        **params (Keyword Args): parameters to include in the\n            repr string\n\n    Returns:\n        repr (str): repr string\n\n    \"\"\"\n    class_name = obj.__class__.__name__\n    if new_line_threshold is None or len(params) &lt;= new_line_threshold:\n        start, join_on, end = \"\", \", \", \"\"\n    else:\n        start, join_on, end = \"\\n    \", \",\\n    \", \"\\n\"\n    return f\"{class_name}({start}{_format_params(params, join_on=join_on)}{end})\"\n</code></pre>"},{"location":"reference/#alsek.utils.scanning","title":"<code>scanning</code>","text":"<p>Helpers</p>"},{"location":"reference/#alsek.utils.scanning.collect_tasks","title":"<code>collect_tasks(module)</code>","text":"<p>Recursively collect all tasks in <code>name</code>.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>(str, ModuleType)</code> <p>name of a module</p> required <p>Returns:</p> Name Type Description <code>module</code> <code>tuple[Task, ...]</code> <p>collected tasks</p> <p>Raises:</p> Type Description <code>NoTasksFoundError</code> <p>if no tasks can be found</p> Source code in <code>alsek/utils/scanning.py</code> <pre><code>@magic_logger(\n    before=lambda module: log.debug(\"Scanning %r for tasks...\", module),\n    after=lambda output: log.debug(\n        \"Found %s task%s.\",\n        len(output),\n        \"s\" if len(output) &gt; 1 else \"\",\n    ),\n)\ndef collect_tasks(module: str | ModuleType) -&gt; tuple[Task, ...]:\n    \"\"\"Recursively collect all tasks in ``name``.\n\n    Args:\n        module (str, ModuleType): name of a module\n\n    Returns:\n        module (tuple[Task, ...]): collected tasks\n\n    Raises:\n        NoTasksFoundError: if no tasks can be found\n\n    \"\"\"\n    sys.path.append(os.getcwd())\n    if isinstance(module, str):\n        module = import_module(module)\n    elif not isinstance(module, ModuleType):\n        raise TypeError(f\"Unsupported input type, got {type(module)}\")\n\n    all_tasks: dict[str, Task] = dict()\n    for m in _enumerate_modules(module):\n        for name, task in getmembers(m, predicate=_is_task):\n            if name in all_tasks:\n                if task != all_tasks[name]:\n                    raise TaskNameCollisionError(f\"Multiple tasks '{name}'\")\n            else:\n                all_tasks[name] = task\n\n    if all_tasks:\n        return tuple(v for _, v in all_tasks.items())\n    else:\n        raise NoTasksFoundError(\"No tasks found\")\n</code></pre>"},{"location":"reference/#alsek.utils.sorting","title":"<code>sorting</code>","text":"<p>Sorting</p>"},{"location":"reference/#alsek.utils.sorting.dict_sort","title":"<code>dict_sort(dictionary, key=None)</code>","text":"<p>Sort a dictionary by key.</p> <p>Parameters:</p> Name Type Description Default <code>dictionary</code> <code>dict[Any, Any]</code> required <code>key</code> <code>callable</code> <p>a callable which consumes a key and returns an object which supports the less than comparison operator.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>sorted_dictionary</code> <code>dict</code> <p><code>dictionary</code> sorted</p> Source code in <code>alsek/utils/sorting.py</code> <pre><code>def dict_sort(\n    dictionary: dict[Any, Any],\n    key: Optional[Callable[[Any], Any]] = None,\n) -&gt; dict[Any, Any]:\n    \"\"\"Sort a dictionary by key.\n\n    Args:\n        dictionary:\n        key (callable): a callable which consumes a key\n            and returns an object which supports the\n            less than comparison operator.\n\n    Returns:\n        sorted_dictionary (dict): ``dictionary`` sorted\n\n    \"\"\"\n    return dict(sorted(dictionary.items(), key=lambda x: (key or (lambda k: k))(x[0])))  # type: ignore\n</code></pre>"},{"location":"reference/#alsek.utils.string","title":"<code>string</code>","text":"<p>String Utils</p>"},{"location":"reference/#alsek.utils.string.smart_join","title":"<code>smart_join(items, limit=None, delimiter=', ')</code>","text":"<p>Joins a list of strings with a delimiter, limiting the number of items to display and optionally appending a continuation indicator or providing a grammatically correct conjunction for the last two items.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[str]</code> <p>A list of strings to be joined.</p> required <code>limit</code> <code>Optional[int]</code> <p>The maximum number of items to include in the joined string. If None, join all items without limiting.</p> <code>None</code> <code>delimiter</code> <code>str</code> <p>The string used to separate the items in the joined output.</p> <code>', '</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string containing the joined items, formatted according to the</p> <code>str</code> <p>specified delimiter and limits.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the <code>items</code> list is empty.</p> Source code in <code>alsek/utils/string.py</code> <pre><code>def smart_join(\n    items: list[str],\n    limit: Optional[int] = None,\n    delimiter: str = \", \",\n) -&gt; str:\n    \"\"\"Joins a list of strings with a delimiter, limiting the number of items to display\n    and optionally appending a continuation indicator or providing a grammatically\n    correct conjunction for the last two items.\n\n    Args:\n        items (list[str]): A list of strings to be joined.\n        limit (Optional[int]): The maximum number of items to include in the joined\n            string. If None, join all items without limiting.\n        delimiter (str): The string used to separate the items in the joined output.\n\n    Returns:\n        str: A string containing the joined items, formatted according to the\n        specified delimiter and limits.\n\n    Raises:\n        ValueError: If the `items` list is empty.\n\n    \"\"\"\n    if len(items) == 0:\n        raise ValueError(\"No items to join\")\n    elif len(items) == 1:\n        return items[0]\n    elif limit is None or len(items) &lt;= limit:\n        *start, last = items\n        return f\"{delimiter.join(start)} and {last}\"\n    else:\n        return delimiter.join(items[:limit]) + \"...\"\n</code></pre>"},{"location":"reference/#alsek.utils.system","title":"<code>system</code>","text":"<p>System Utils</p>"},{"location":"reference/#alsek.utils.system.StopSignalListener","title":"<code>StopSignalListener</code>","text":"<p>Tool for listing for stop signals.</p> <p>Parameters:</p> Name Type Description Default <code>stop_signals</code> <code>tuple[int, ...]</code> <p>one or more stop signals to listen for.</p> <code>DEFAULT_STOP_SIGNALS</code> <code>exit_override</code> <code>bool</code> <p>trigger an immediate and non-graceful shutdown of the current process if two or more SIGTERM or SIGINT signals are received.</p> <code>True</code> Source code in <code>alsek/utils/system.py</code> <pre><code>class StopSignalListener:\n    \"\"\"Tool for listing for stop signals.\n\n    Args:\n        stop_signals (tuple[int, ...], optional): one or more stop\n            signals to listen for.\n        exit_override (bool): trigger an immediate and non-graceful shutdown\n            of the current process if two or more SIGTERM or SIGINT signals\n            are received.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        stop_signals: tuple[int, ...] = DEFAULT_STOP_SIGNALS,\n        exit_override: bool = True,\n    ) -&gt; None:\n        self.stop_signals = stop_signals\n        self.exit_override = exit_override\n\n        self.exit_event = Event()\n        for s in self.stop_signals:\n            signal.signal(s, self._signal_handler)\n\n    def _signal_handler(self, signum: int, *args: Any) -&gt; None:  # noqa\n        log.debug(\"Received stop signal %s...\", Signals(signum).name)\n        if self.exit_override and self.received:\n            sys.exit(1)\n        self.exit_event.set()\n\n    def wait(self, timeout: Optional[int]) -&gt; None:\n        \"\"\"Wait for a stop signal to be received.\n\n        Args:\n            timeout (int, optional): amount of time\n                (in milliseconds) to wait\n\n        Returns:\n            None\n\n        \"\"\"\n        self.exit_event.wait(timeout if timeout is None else timeout / 1000)\n\n    @property\n    def received(self) -&gt; bool:\n        \"\"\"Whether a stop signal has been received.\"\"\"\n        return self.exit_event.is_set()\n</code></pre>"},{"location":"reference/#alsek.utils.system.StopSignalListener.received","title":"<code>received</code>  <code>property</code>","text":"<p>Whether a stop signal has been received.</p>"},{"location":"reference/#alsek.utils.system.StopSignalListener.wait","title":"<code>wait(timeout)</code>","text":"<p>Wait for a stop signal to be received.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>int</code> <p>amount of time (in milliseconds) to wait</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alsek/utils/system.py</code> <pre><code>def wait(self, timeout: Optional[int]) -&gt; None:\n    \"\"\"Wait for a stop signal to be received.\n\n    Args:\n        timeout (int, optional): amount of time\n            (in milliseconds) to wait\n\n    Returns:\n        None\n\n    \"\"\"\n    self.exit_event.wait(timeout if timeout is None else timeout / 1000)\n</code></pre>"},{"location":"reference/#alsek.utils.system.smart_cpu_count","title":"<code>smart_cpu_count()</code>","text":"<p>Count the number of CPUs, with one reserved for the main process.</p> <p>Returns:</p> Name Type Description <code>count</code> <code>int</code> <p>number of cpus</p> Source code in <code>alsek/utils/system.py</code> <pre><code>def smart_cpu_count() -&gt; int:\n    \"\"\"Count the number of CPUs, with one reserved\n    for the main process.\n\n    Returns:\n        count (int): number of cpus\n\n    \"\"\"\n    return max(1, cpu_count() - 1)\n</code></pre>"},{"location":"reference/#alsek.utils.system.thread_raise","title":"<code>thread_raise(ident, exception)</code>","text":"<p>Raise an exception in a thread asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>ident</code> <code>int</code> <p>ident of the thread</p> required <code>exception</code> <code>Type[BaseException]</code> <p>type of exception to raise in the thread</p> required References <ul> <li>https://docs.python.org/3/c-api/init.html#c.PyThreadState_SetAsyncExc</li> </ul> Warning <ul> <li>Intended for use with CPython only</li> </ul> Source code in <code>alsek/utils/system.py</code> <pre><code>def thread_raise(ident: int, exception: Type[BaseException]) -&gt; None:\n    \"\"\"Raise an exception in a thread asynchronously.\n\n    Args:\n        ident (int): ident of the thread\n        exception (Type[BaseException]): type of exception to raise in the thread\n\n    References:\n        * https://docs.python.org/3/c-api/init.html#c.PyThreadState_SetAsyncExc\n\n    Warning:\n        * Intended for use with CPython only\n\n    \"\"\"\n    n = ctypes.pythonapi.PyThreadState_SetAsyncExc(\n        _cast_ident_to_ctype(ident),\n        ctypes.py_object(exception),\n    )\n    if n != 1:\n        log.warning(f\"Raising {exception} in thread {ident} modified {n} threads\")\n</code></pre>"},{"location":"reference/#alsek.utils.temporal","title":"<code>temporal</code>","text":"<p>Temporal Utils</p>"},{"location":"reference/#alsek.utils.temporal.from_timestamp_ms","title":"<code>from_timestamp_ms(timestamp)</code>","text":"<p>Construct datetime object from UTC timestamp in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>int</code> <p>UTC time in milliseconds</p> required <p>Returns:</p> Type Description <code>datetime</code> <p>datetime</p> Source code in <code>alsek/utils/temporal.py</code> <pre><code>def from_timestamp_ms(timestamp: int) -&gt; datetime:\n    \"\"\"Construct datetime object from UTC timestamp in milliseconds.\n\n    Args:\n        timestamp (int): UTC time in milliseconds\n\n    Returns:\n        datetime\n\n    \"\"\"\n    return datetime.fromtimestamp(timestamp / 1000)\n</code></pre>"},{"location":"reference/#alsek.utils.temporal.time_ms","title":"<code>time_ms()</code>","text":"<p>Get the current time since the Epoch in milliseconds.</p> <p>Returns:</p> Name Type Description <code>time</code> <code>int</code> <p>current time in milliseconds</p> Source code in <code>alsek/utils/temporal.py</code> <pre><code>def time_ms() -&gt; int:\n    \"\"\"Get the current time since the Epoch in milliseconds.\n\n    Returns:\n        time (int): current time in milliseconds\n\n    \"\"\"\n    return int(time.time() * 1000)\n</code></pre>"},{"location":"reference/#alsek.utils.temporal.utcnow_timestamp_ms","title":"<code>utcnow_timestamp_ms()</code>","text":"<p>UTC timestamp in milliseconds.</p> <p>Returns:</p> Name Type Description <code>timestamp</code> <code>int</code> <p>UTC time in milliseconds</p> Source code in <code>alsek/utils/temporal.py</code> <pre><code>def utcnow_timestamp_ms() -&gt; int:\n    \"\"\"UTC timestamp in milliseconds.\n\n    Returns:\n        timestamp (int): UTC time in milliseconds\n\n    \"\"\"\n    return int(datetime.utcnow().timestamp() * 1000)\n</code></pre>"},{"location":"reference/#alsek.utils.waiting","title":"<code>waiting</code>","text":"<p>Waiting</p>"},{"location":"reference/#alsek.utils.waiting.waiter","title":"<code>waiter(condition, sleep_interval=1 * 1000, timeout=None, timeout_msg=None)</code>","text":"<p>Wait for <code>condition</code>.</p> <p>Parameters:</p> Name Type Description Default <code>condition</code> <code>callable</code> <p>condition to wait for</p> required <code>sleep_interval</code> <code>int</code> <p>time (in milliseconds) to sleep between checks of <code>condition</code>.</p> <code>1 * 1000</code> <code>timeout</code> <code>int</code> <p>maximum amount of time (in milliseconds) this function can wait for <code>condition</code> to evaluate to <code>True</code>.</p> <code>None</code> <code>timeout_msg</code> <code>str</code> <p>message to display in the event of a timeout</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>alsek/utils/waiting.py</code> <pre><code>def waiter(\n    condition: Callable[[], bool],\n    sleep_interval: int = 1 * 1000,\n    timeout: Optional[int] = None,\n    timeout_msg: Optional[str] = None,\n) -&gt; bool:\n    \"\"\"Wait for ``condition``.\n\n    Args:\n        condition (callable): condition to wait for\n        sleep_interval (int): time (in milliseconds) to sleep\n            between checks of ``condition``.\n        timeout (int, optional): maximum amount of time (in milliseconds)\n            this function can wait for ``condition`` to evaluate\n            to ``True``.\n        timeout_msg (str, optional): message to display in the\n            event of a timeout\n\n    Returns:\n        bool\n\n    \"\"\"\n    start = time_ms()\n    stop_signal = StopSignalListener()\n    while True:\n        if stop_signal.received:\n            return False\n        elif condition():\n            return True\n        elif timeout is not None and (time_ms() - start) &gt; timeout:\n            raise TimeoutError(timeout_msg or \"\")\n        else:\n            stop_signal.wait(\n                min(sleep_interval, timeout) if timeout else sleep_interval\n            )\n</code></pre>"},{"location":"tips_and_tricks/","title":"Tips &amp; Tricks \u26f7\ufe0f","text":""},{"location":"tips_and_tricks/#multiprocessing-backend","title":"Multiprocessing Backend","text":"<p>It is possible to configure the multiprocessing library used by a worker pool. By default, <code>multiprocessing</code> from  the Python standard library will be used. However, this can be changed to the <code>PyTorch</code> implementation of multiprocessing by setting <code>ALSEK_MULTIPROCESSING_BACKEND</code> to <code>'torch'</code> prior to starting the worker pool.</p> <pre><code>export ALSEK_MULTIPROCESSING_BACKEND=torch\n\nalsek thread-pool my_project\n</code></pre>"},{"location":"tips_and_tricks/#capturing-status-updates","title":"Capturing Status Updates","text":"<p>In some applications it may be desirable to persists status updates  to multiple locations. For example, a Redis database and a PostgreSQL database. A short example of how to do this is provided below.</p> <pre><code>from typing import Optional, Any\n\nfrom alsek.core.message import Message\nfrom alsek.core.status.standard import StatusTracker\nfrom alsek.core.status.types import TaskStatus\n\nfrom sqlalchemy import Column, String, create_engine\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom sqlalchemy.orm import declarative_base, sessionmaker\n\nBase = declarative_base()\n\nengine = create_engine(\"...\")\nSession = sessionmaker(bind=engine)\nsession = Session()\n\n\nclass Status(Base):\n    __tablename__ = \"status\"\n\n    id = Column(UUID, primary_key=True)\n    status = Column(String)\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;Status(id='{self.id}', status='{self.status}')&gt;\"\n\n\nclass CustomStatusTracker(StatusTracker):\n    def set(self, message: Message, status: TaskStatus, detail: Optional[Any] = None) -&gt; None:\n        super().set(message, status=status, detail=detail)\n\n        if status == TaskStatus.SUBMITTED:\n            session.add(Status(id=message.uuid, status=status.name))\n        else:\n            record = session.query(Status).get(message.uuid)\n            record.status = status.name\n        session.commit()\n</code></pre> <p>This new <code>CustomStatusTracker()</code> class is a drop-in replacement for <code>StatusTracker()</code>.</p>"},{"location":"tips_and_tricks/#testing","title":"Testing","text":"<p>Testing an application may require a worker pool to be brought online. A small example of how to do this with pytest  and multiprocessing is provided below.</p> <p>First, create a <code>conftest.py</code> file with a <code>background_worker_pool</code> fixture.</p> <pre><code>import pytest\nfrom multiprocessing import Process\n\nfrom alsek.core.worker.thread import ThreadWorkerPool\n\nfrom my_application.tasks import task_1, task_2\n\n\ndef _run_pool() -&gt; None:\n    ThreadWorkerPool([task_1, task_2], backoff=None).run()\n\n\n@pytest.fixture()\ndef background_worker_pool() -&gt; None:\n    process = Process(target=_run_pool, daemon=True)\n    process.start()\n    yield\n    process.terminate()\n</code></pre> <p>Now, a worker pool can be brought online simply by including <code>background_worker_pool</code> in the signature of a test.</p> <pre><code>from alsek import task\nfrom my_application.tasks import task_1\n\n\ndef test_processing(background_worker_pool: None) -&gt; None:\n    message = task_1.generate()\n    ...\n</code></pre>"}]}