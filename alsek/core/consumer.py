"""

    Consumer

"""
import logging
from typing import Iterable, Optional, Union

from alsek.core.backoff import Backoff, ConstantBackoff, LinearBackoff
from alsek.core.broker import Broker
from alsek.core.concurrency import Lock
from alsek.core.message import Message
from alsek.storage.backends import Backend
from alsek.utils.namespacing import get_priority_namespace, get_subnamespace
from alsek.utils.system import StopSignalListener
from redis.exceptions import ConnectionError


class _ConsumptionMutex(Lock):
    def __init__(
        self,
        message: Message,
        backend: Backend,
        ttl_buffer: int = 90 * 1000,
    ) -> None:
        super().__init__(
            name=message.uuid,
            backend=backend,
            ttl=message.timeout + ttl_buffer,
            auto_release=False,
        )


def _dedup_messages(messages: list[Message]) -> list[Message]:
    output: list[Message] = list()
    for m in messages:
        if m.uuid not in {i.uuid for i in output}:
            output.append(m)
    return output


class Consumer:
    """Tool for consuming messages generated by the broker.

    Args:
        broker (Broker): an Alsek broker
        subset (list[str], dict[str, list[str]], optional): subset of messages to consume
            Must be one of the following

                * ``None``: consume messages from all queues and tasks
                * ``list``: a list of queues of the form ``["queue_a", "queue_b", "queue_c", ...]``
                * ``dict``: a dictionary of queues and tasks of the form
                    ``{"queue_a": ["task_name_a", "task_name_b", "task_name_c", ...], ...}``

        backoff (Backoff, optional): backoff to use in response to passes over the backend
            which did not yield any actionable messages.

    Notes:
        * If ``subset`` is a ``list`` or ``dict``, queue priority is derived from the
          order of the items. Items which appear earlier are given higher priority.
        * If ``subset`` is a ``dict``, task priority is derived from the order of
          task names in the value associated with each key (queue).

    Warning:
        * If ``subset`` is of type ``dict``, task names not included
          in any of the values will be ignored.

    """

    def __init__(
        self,
        broker: Broker,
        subset: Optional[Union[list[str], dict[str, list[str]]]] = None,
        backoff: Optional[Backoff] = LinearBackoff(
            1 * 1000,
            floor=1000,
            ceiling=30_000,
            zero_override=False,
        ),
    ) -> None:
        self.subset = subset
        self.broker = broker
        self.backoff = backoff or ConstantBackoff(0, floor=0, ceiling=0)

        self._empty_passes: int = 0
        self.stop_signal = StopSignalListener()

    def _scan_subnamespaces(self) -> Iterable[str]:
        if not self.subset:
            subnamespaces = [get_subnamespace(None)]
        elif isinstance(self.subset, list):
            subnamespaces = [get_subnamespace(q) for q in self.subset]
        else:
            subnamespaces = [
                get_subnamespace(q, task_name=t)
                for (q, tasks) in self.subset.items()
                for t in tasks
            ]

        for s in subnamespaces:
            if self.stop_signal.received:
                break
            for i in self.broker.backend.scan(f"{get_priority_namespace(s)}*"):
                if self.stop_signal.received:
                    break
                yield i

    def _poll(self) -> list[Message]:
        # NOTE: with this approach, we 'drain' / exhaust queues in
        #       the order they're privided, and then drain the next.
        #       So if we had queues A,B,C we'd drain A, then drain B
        #       and, finally, drain C.
        # ToDo: implement a 'flat' option that moves to the next queue
        #       So, A then B then C, round and round.
        output: list[Message] = list()

        def main_loop() -> None:
            for s in self._scan_subnamespaces():
                for name in self.broker.backend.priority_iter(s):
                    message_data = self.broker.backend.get(name)
                    if message_data is None:
                        # Message data can be None if it has been deleted (by a TTL or
                        # another worker) between the `priority_iter()` and `get()` operations.
                        continue

                    message = Message(**message_data)
                    if message.ready and not self.stop_signal.received:
                        with _ConsumptionMutex(message, self.broker.backend) as lock:
                            if lock.acquire(strict=False):
                                output.append(message.link_lock(lock, override=True))

        try:
            main_loop()
        except BaseException as error:
            pass

        self._empty_passes = 0 if output else self._empty_passes + 1
        return _dedup_messages(output)

    def stream(self) -> Iterable[Message]:
        """Generate a stream of messages to process from
        the data backend.

        Returns:
            stream (Iterable[Message]): an iterable of messages to process

        """
        while not self.stop_signal.received:
            for message in self._poll():
                yield message
            self.stop_signal.wait(self.backoff.get(self._empty_passes))
